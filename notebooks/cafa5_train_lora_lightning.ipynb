{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-02-15T17:02:12.444991-08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.13\n",
      "IPython version      : 8.18.1\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.133.1-microsoft-standard-WSL2\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 28\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/cafa5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59837</th>\n",
       "      <td>Q75PL7</td>\n",
       "      <td>MPPNSVDKTNETEYLKDNHVDYEKLIAPQASPIKHKIVVMNVIRFS...</td>\n",
       "      <td>59837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347</th>\n",
       "      <td>E9QA15</td>\n",
       "      <td>MDDFERRRELRRQKREEMRLEAERIAYQRNDDDEEEAARERRRRAR...</td>\n",
       "      <td>12347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62582</th>\n",
       "      <td>Q84TI3</td>\n",
       "      <td>MKRLRSSDDLDFCNDKNVDGEPPNSDRPASSSHRGFFSGNNRDRGE...</td>\n",
       "      <td>62582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47476</th>\n",
       "      <td>Q24060</td>\n",
       "      <td>MRYLCVFSLTLILCCLSIKAQSLNCTRLRENCRPCTRRLVDPINDL...</td>\n",
       "      <td>47476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40185</th>\n",
       "      <td>P84282</td>\n",
       "      <td>APECGREAHCGDDCQSQVVTRDFDDRTCPKLLCCSKDGWCGNTDAN...</td>\n",
       "      <td>40185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Entry ID                                           Sequence  Index\n",
       "59837   Q75PL7  MPPNSVDKTNETEYLKDNHVDYEKLIAPQASPIKHKIVVMNVIRFS...  59837\n",
       "12347   E9QA15  MDDFERRRELRRQKREEMRLEAERIAYQRNDDDEEEAARERRRRAR...  12347\n",
       "62582   Q84TI3  MKRLRSSDDLDFCNDKNVDGEPPNSDRPASSSHRGFFSGNNRDRGE...  62582\n",
       "47476   Q24060  MRYLCVFSLTLILCCLSIKAQSLNCTRLRENCRPCTRRLVDPINDL...  47476\n",
       "40185   P84282  APECGREAHCGDDCQSQVVTRDFDDRTCPKLLCCSKDGWCGNTDAN...  40185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(data_path / \"top100_train_split.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Entry ID', 'Sequence', 'Index'],\n",
       "    num_rows: 70921\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index'],\n",
       "        num_rows: 53190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index'],\n",
       "        num_rows: 17731\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.25, seed=0)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entry ID': 'Q6U841',\n",
       " 'Sequence': 'MEIKDQGAQMEPLLPTRNDEEAVVDRGGTRSILKTHFEKEDLEGHRTLFIGVHVPLGGRKSHRRHRHRGHKHRKRDRERDSGLEDGRESPSFDTPSQRVQFILGTEDDDEEHIPHDLFTELDEICWREGEDAEWRETARWLKFEEDVEDGGERWSKPYVATLSLHSLFELRSCILNGTVLLDMHANTLEEIADMVLDQQVSSGQLNEDVRHRVHEALMKQHHHQNQKKLTNRIPIVRSFADIGKKQSEPNSMDKNAGQVVSPQSAPACVENKNDVSRENSTVDFSKGLGGQQKGHTSPCGMKQRHEKGPPHQQEREVDLHFMKKIPPGAEASNILVGELEFLDRTVVAFVRLSPAVLLQGLAEVPIPTRFLFILLGPLGKGQQYHEIGRSIATLMTDEVFHDVAYKAKDRNDLVSGIDEFLDQVTVLPPGEWDPSIRIEPPKNVPSQEKRKIPAVPNGTAAHGEAEPHGGHSGPELQRTGRIFGGLILDIKRKAPYFWSDFRDAFSLQCLASFLFLYCACMSPVITFGGLLGEATEGRISAIESLFGASMTGIAYSLFGGQPLTILGSTGPVLVFEKILFKFCKEYGLSYLSLRASIGLWTATLCIILVATDASSLVCYITRFTEEAFASLICIIFIYEALEKLFELSEAYPINMHNDLELLTQYSCNCVEPHNPSNGTLKEWRESNISASDIIWENLTVSECKSLHGEYVGRACGHDHPYVPDVLFWSVILFFSTVTLSATLKQFKTSRYFPTKVRSIVSDFAVFLTILCMVLIDYAIGIPSPKLQVPSVFKPTRDDRGWFVTPLGPNPWWTVIAAIIPALLCTILIFMDQQITAVIINRKEHKLKKGCGYHLDLLMVAVMLGVCSIMGLPWFVAATVLSITHVNSLKLESECSAPGEQPKFLGIREQRVTGLMIFILMGSSVFMTSILKFIPMPVLYGVFLYMGASSLKGIQFFDRIKLFWMPAKHQPDFIYLRHVPLRKVHLFTIIQMSCLGLLWIIKVSRAAIVFPMMVLALVFVRKLMDLLFTKRELSWLDDLMPESKKKKLEDAEKEEEQSMLAMEDEGTVQLPLEGHYRDDPSVINISDEMSKTALWRNLLITADNSKDKESSFPSKSSPS',\n",
       " 'Index': 59130}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from transformers import AutoTokenizer, EsmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esm2_t12_35M_UR50D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_seqs(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"Sequence\"],\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e882545765a345db84e9e3a9e31a9760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687f61401839476abd60c2dcd21e9e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 53190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 17731\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_seqs, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 53190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 17731\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"Index\"]\n",
    ")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, dataset, split=\"train\"):\n",
    "        self.data = dataset[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.num_rows\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProteinDataset(tokenized_dataset)\n",
    "val_dataset = ProteinDataset(tokenized_dataset, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88652, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets\n",
    "targets = np.load(data_path / \"train_bp_top100_targets.npy\")\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = tokenizer.pad(batch)\n",
    "    batch[\"targets\"] = torch.as_tensor(\n",
    "        targets[batch[\"Index\"].tolist()], dtype=torch.float\n",
    "    )\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Index': tensor([ 5574, 19919, 37912,  7491, 17731, 18442, 79841, 68678]), 'input_ids': tensor([[ 0, 20, 13,  ...,  1,  1,  1],\n",
       "        [ 0, 20,  9,  ...,  1,  1,  1],\n",
       "        [ 0, 20,  7,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [ 0, 20,  8,  ...,  1,  1,  1],\n",
       "        [ 0, 20,  8,  ...,  1,  1,  1],\n",
       "        [ 0, 20, 14,  ...,  1,  1,  1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'targets': tensor([[1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "         1., 0., 0., 1., 1., 0., 0., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏃Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤖 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = EsmModel.from_pretrained(model_name)\n",
    "embedding_dim = llm.config.hidden_size\n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetunedESM(nn.Module):\n",
    "    def __init__(self, llm, dropout_p, embedding_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.llm = llm\n",
    "        self.dropout_p = dropout_p\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.pre_classifier = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def mean_pooling(self, token_embeddings, attention_mask):\n",
    "        \"\"\"Average the embedding of all amino acids in a sequence\"\"\"\n",
    "\n",
    "        # expand the mask\n",
    "        expanded_mask = (\n",
    "            attention_mask.unsqueeze(-1).expand(token_embeddings.shape).float()\n",
    "        )\n",
    "\n",
    "        # sum unmasked token embeddings\n",
    "        sum_embeddings = torch.sum(token_embeddings * expanded_mask, dim=1)\n",
    "\n",
    "        # number of unmasked tokens for each sequence\n",
    "        # set a min value to avoid divide by zero\n",
    "        num_tokens = torch.clamp(expanded_mask.sum(1), min=1e-9)\n",
    "\n",
    "        # divide\n",
    "        mean_embeddings = sum_embeddings / num_tokens\n",
    "        return mean_embeddings\n",
    "\n",
    "    def forward(self, batch):\n",
    "        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n",
    "\n",
    "        # per token representations from the last layer\n",
    "        token_embeddings = self.llm(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).last_hidden_state\n",
    "\n",
    "        # average per token representations\n",
    "        mean_embeddings = self.mean_pooling(token_embeddings, attention_mask)\n",
    "\n",
    "        # https://github.com/huggingface/transformers/blob/main/src/transformers/models/distilbert/modeling_distilbert.py\n",
    "        mean_embeddings = self.pre_classifier(mean_embeddings)  # (bs, embedding_dim)\n",
    "        mean_embeddings = nn.ReLU()(mean_embeddings)\n",
    "        mean_embeddings = self.dropout(mean_embeddings)\n",
    "\n",
    "        logits = self.classifier(mean_embeddings)  # (bs, num_classes)\n",
    "        return logits\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, batch):\n",
    "        self.eval()\n",
    "        y = self(batch)\n",
    "        return y.cpu().numpy()\n",
    "\n",
    "    def save(self, dp):\n",
    "        with open(Path(dp, \"args.json\"), \"w\") as fp:\n",
    "            contents = {\n",
    "                \"dropout_p\": self.dropout_p,\n",
    "                \"embedding_dim\": self.embedding_dim,\n",
    "                \"num_classes\": self.num_classes,\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "        torch.save(self.state_dict(), Path(dp) / \"model.pt\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, esm_model, args_fp, state_dict_fp):\n",
    "        with open(args_fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "\n",
    "        llm = EsmModel.from_pretrained(esm_model)\n",
    "        model = cls(llm=llm, **kwargs)\n",
    "        model.load_state_dict(\n",
    "            torch.load(state_dict_fp, map_location=torch.device(\"cpu\"))\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of FinetunedESM(\n",
      "  (llm): EsmModel(\n",
      "    (embeddings): EsmEmbeddings(\n",
      "      (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (position_embeddings): Embedding(1026, 480, padding_idx=1)\n",
      "    )\n",
      "    (encoder): EsmEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x EsmLayer(\n",
      "          (attention): EsmAttention(\n",
      "            (self): EsmSelfAttention(\n",
      "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
      "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
      "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (rotary_embeddings): RotaryEmbedding()\n",
      "            )\n",
      "            (output): EsmSelfOutput(\n",
      "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (intermediate): EsmIntermediate(\n",
      "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
      "          )\n",
      "          (output): EsmOutput(\n",
      "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pooler): EsmPooler(\n",
      "      (dense): Linear(in_features=480, out_features=480, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "    (contact_head): EsmContactPredictionHead(\n",
      "      (regression): Linear(in_features=240, out_features=1, bias=True)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (pre_classifier): Linear(in_features=480, out_features=480, bias=True)\n",
      "  (classifier): Linear(in_features=480, out_features=100, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "\n",
    "model = FinetunedESM(\n",
    "    llm=llm, dropout_p=0.1, embedding_dim=embedding_dim, num_classes=num_classes\n",
    ")\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trainable Parameters: 34271861\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Trainable Parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.W_a = nn.Parameter(torch.randn(in_dim, rank) / math.sqrt(rank))\n",
    "        self.W_b = nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x @ self.W_a  # batch * rank\n",
    "        x = x @ self.W_b  # batch * out_dim\n",
    "        return self.alpha * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithLoRA(nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora(\n",
    "    model,\n",
    "    lora_rank=8,\n",
    "    lora_alpha=16,\n",
    "    lora_query=True,\n",
    "    lora_key=False,\n",
    "    lora_value=True,\n",
    "    lora_projection=False,\n",
    "    lora_mlp=False,\n",
    "    lora_head=True,\n",
    "):\n",
    "    # freeze model layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # for adding lora to linear layers\n",
    "    linear_with_lora = partial(LinearWithLoRA, rank=lora_rank, alpha=lora_alpha)\n",
    "\n",
    "    # iterate through each transfomer layer\n",
    "    for layer in model.llm.encoder.layer:\n",
    "        if lora_query:\n",
    "            layer.attention.self.query = linear_with_lora(layer.attention.self.query)\n",
    "\n",
    "        if lora_key:\n",
    "            layer.attention.self.key = linear_with_lora(layer.attention.self.key)\n",
    "\n",
    "        if lora_value:\n",
    "            layer.attention.self.value = linear_with_lora(layer.attention.self.value)\n",
    "\n",
    "        if lora_projection:\n",
    "            layer.attention.output.dense = linear_with_lora(\n",
    "                layer.attention.output.dense\n",
    "            )\n",
    "\n",
    "        if lora_mlp:\n",
    "            layer.output.dense = linear_with_lora(layer.output.dense)\n",
    "            layer.output.dense = linear_with_lora(layer.output.dense)\n",
    "\n",
    "    if lora_head:\n",
    "        model.pre_classifier = linear_with_lora(model.pre_classifier)\n",
    "        model.classifier = linear_with_lora(model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trainable Parameters: 196640\n"
     ]
    }
   ],
   "source": [
    "apply_lora(model)\n",
    "print(f\"# Trainable Parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torchmetrics.functional.classification import multilabel_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMLightningModule(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        loss = self.loss_fn(logits, batch[\"targets\"])\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss  # this is passed to the optimizer for training\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        loss = self.loss_fn(logits, batch[\"targets\"])\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "        f1_score = multilabel_f1_score(\n",
    "            logits, batch[\"targets\"].type(torch.int), num_classes\n",
    "        )\n",
    "        self.log(\"val_f1_score\", f1_score, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "\n",
    "        f1_score = multilabel_f1_score(\n",
    "            logits, batch[\"targets\"].type(torch.int), num_classes\n",
    "        )\n",
    "        self.log(\"f1_score\", f1_score, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = ESMLightningModule(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(save_top_k=1, mode=\"max\", monitor=\"val_f1_score\")]\n",
    "logger = CSVLogger(save_dir=\"logs/\", name=\"esm_model_lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    callbacks=callbacks,\n",
    "    accelerator=\"gpu\",\n",
    "    precision=\"16-mixed\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | model   | FinetunedESM      | 34.5 M\n",
      "1 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------\n",
      "196 K     Trainable params\n",
      "34.3 M    Non-trainable params\n",
      "34.5 M    Total params\n",
      "137.874   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebbfaa170494aceac802040009c3525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4b0c26bd0a48a988cc2233290325d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65470ddc6c4f4157a37f570a10b050c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebbef893df54f529636239993de6177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a5d4836dfb4bfdb14dfdf493b09e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1202f291046c4e55867f37555fc1338c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1fe79c364c41b1bb74f87fc8678a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 170.78 min\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "trainer.fit(\n",
    "    model=lightning_model, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"Training Time: {(end-start)/60:.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
