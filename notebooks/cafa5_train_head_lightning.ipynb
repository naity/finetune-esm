{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-02-17T01:43:23.810230+00:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.13\n",
      "IPython version      : 8.21.0\n",
      "\n",
      "Compiler    : GCC 12.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.0-1033-aws\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 48\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/cafa5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59837</th>\n",
       "      <td>Q75PL7</td>\n",
       "      <td>MPPNSVDKTNETEYLKDNHVDYEKLIAPQASPIKHKIVVMNVIRFS...</td>\n",
       "      <td>59837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347</th>\n",
       "      <td>E9QA15</td>\n",
       "      <td>MDDFERRRELRRQKREEMRLEAERIAYQRNDDDEEEAARERRRRAR...</td>\n",
       "      <td>12347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62582</th>\n",
       "      <td>Q84TI3</td>\n",
       "      <td>MKRLRSSDDLDFCNDKNVDGEPPNSDRPASSSHRGFFSGNNRDRGE...</td>\n",
       "      <td>62582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47476</th>\n",
       "      <td>Q24060</td>\n",
       "      <td>MRYLCVFSLTLILCCLSIKAQSLNCTRLRENCRPCTRRLVDPINDL...</td>\n",
       "      <td>47476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40185</th>\n",
       "      <td>P84282</td>\n",
       "      <td>APECGREAHCGDDCQSQVVTRDFDDRTCPKLLCCSKDGWCGNTDAN...</td>\n",
       "      <td>40185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Entry ID                                           Sequence  Index\n",
       "59837   Q75PL7  MPPNSVDKTNETEYLKDNHVDYEKLIAPQASPIKHKIVVMNVIRFS...  59837\n",
       "12347   E9QA15  MDDFERRRELRRQKREEMRLEAERIAYQRNDDDEEEAARERRRRAR...  12347\n",
       "62582   Q84TI3  MKRLRSSDDLDFCNDKNVDGEPPNSDRPASSSHRGFFSGNNRDRGE...  62582\n",
       "47476   Q24060  MRYLCVFSLTLILCCLSIKAQSLNCTRLRENCRPCTRRLVDPINDL...  47476\n",
       "40185   P84282  APECGREAHCGDDCQSQVVTRDFDDRTCPKLLCCSKDGWCGNTDAN...  40185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(data_path / \"top100_train_split.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Entry ID', 'Sequence', 'Index'],\n",
       "    num_rows: 70921\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index'],\n",
       "        num_rows: 53190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index'],\n",
       "        num_rows: 17731\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.25, seed=0)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entry ID': 'Q6U841',\n",
       " 'Sequence': 'MEIKDQGAQMEPLLPTRNDEEAVVDRGGTRSILKTHFEKEDLEGHRTLFIGVHVPLGGRKSHRRHRHRGHKHRKRDRERDSGLEDGRESPSFDTPSQRVQFILGTEDDDEEHIPHDLFTELDEICWREGEDAEWRETARWLKFEEDVEDGGERWSKPYVATLSLHSLFELRSCILNGTVLLDMHANTLEEIADMVLDQQVSSGQLNEDVRHRVHEALMKQHHHQNQKKLTNRIPIVRSFADIGKKQSEPNSMDKNAGQVVSPQSAPACVENKNDVSRENSTVDFSKGLGGQQKGHTSPCGMKQRHEKGPPHQQEREVDLHFMKKIPPGAEASNILVGELEFLDRTVVAFVRLSPAVLLQGLAEVPIPTRFLFILLGPLGKGQQYHEIGRSIATLMTDEVFHDVAYKAKDRNDLVSGIDEFLDQVTVLPPGEWDPSIRIEPPKNVPSQEKRKIPAVPNGTAAHGEAEPHGGHSGPELQRTGRIFGGLILDIKRKAPYFWSDFRDAFSLQCLASFLFLYCACMSPVITFGGLLGEATEGRISAIESLFGASMTGIAYSLFGGQPLTILGSTGPVLVFEKILFKFCKEYGLSYLSLRASIGLWTATLCIILVATDASSLVCYITRFTEEAFASLICIIFIYEALEKLFELSEAYPINMHNDLELLTQYSCNCVEPHNPSNGTLKEWRESNISASDIIWENLTVSECKSLHGEYVGRACGHDHPYVPDVLFWSVILFFSTVTLSATLKQFKTSRYFPTKVRSIVSDFAVFLTILCMVLIDYAIGIPSPKLQVPSVFKPTRDDRGWFVTPLGPNPWWTVIAAIIPALLCTILIFMDQQITAVIINRKEHKLKKGCGYHLDLLMVAVMLGVCSIMGLPWFVAATVLSITHVNSLKLESECSAPGEQPKFLGIREQRVTGLMIFILMGSSVFMTSILKFIPMPVLYGVFLYMGASSLKGIQFFDRIKLFWMPAKHQPDFIYLRHVPLRKVHLFTIIQMSCLGLLWIIKVSRAAIVFPMMVLALVFVRKLMDLLFTKRELSWLDDLMPESKKKKLEDAEKEEEQSMLAMEDEGTVQLPLEGHYRDDPSVINISDEMSKTALWRNLLITADNSKDKESSFPSKSSPS',\n",
       " 'Index': 59130}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from transformers import AutoTokenizer, EsmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 95.0/95.0 [00:00<00:00, 686kB/s]\n",
      "vocab.txt: 100%|██████████| 93.0/93.0 [00:00<00:00, 799kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 1.10MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_seqs(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"Sequence\"],\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/53190 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "                                                                  \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 53190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 17731\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_seqs, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 53190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Entry ID', 'Sequence', 'Index', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 17731\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"Index\"]\n",
    ")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53190"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, dataset, split=\"train\"):\n",
    "        self.data = dataset[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.num_rows\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProteinDataset(tokenized_dataset)\n",
    "val_dataset = ProteinDataset(tokenized_dataset, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88652, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets\n",
    "targets = np.load(data_path / \"train_bp_top100_targets.npy\")\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = tokenizer.pad(batch)\n",
    "    batch[\"targets\"] = torch.as_tensor(\n",
    "        targets[batch[\"Index\"].tolist()], dtype=torch.float\n",
    "    )\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Index': tensor([25674, 20809, 73439, 86298, 42191, 25796, 11249, 22095]), 'input_ids': tensor([[ 0, 20,  6,  ...,  1,  1,  1],\n",
       "        [ 0, 20, 14,  ...,  1,  1,  1],\n",
       "        [ 0, 20, 22,  ...,  1,  1,  1],\n",
       "        ...,\n",
       "        [ 0, 20,  8,  ...,  1,  1,  1],\n",
       "        [ 0, 20,  8,  ...,  1,  1,  1],\n",
       "        [ 0, 20,  8,  ...,  1,  1,  1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'targets': tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "         1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
       "         0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "         1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏃Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤖 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 724/724 [00:00<00:00, 4.10MB/s]\n",
      "model.safetensors: 100%|██████████| 2.61G/2.61G [00:33<00:00, 76.9MB/s]\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = EsmModel.from_pretrained(model_name)\n",
    "embedding_dim = llm.config.hidden_size\n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetunedESM(nn.Module):\n",
    "    def __init__(self, llm, dropout_p, embedding_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.llm = llm\n",
    "        self.dropout_p = dropout_p\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.pre_classifier = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def mean_pooling(self, token_embeddings, attention_mask):\n",
    "        \"\"\"Average the embedding of all amino acids in a sequence\"\"\"\n",
    "\n",
    "        # expand the mask\n",
    "        expanded_mask = (\n",
    "            attention_mask.unsqueeze(-1).expand(token_embeddings.shape).float()\n",
    "        )\n",
    "\n",
    "        # sum unmasked token embeddings\n",
    "        sum_embeddings = torch.sum(token_embeddings * expanded_mask, dim=1)\n",
    "\n",
    "        # number of unmasked tokens for each sequence\n",
    "        # set a min value to avoid divide by zero\n",
    "        num_tokens = torch.clamp(expanded_mask.sum(1), min=1e-9)\n",
    "\n",
    "        # divide\n",
    "        mean_embeddings = sum_embeddings / num_tokens\n",
    "        return mean_embeddings\n",
    "\n",
    "    def forward(self, batch):\n",
    "        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n",
    "\n",
    "        # per token representations from the last layer\n",
    "        token_embeddings = self.llm(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).last_hidden_state\n",
    "\n",
    "        # average per token representations\n",
    "        mean_embeddings = self.mean_pooling(token_embeddings, attention_mask)\n",
    "\n",
    "        # https://github.com/huggingface/transformers/blob/main/src/transformers/models/distilbert/modeling_distilbert.py\n",
    "        mean_embeddings = self.pre_classifier(mean_embeddings)  # (bs, embedding_dim)\n",
    "        mean_embeddings = nn.ReLU()(mean_embeddings)\n",
    "        mean_embeddings = self.dropout(mean_embeddings)\n",
    "\n",
    "        logits = self.classifier(mean_embeddings)  # (bs, num_classes)\n",
    "        return logits\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, batch):\n",
    "        self.eval()\n",
    "        y = self(batch)\n",
    "        return y.cpu().numpy()\n",
    "\n",
    "    def save(self, dp):\n",
    "        with open(Path(dp, \"args.json\"), \"w\") as fp:\n",
    "            contents = {\n",
    "                \"dropout_p\": self.dropout_p,\n",
    "                \"embedding_dim\": self.embedding_dim,\n",
    "                \"num_classes\": self.num_classes,\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "        torch.save(self.state_dict(), Path(dp) / \"model.pt\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, esm_model, args_fp, state_dict_fp):\n",
    "        with open(args_fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "\n",
    "        llm = EsmModel.from_pretrained(esm_model)\n",
    "        model = cls(llm=llm, **kwargs)\n",
    "        model.load_state_dict(\n",
    "            torch.load(state_dict_fp, map_location=torch.device(\"cpu\"))\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of FinetunedESM(\n",
      "  (llm): EsmModel(\n",
      "    (embeddings): EsmEmbeddings(\n",
      "      (word_embeddings): Embedding(33, 1280, padding_idx=1)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (position_embeddings): Embedding(1026, 1280, padding_idx=1)\n",
      "    )\n",
      "    (encoder): EsmEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-32): 33 x EsmLayer(\n",
      "          (attention): EsmAttention(\n",
      "            (self): EsmSelfAttention(\n",
      "              (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (key): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (rotary_embeddings): RotaryEmbedding()\n",
      "            )\n",
      "            (output): EsmSelfOutput(\n",
      "              (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (intermediate): EsmIntermediate(\n",
      "            (dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "          )\n",
      "          (output): EsmOutput(\n",
      "            (dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pooler): EsmPooler(\n",
      "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "    (contact_head): EsmContactPredictionHead(\n",
      "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (pre_classifier): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (classifier): Linear(in_features=1280, out_features=100, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "\n",
    "model = FinetunedESM(\n",
    "    llm=llm, dropout_p=0.1, embedding_dim=embedding_dim, num_classes=num_classes\n",
    ")\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trainable Parameters: 654121721\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Trainable Parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze model layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.pre_classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Trainable Parameters: 1767780\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Trainable Parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm.embeddings.word_embeddings.weight: False\n",
      "llm.embeddings.position_embeddings.weight: False\n",
      "llm.encoder.layer.0.attention.self.query.weight: False\n",
      "llm.encoder.layer.0.attention.self.query.bias: False\n",
      "llm.encoder.layer.0.attention.self.key.weight: False\n",
      "llm.encoder.layer.0.attention.self.key.bias: False\n",
      "llm.encoder.layer.0.attention.self.value.weight: False\n",
      "llm.encoder.layer.0.attention.self.value.bias: False\n",
      "llm.encoder.layer.0.attention.output.dense.weight: False\n",
      "llm.encoder.layer.0.attention.output.dense.bias: False\n",
      "llm.encoder.layer.0.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.0.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.0.intermediate.dense.weight: False\n",
      "llm.encoder.layer.0.intermediate.dense.bias: False\n",
      "llm.encoder.layer.0.output.dense.weight: False\n",
      "llm.encoder.layer.0.output.dense.bias: False\n",
      "llm.encoder.layer.0.LayerNorm.weight: False\n",
      "llm.encoder.layer.0.LayerNorm.bias: False\n",
      "llm.encoder.layer.1.attention.self.query.weight: False\n",
      "llm.encoder.layer.1.attention.self.query.bias: False\n",
      "llm.encoder.layer.1.attention.self.key.weight: False\n",
      "llm.encoder.layer.1.attention.self.key.bias: False\n",
      "llm.encoder.layer.1.attention.self.value.weight: False\n",
      "llm.encoder.layer.1.attention.self.value.bias: False\n",
      "llm.encoder.layer.1.attention.output.dense.weight: False\n",
      "llm.encoder.layer.1.attention.output.dense.bias: False\n",
      "llm.encoder.layer.1.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.1.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.1.intermediate.dense.weight: False\n",
      "llm.encoder.layer.1.intermediate.dense.bias: False\n",
      "llm.encoder.layer.1.output.dense.weight: False\n",
      "llm.encoder.layer.1.output.dense.bias: False\n",
      "llm.encoder.layer.1.LayerNorm.weight: False\n",
      "llm.encoder.layer.1.LayerNorm.bias: False\n",
      "llm.encoder.layer.2.attention.self.query.weight: False\n",
      "llm.encoder.layer.2.attention.self.query.bias: False\n",
      "llm.encoder.layer.2.attention.self.key.weight: False\n",
      "llm.encoder.layer.2.attention.self.key.bias: False\n",
      "llm.encoder.layer.2.attention.self.value.weight: False\n",
      "llm.encoder.layer.2.attention.self.value.bias: False\n",
      "llm.encoder.layer.2.attention.output.dense.weight: False\n",
      "llm.encoder.layer.2.attention.output.dense.bias: False\n",
      "llm.encoder.layer.2.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.2.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.2.intermediate.dense.weight: False\n",
      "llm.encoder.layer.2.intermediate.dense.bias: False\n",
      "llm.encoder.layer.2.output.dense.weight: False\n",
      "llm.encoder.layer.2.output.dense.bias: False\n",
      "llm.encoder.layer.2.LayerNorm.weight: False\n",
      "llm.encoder.layer.2.LayerNorm.bias: False\n",
      "llm.encoder.layer.3.attention.self.query.weight: False\n",
      "llm.encoder.layer.3.attention.self.query.bias: False\n",
      "llm.encoder.layer.3.attention.self.key.weight: False\n",
      "llm.encoder.layer.3.attention.self.key.bias: False\n",
      "llm.encoder.layer.3.attention.self.value.weight: False\n",
      "llm.encoder.layer.3.attention.self.value.bias: False\n",
      "llm.encoder.layer.3.attention.output.dense.weight: False\n",
      "llm.encoder.layer.3.attention.output.dense.bias: False\n",
      "llm.encoder.layer.3.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.3.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.3.intermediate.dense.weight: False\n",
      "llm.encoder.layer.3.intermediate.dense.bias: False\n",
      "llm.encoder.layer.3.output.dense.weight: False\n",
      "llm.encoder.layer.3.output.dense.bias: False\n",
      "llm.encoder.layer.3.LayerNorm.weight: False\n",
      "llm.encoder.layer.3.LayerNorm.bias: False\n",
      "llm.encoder.layer.4.attention.self.query.weight: False\n",
      "llm.encoder.layer.4.attention.self.query.bias: False\n",
      "llm.encoder.layer.4.attention.self.key.weight: False\n",
      "llm.encoder.layer.4.attention.self.key.bias: False\n",
      "llm.encoder.layer.4.attention.self.value.weight: False\n",
      "llm.encoder.layer.4.attention.self.value.bias: False\n",
      "llm.encoder.layer.4.attention.output.dense.weight: False\n",
      "llm.encoder.layer.4.attention.output.dense.bias: False\n",
      "llm.encoder.layer.4.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.4.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.4.intermediate.dense.weight: False\n",
      "llm.encoder.layer.4.intermediate.dense.bias: False\n",
      "llm.encoder.layer.4.output.dense.weight: False\n",
      "llm.encoder.layer.4.output.dense.bias: False\n",
      "llm.encoder.layer.4.LayerNorm.weight: False\n",
      "llm.encoder.layer.4.LayerNorm.bias: False\n",
      "llm.encoder.layer.5.attention.self.query.weight: False\n",
      "llm.encoder.layer.5.attention.self.query.bias: False\n",
      "llm.encoder.layer.5.attention.self.key.weight: False\n",
      "llm.encoder.layer.5.attention.self.key.bias: False\n",
      "llm.encoder.layer.5.attention.self.value.weight: False\n",
      "llm.encoder.layer.5.attention.self.value.bias: False\n",
      "llm.encoder.layer.5.attention.output.dense.weight: False\n",
      "llm.encoder.layer.5.attention.output.dense.bias: False\n",
      "llm.encoder.layer.5.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.5.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.5.intermediate.dense.weight: False\n",
      "llm.encoder.layer.5.intermediate.dense.bias: False\n",
      "llm.encoder.layer.5.output.dense.weight: False\n",
      "llm.encoder.layer.5.output.dense.bias: False\n",
      "llm.encoder.layer.5.LayerNorm.weight: False\n",
      "llm.encoder.layer.5.LayerNorm.bias: False\n",
      "llm.encoder.layer.6.attention.self.query.weight: False\n",
      "llm.encoder.layer.6.attention.self.query.bias: False\n",
      "llm.encoder.layer.6.attention.self.key.weight: False\n",
      "llm.encoder.layer.6.attention.self.key.bias: False\n",
      "llm.encoder.layer.6.attention.self.value.weight: False\n",
      "llm.encoder.layer.6.attention.self.value.bias: False\n",
      "llm.encoder.layer.6.attention.output.dense.weight: False\n",
      "llm.encoder.layer.6.attention.output.dense.bias: False\n",
      "llm.encoder.layer.6.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.6.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.6.intermediate.dense.weight: False\n",
      "llm.encoder.layer.6.intermediate.dense.bias: False\n",
      "llm.encoder.layer.6.output.dense.weight: False\n",
      "llm.encoder.layer.6.output.dense.bias: False\n",
      "llm.encoder.layer.6.LayerNorm.weight: False\n",
      "llm.encoder.layer.6.LayerNorm.bias: False\n",
      "llm.encoder.layer.7.attention.self.query.weight: False\n",
      "llm.encoder.layer.7.attention.self.query.bias: False\n",
      "llm.encoder.layer.7.attention.self.key.weight: False\n",
      "llm.encoder.layer.7.attention.self.key.bias: False\n",
      "llm.encoder.layer.7.attention.self.value.weight: False\n",
      "llm.encoder.layer.7.attention.self.value.bias: False\n",
      "llm.encoder.layer.7.attention.output.dense.weight: False\n",
      "llm.encoder.layer.7.attention.output.dense.bias: False\n",
      "llm.encoder.layer.7.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.7.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.7.intermediate.dense.weight: False\n",
      "llm.encoder.layer.7.intermediate.dense.bias: False\n",
      "llm.encoder.layer.7.output.dense.weight: False\n",
      "llm.encoder.layer.7.output.dense.bias: False\n",
      "llm.encoder.layer.7.LayerNorm.weight: False\n",
      "llm.encoder.layer.7.LayerNorm.bias: False\n",
      "llm.encoder.layer.8.attention.self.query.weight: False\n",
      "llm.encoder.layer.8.attention.self.query.bias: False\n",
      "llm.encoder.layer.8.attention.self.key.weight: False\n",
      "llm.encoder.layer.8.attention.self.key.bias: False\n",
      "llm.encoder.layer.8.attention.self.value.weight: False\n",
      "llm.encoder.layer.8.attention.self.value.bias: False\n",
      "llm.encoder.layer.8.attention.output.dense.weight: False\n",
      "llm.encoder.layer.8.attention.output.dense.bias: False\n",
      "llm.encoder.layer.8.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.8.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.8.intermediate.dense.weight: False\n",
      "llm.encoder.layer.8.intermediate.dense.bias: False\n",
      "llm.encoder.layer.8.output.dense.weight: False\n",
      "llm.encoder.layer.8.output.dense.bias: False\n",
      "llm.encoder.layer.8.LayerNorm.weight: False\n",
      "llm.encoder.layer.8.LayerNorm.bias: False\n",
      "llm.encoder.layer.9.attention.self.query.weight: False\n",
      "llm.encoder.layer.9.attention.self.query.bias: False\n",
      "llm.encoder.layer.9.attention.self.key.weight: False\n",
      "llm.encoder.layer.9.attention.self.key.bias: False\n",
      "llm.encoder.layer.9.attention.self.value.weight: False\n",
      "llm.encoder.layer.9.attention.self.value.bias: False\n",
      "llm.encoder.layer.9.attention.output.dense.weight: False\n",
      "llm.encoder.layer.9.attention.output.dense.bias: False\n",
      "llm.encoder.layer.9.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.9.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.9.intermediate.dense.weight: False\n",
      "llm.encoder.layer.9.intermediate.dense.bias: False\n",
      "llm.encoder.layer.9.output.dense.weight: False\n",
      "llm.encoder.layer.9.output.dense.bias: False\n",
      "llm.encoder.layer.9.LayerNorm.weight: False\n",
      "llm.encoder.layer.9.LayerNorm.bias: False\n",
      "llm.encoder.layer.10.attention.self.query.weight: False\n",
      "llm.encoder.layer.10.attention.self.query.bias: False\n",
      "llm.encoder.layer.10.attention.self.key.weight: False\n",
      "llm.encoder.layer.10.attention.self.key.bias: False\n",
      "llm.encoder.layer.10.attention.self.value.weight: False\n",
      "llm.encoder.layer.10.attention.self.value.bias: False\n",
      "llm.encoder.layer.10.attention.output.dense.weight: False\n",
      "llm.encoder.layer.10.attention.output.dense.bias: False\n",
      "llm.encoder.layer.10.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.10.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.10.intermediate.dense.weight: False\n",
      "llm.encoder.layer.10.intermediate.dense.bias: False\n",
      "llm.encoder.layer.10.output.dense.weight: False\n",
      "llm.encoder.layer.10.output.dense.bias: False\n",
      "llm.encoder.layer.10.LayerNorm.weight: False\n",
      "llm.encoder.layer.10.LayerNorm.bias: False\n",
      "llm.encoder.layer.11.attention.self.query.weight: False\n",
      "llm.encoder.layer.11.attention.self.query.bias: False\n",
      "llm.encoder.layer.11.attention.self.key.weight: False\n",
      "llm.encoder.layer.11.attention.self.key.bias: False\n",
      "llm.encoder.layer.11.attention.self.value.weight: False\n",
      "llm.encoder.layer.11.attention.self.value.bias: False\n",
      "llm.encoder.layer.11.attention.output.dense.weight: False\n",
      "llm.encoder.layer.11.attention.output.dense.bias: False\n",
      "llm.encoder.layer.11.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.11.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.11.intermediate.dense.weight: False\n",
      "llm.encoder.layer.11.intermediate.dense.bias: False\n",
      "llm.encoder.layer.11.output.dense.weight: False\n",
      "llm.encoder.layer.11.output.dense.bias: False\n",
      "llm.encoder.layer.11.LayerNorm.weight: False\n",
      "llm.encoder.layer.11.LayerNorm.bias: False\n",
      "llm.encoder.layer.12.attention.self.query.weight: False\n",
      "llm.encoder.layer.12.attention.self.query.bias: False\n",
      "llm.encoder.layer.12.attention.self.key.weight: False\n",
      "llm.encoder.layer.12.attention.self.key.bias: False\n",
      "llm.encoder.layer.12.attention.self.value.weight: False\n",
      "llm.encoder.layer.12.attention.self.value.bias: False\n",
      "llm.encoder.layer.12.attention.output.dense.weight: False\n",
      "llm.encoder.layer.12.attention.output.dense.bias: False\n",
      "llm.encoder.layer.12.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.12.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.12.intermediate.dense.weight: False\n",
      "llm.encoder.layer.12.intermediate.dense.bias: False\n",
      "llm.encoder.layer.12.output.dense.weight: False\n",
      "llm.encoder.layer.12.output.dense.bias: False\n",
      "llm.encoder.layer.12.LayerNorm.weight: False\n",
      "llm.encoder.layer.12.LayerNorm.bias: False\n",
      "llm.encoder.layer.13.attention.self.query.weight: False\n",
      "llm.encoder.layer.13.attention.self.query.bias: False\n",
      "llm.encoder.layer.13.attention.self.key.weight: False\n",
      "llm.encoder.layer.13.attention.self.key.bias: False\n",
      "llm.encoder.layer.13.attention.self.value.weight: False\n",
      "llm.encoder.layer.13.attention.self.value.bias: False\n",
      "llm.encoder.layer.13.attention.output.dense.weight: False\n",
      "llm.encoder.layer.13.attention.output.dense.bias: False\n",
      "llm.encoder.layer.13.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.13.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.13.intermediate.dense.weight: False\n",
      "llm.encoder.layer.13.intermediate.dense.bias: False\n",
      "llm.encoder.layer.13.output.dense.weight: False\n",
      "llm.encoder.layer.13.output.dense.bias: False\n",
      "llm.encoder.layer.13.LayerNorm.weight: False\n",
      "llm.encoder.layer.13.LayerNorm.bias: False\n",
      "llm.encoder.layer.14.attention.self.query.weight: False\n",
      "llm.encoder.layer.14.attention.self.query.bias: False\n",
      "llm.encoder.layer.14.attention.self.key.weight: False\n",
      "llm.encoder.layer.14.attention.self.key.bias: False\n",
      "llm.encoder.layer.14.attention.self.value.weight: False\n",
      "llm.encoder.layer.14.attention.self.value.bias: False\n",
      "llm.encoder.layer.14.attention.output.dense.weight: False\n",
      "llm.encoder.layer.14.attention.output.dense.bias: False\n",
      "llm.encoder.layer.14.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.14.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.14.intermediate.dense.weight: False\n",
      "llm.encoder.layer.14.intermediate.dense.bias: False\n",
      "llm.encoder.layer.14.output.dense.weight: False\n",
      "llm.encoder.layer.14.output.dense.bias: False\n",
      "llm.encoder.layer.14.LayerNorm.weight: False\n",
      "llm.encoder.layer.14.LayerNorm.bias: False\n",
      "llm.encoder.layer.15.attention.self.query.weight: False\n",
      "llm.encoder.layer.15.attention.self.query.bias: False\n",
      "llm.encoder.layer.15.attention.self.key.weight: False\n",
      "llm.encoder.layer.15.attention.self.key.bias: False\n",
      "llm.encoder.layer.15.attention.self.value.weight: False\n",
      "llm.encoder.layer.15.attention.self.value.bias: False\n",
      "llm.encoder.layer.15.attention.output.dense.weight: False\n",
      "llm.encoder.layer.15.attention.output.dense.bias: False\n",
      "llm.encoder.layer.15.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.15.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.15.intermediate.dense.weight: False\n",
      "llm.encoder.layer.15.intermediate.dense.bias: False\n",
      "llm.encoder.layer.15.output.dense.weight: False\n",
      "llm.encoder.layer.15.output.dense.bias: False\n",
      "llm.encoder.layer.15.LayerNorm.weight: False\n",
      "llm.encoder.layer.15.LayerNorm.bias: False\n",
      "llm.encoder.layer.16.attention.self.query.weight: False\n",
      "llm.encoder.layer.16.attention.self.query.bias: False\n",
      "llm.encoder.layer.16.attention.self.key.weight: False\n",
      "llm.encoder.layer.16.attention.self.key.bias: False\n",
      "llm.encoder.layer.16.attention.self.value.weight: False\n",
      "llm.encoder.layer.16.attention.self.value.bias: False\n",
      "llm.encoder.layer.16.attention.output.dense.weight: False\n",
      "llm.encoder.layer.16.attention.output.dense.bias: False\n",
      "llm.encoder.layer.16.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.16.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.16.intermediate.dense.weight: False\n",
      "llm.encoder.layer.16.intermediate.dense.bias: False\n",
      "llm.encoder.layer.16.output.dense.weight: False\n",
      "llm.encoder.layer.16.output.dense.bias: False\n",
      "llm.encoder.layer.16.LayerNorm.weight: False\n",
      "llm.encoder.layer.16.LayerNorm.bias: False\n",
      "llm.encoder.layer.17.attention.self.query.weight: False\n",
      "llm.encoder.layer.17.attention.self.query.bias: False\n",
      "llm.encoder.layer.17.attention.self.key.weight: False\n",
      "llm.encoder.layer.17.attention.self.key.bias: False\n",
      "llm.encoder.layer.17.attention.self.value.weight: False\n",
      "llm.encoder.layer.17.attention.self.value.bias: False\n",
      "llm.encoder.layer.17.attention.output.dense.weight: False\n",
      "llm.encoder.layer.17.attention.output.dense.bias: False\n",
      "llm.encoder.layer.17.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.17.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.17.intermediate.dense.weight: False\n",
      "llm.encoder.layer.17.intermediate.dense.bias: False\n",
      "llm.encoder.layer.17.output.dense.weight: False\n",
      "llm.encoder.layer.17.output.dense.bias: False\n",
      "llm.encoder.layer.17.LayerNorm.weight: False\n",
      "llm.encoder.layer.17.LayerNorm.bias: False\n",
      "llm.encoder.layer.18.attention.self.query.weight: False\n",
      "llm.encoder.layer.18.attention.self.query.bias: False\n",
      "llm.encoder.layer.18.attention.self.key.weight: False\n",
      "llm.encoder.layer.18.attention.self.key.bias: False\n",
      "llm.encoder.layer.18.attention.self.value.weight: False\n",
      "llm.encoder.layer.18.attention.self.value.bias: False\n",
      "llm.encoder.layer.18.attention.output.dense.weight: False\n",
      "llm.encoder.layer.18.attention.output.dense.bias: False\n",
      "llm.encoder.layer.18.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.18.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.18.intermediate.dense.weight: False\n",
      "llm.encoder.layer.18.intermediate.dense.bias: False\n",
      "llm.encoder.layer.18.output.dense.weight: False\n",
      "llm.encoder.layer.18.output.dense.bias: False\n",
      "llm.encoder.layer.18.LayerNorm.weight: False\n",
      "llm.encoder.layer.18.LayerNorm.bias: False\n",
      "llm.encoder.layer.19.attention.self.query.weight: False\n",
      "llm.encoder.layer.19.attention.self.query.bias: False\n",
      "llm.encoder.layer.19.attention.self.key.weight: False\n",
      "llm.encoder.layer.19.attention.self.key.bias: False\n",
      "llm.encoder.layer.19.attention.self.value.weight: False\n",
      "llm.encoder.layer.19.attention.self.value.bias: False\n",
      "llm.encoder.layer.19.attention.output.dense.weight: False\n",
      "llm.encoder.layer.19.attention.output.dense.bias: False\n",
      "llm.encoder.layer.19.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.19.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.19.intermediate.dense.weight: False\n",
      "llm.encoder.layer.19.intermediate.dense.bias: False\n",
      "llm.encoder.layer.19.output.dense.weight: False\n",
      "llm.encoder.layer.19.output.dense.bias: False\n",
      "llm.encoder.layer.19.LayerNorm.weight: False\n",
      "llm.encoder.layer.19.LayerNorm.bias: False\n",
      "llm.encoder.layer.20.attention.self.query.weight: False\n",
      "llm.encoder.layer.20.attention.self.query.bias: False\n",
      "llm.encoder.layer.20.attention.self.key.weight: False\n",
      "llm.encoder.layer.20.attention.self.key.bias: False\n",
      "llm.encoder.layer.20.attention.self.value.weight: False\n",
      "llm.encoder.layer.20.attention.self.value.bias: False\n",
      "llm.encoder.layer.20.attention.output.dense.weight: False\n",
      "llm.encoder.layer.20.attention.output.dense.bias: False\n",
      "llm.encoder.layer.20.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.20.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.20.intermediate.dense.weight: False\n",
      "llm.encoder.layer.20.intermediate.dense.bias: False\n",
      "llm.encoder.layer.20.output.dense.weight: False\n",
      "llm.encoder.layer.20.output.dense.bias: False\n",
      "llm.encoder.layer.20.LayerNorm.weight: False\n",
      "llm.encoder.layer.20.LayerNorm.bias: False\n",
      "llm.encoder.layer.21.attention.self.query.weight: False\n",
      "llm.encoder.layer.21.attention.self.query.bias: False\n",
      "llm.encoder.layer.21.attention.self.key.weight: False\n",
      "llm.encoder.layer.21.attention.self.key.bias: False\n",
      "llm.encoder.layer.21.attention.self.value.weight: False\n",
      "llm.encoder.layer.21.attention.self.value.bias: False\n",
      "llm.encoder.layer.21.attention.output.dense.weight: False\n",
      "llm.encoder.layer.21.attention.output.dense.bias: False\n",
      "llm.encoder.layer.21.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.21.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.21.intermediate.dense.weight: False\n",
      "llm.encoder.layer.21.intermediate.dense.bias: False\n",
      "llm.encoder.layer.21.output.dense.weight: False\n",
      "llm.encoder.layer.21.output.dense.bias: False\n",
      "llm.encoder.layer.21.LayerNorm.weight: False\n",
      "llm.encoder.layer.21.LayerNorm.bias: False\n",
      "llm.encoder.layer.22.attention.self.query.weight: False\n",
      "llm.encoder.layer.22.attention.self.query.bias: False\n",
      "llm.encoder.layer.22.attention.self.key.weight: False\n",
      "llm.encoder.layer.22.attention.self.key.bias: False\n",
      "llm.encoder.layer.22.attention.self.value.weight: False\n",
      "llm.encoder.layer.22.attention.self.value.bias: False\n",
      "llm.encoder.layer.22.attention.output.dense.weight: False\n",
      "llm.encoder.layer.22.attention.output.dense.bias: False\n",
      "llm.encoder.layer.22.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.22.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.22.intermediate.dense.weight: False\n",
      "llm.encoder.layer.22.intermediate.dense.bias: False\n",
      "llm.encoder.layer.22.output.dense.weight: False\n",
      "llm.encoder.layer.22.output.dense.bias: False\n",
      "llm.encoder.layer.22.LayerNorm.weight: False\n",
      "llm.encoder.layer.22.LayerNorm.bias: False\n",
      "llm.encoder.layer.23.attention.self.query.weight: False\n",
      "llm.encoder.layer.23.attention.self.query.bias: False\n",
      "llm.encoder.layer.23.attention.self.key.weight: False\n",
      "llm.encoder.layer.23.attention.self.key.bias: False\n",
      "llm.encoder.layer.23.attention.self.value.weight: False\n",
      "llm.encoder.layer.23.attention.self.value.bias: False\n",
      "llm.encoder.layer.23.attention.output.dense.weight: False\n",
      "llm.encoder.layer.23.attention.output.dense.bias: False\n",
      "llm.encoder.layer.23.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.23.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.23.intermediate.dense.weight: False\n",
      "llm.encoder.layer.23.intermediate.dense.bias: False\n",
      "llm.encoder.layer.23.output.dense.weight: False\n",
      "llm.encoder.layer.23.output.dense.bias: False\n",
      "llm.encoder.layer.23.LayerNorm.weight: False\n",
      "llm.encoder.layer.23.LayerNorm.bias: False\n",
      "llm.encoder.layer.24.attention.self.query.weight: False\n",
      "llm.encoder.layer.24.attention.self.query.bias: False\n",
      "llm.encoder.layer.24.attention.self.key.weight: False\n",
      "llm.encoder.layer.24.attention.self.key.bias: False\n",
      "llm.encoder.layer.24.attention.self.value.weight: False\n",
      "llm.encoder.layer.24.attention.self.value.bias: False\n",
      "llm.encoder.layer.24.attention.output.dense.weight: False\n",
      "llm.encoder.layer.24.attention.output.dense.bias: False\n",
      "llm.encoder.layer.24.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.24.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.24.intermediate.dense.weight: False\n",
      "llm.encoder.layer.24.intermediate.dense.bias: False\n",
      "llm.encoder.layer.24.output.dense.weight: False\n",
      "llm.encoder.layer.24.output.dense.bias: False\n",
      "llm.encoder.layer.24.LayerNorm.weight: False\n",
      "llm.encoder.layer.24.LayerNorm.bias: False\n",
      "llm.encoder.layer.25.attention.self.query.weight: False\n",
      "llm.encoder.layer.25.attention.self.query.bias: False\n",
      "llm.encoder.layer.25.attention.self.key.weight: False\n",
      "llm.encoder.layer.25.attention.self.key.bias: False\n",
      "llm.encoder.layer.25.attention.self.value.weight: False\n",
      "llm.encoder.layer.25.attention.self.value.bias: False\n",
      "llm.encoder.layer.25.attention.output.dense.weight: False\n",
      "llm.encoder.layer.25.attention.output.dense.bias: False\n",
      "llm.encoder.layer.25.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.25.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.25.intermediate.dense.weight: False\n",
      "llm.encoder.layer.25.intermediate.dense.bias: False\n",
      "llm.encoder.layer.25.output.dense.weight: False\n",
      "llm.encoder.layer.25.output.dense.bias: False\n",
      "llm.encoder.layer.25.LayerNorm.weight: False\n",
      "llm.encoder.layer.25.LayerNorm.bias: False\n",
      "llm.encoder.layer.26.attention.self.query.weight: False\n",
      "llm.encoder.layer.26.attention.self.query.bias: False\n",
      "llm.encoder.layer.26.attention.self.key.weight: False\n",
      "llm.encoder.layer.26.attention.self.key.bias: False\n",
      "llm.encoder.layer.26.attention.self.value.weight: False\n",
      "llm.encoder.layer.26.attention.self.value.bias: False\n",
      "llm.encoder.layer.26.attention.output.dense.weight: False\n",
      "llm.encoder.layer.26.attention.output.dense.bias: False\n",
      "llm.encoder.layer.26.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.26.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.26.intermediate.dense.weight: False\n",
      "llm.encoder.layer.26.intermediate.dense.bias: False\n",
      "llm.encoder.layer.26.output.dense.weight: False\n",
      "llm.encoder.layer.26.output.dense.bias: False\n",
      "llm.encoder.layer.26.LayerNorm.weight: False\n",
      "llm.encoder.layer.26.LayerNorm.bias: False\n",
      "llm.encoder.layer.27.attention.self.query.weight: False\n",
      "llm.encoder.layer.27.attention.self.query.bias: False\n",
      "llm.encoder.layer.27.attention.self.key.weight: False\n",
      "llm.encoder.layer.27.attention.self.key.bias: False\n",
      "llm.encoder.layer.27.attention.self.value.weight: False\n",
      "llm.encoder.layer.27.attention.self.value.bias: False\n",
      "llm.encoder.layer.27.attention.output.dense.weight: False\n",
      "llm.encoder.layer.27.attention.output.dense.bias: False\n",
      "llm.encoder.layer.27.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.27.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.27.intermediate.dense.weight: False\n",
      "llm.encoder.layer.27.intermediate.dense.bias: False\n",
      "llm.encoder.layer.27.output.dense.weight: False\n",
      "llm.encoder.layer.27.output.dense.bias: False\n",
      "llm.encoder.layer.27.LayerNorm.weight: False\n",
      "llm.encoder.layer.27.LayerNorm.bias: False\n",
      "llm.encoder.layer.28.attention.self.query.weight: False\n",
      "llm.encoder.layer.28.attention.self.query.bias: False\n",
      "llm.encoder.layer.28.attention.self.key.weight: False\n",
      "llm.encoder.layer.28.attention.self.key.bias: False\n",
      "llm.encoder.layer.28.attention.self.value.weight: False\n",
      "llm.encoder.layer.28.attention.self.value.bias: False\n",
      "llm.encoder.layer.28.attention.output.dense.weight: False\n",
      "llm.encoder.layer.28.attention.output.dense.bias: False\n",
      "llm.encoder.layer.28.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.28.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.28.intermediate.dense.weight: False\n",
      "llm.encoder.layer.28.intermediate.dense.bias: False\n",
      "llm.encoder.layer.28.output.dense.weight: False\n",
      "llm.encoder.layer.28.output.dense.bias: False\n",
      "llm.encoder.layer.28.LayerNorm.weight: False\n",
      "llm.encoder.layer.28.LayerNorm.bias: False\n",
      "llm.encoder.layer.29.attention.self.query.weight: False\n",
      "llm.encoder.layer.29.attention.self.query.bias: False\n",
      "llm.encoder.layer.29.attention.self.key.weight: False\n",
      "llm.encoder.layer.29.attention.self.key.bias: False\n",
      "llm.encoder.layer.29.attention.self.value.weight: False\n",
      "llm.encoder.layer.29.attention.self.value.bias: False\n",
      "llm.encoder.layer.29.attention.output.dense.weight: False\n",
      "llm.encoder.layer.29.attention.output.dense.bias: False\n",
      "llm.encoder.layer.29.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.29.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.29.intermediate.dense.weight: False\n",
      "llm.encoder.layer.29.intermediate.dense.bias: False\n",
      "llm.encoder.layer.29.output.dense.weight: False\n",
      "llm.encoder.layer.29.output.dense.bias: False\n",
      "llm.encoder.layer.29.LayerNorm.weight: False\n",
      "llm.encoder.layer.29.LayerNorm.bias: False\n",
      "llm.encoder.layer.30.attention.self.query.weight: False\n",
      "llm.encoder.layer.30.attention.self.query.bias: False\n",
      "llm.encoder.layer.30.attention.self.key.weight: False\n",
      "llm.encoder.layer.30.attention.self.key.bias: False\n",
      "llm.encoder.layer.30.attention.self.value.weight: False\n",
      "llm.encoder.layer.30.attention.self.value.bias: False\n",
      "llm.encoder.layer.30.attention.output.dense.weight: False\n",
      "llm.encoder.layer.30.attention.output.dense.bias: False\n",
      "llm.encoder.layer.30.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.30.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.30.intermediate.dense.weight: False\n",
      "llm.encoder.layer.30.intermediate.dense.bias: False\n",
      "llm.encoder.layer.30.output.dense.weight: False\n",
      "llm.encoder.layer.30.output.dense.bias: False\n",
      "llm.encoder.layer.30.LayerNorm.weight: False\n",
      "llm.encoder.layer.30.LayerNorm.bias: False\n",
      "llm.encoder.layer.31.attention.self.query.weight: False\n",
      "llm.encoder.layer.31.attention.self.query.bias: False\n",
      "llm.encoder.layer.31.attention.self.key.weight: False\n",
      "llm.encoder.layer.31.attention.self.key.bias: False\n",
      "llm.encoder.layer.31.attention.self.value.weight: False\n",
      "llm.encoder.layer.31.attention.self.value.bias: False\n",
      "llm.encoder.layer.31.attention.output.dense.weight: False\n",
      "llm.encoder.layer.31.attention.output.dense.bias: False\n",
      "llm.encoder.layer.31.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.31.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.31.intermediate.dense.weight: False\n",
      "llm.encoder.layer.31.intermediate.dense.bias: False\n",
      "llm.encoder.layer.31.output.dense.weight: False\n",
      "llm.encoder.layer.31.output.dense.bias: False\n",
      "llm.encoder.layer.31.LayerNorm.weight: False\n",
      "llm.encoder.layer.31.LayerNorm.bias: False\n",
      "llm.encoder.layer.32.attention.self.query.weight: False\n",
      "llm.encoder.layer.32.attention.self.query.bias: False\n",
      "llm.encoder.layer.32.attention.self.key.weight: False\n",
      "llm.encoder.layer.32.attention.self.key.bias: False\n",
      "llm.encoder.layer.32.attention.self.value.weight: False\n",
      "llm.encoder.layer.32.attention.self.value.bias: False\n",
      "llm.encoder.layer.32.attention.output.dense.weight: False\n",
      "llm.encoder.layer.32.attention.output.dense.bias: False\n",
      "llm.encoder.layer.32.attention.LayerNorm.weight: False\n",
      "llm.encoder.layer.32.attention.LayerNorm.bias: False\n",
      "llm.encoder.layer.32.intermediate.dense.weight: False\n",
      "llm.encoder.layer.32.intermediate.dense.bias: False\n",
      "llm.encoder.layer.32.output.dense.weight: False\n",
      "llm.encoder.layer.32.output.dense.bias: False\n",
      "llm.encoder.layer.32.LayerNorm.weight: False\n",
      "llm.encoder.layer.32.LayerNorm.bias: False\n",
      "llm.encoder.emb_layer_norm_after.weight: False\n",
      "llm.encoder.emb_layer_norm_after.bias: False\n",
      "llm.pooler.dense.weight: False\n",
      "llm.pooler.dense.bias: False\n",
      "llm.contact_head.regression.weight: False\n",
      "llm.contact_head.regression.bias: False\n",
      "pre_classifier.weight: True\n",
      "pre_classifier.bias: True\n",
      "classifier.weight: True\n",
      "classifier.bias: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torchmetrics.functional.classification import multilabel_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        loss = self.loss_fn(logits, batch[\"targets\"])\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss  # this is passed to the optimizer for training\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "        loss = self.loss_fn(logits, batch[\"targets\"])\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "        f1_score = multilabel_f1_score(\n",
    "            logits, batch[\"targets\"].type(torch.int), num_classes\n",
    "        )\n",
    "        self.log(\"val_f1_score\", f1_score, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        logits = self(batch)\n",
    "\n",
    "        f1_score = multilabel_f1_score(\n",
    "            logits, batch[\"targets\"].type(torch.int), num_classes\n",
    "        )\n",
    "        self.log(\"f1_score\", f1_score, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = ESMLightningModule(model, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(save_top_k=1, mode=\"max\", monitor=\"val_f1_score\")]\n",
    "logger = CSVLogger(save_dir=\"logs/\", name=\"esm_model_head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.strategies import FSDPStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = FSDPStrategy(\n",
    "    auto_wrap_policy = {\n",
    "        nn.TransformerEncoderLayer,\n",
    "        nn.TransformerDecoderLayer,\n",
    "    },\n",
    "    activation_checkpointing_policy = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy=<pytorch_lightning.strategies.fsdp.FSDPStrategy object at 0x7fd517790d00>)` is not compatible with an interactive environment. Run your code as a script, or choose a notebook-compatible strategy: `Trainer(strategy='ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m16-mixed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ml/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:400\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector \u001b[38;5;241m=\u001b[39m _DataConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_connector \u001b[38;5;241m=\u001b[39m \u001b[43m_AcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector \u001b[38;5;241m=\u001b[39m _LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector \u001b[38;5;241m=\u001b[39m _CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:166\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:610\u001b[0m, in \u001b[0;36m_AcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_configure_launcher()\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _IS_INTERACTIVE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer(strategy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy_flag\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m)` is not compatible with an interactive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m environment. Run your code as a script, or choose a notebook-compatible strategy:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `Trainer(strategy=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mddp_notebook\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m creation inside the worker function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m     )\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, XLAAccelerator) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, (SingleDeviceXLAStrategy, XLAStrategy)\n\u001b[1;32m    622\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy=<pytorch_lightning.strategies.fsdp.FSDPStrategy object at 0x7fd517790d00>)` is not compatible with an interactive environment. Run your code as a script, or choose a notebook-compatible strategy: `Trainer(strategy='ddp_notebook')`. In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    accelerator=\"cuda\",\n",
    "    precision=\"16-mixed\",\n",
    "    devices=4,\n",
    "    strategy=strategy,\n",
    "    logger=logger,\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.print(f\"Memory used: {torch.cuda.max_memory_allocated() / 1e9:.02f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "[rank: 0] Seed set to 0\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "[rank: 1] Seed set to 0\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Missing logger folder: logs/esm_model_head\n",
      "[rank: 2] Seed set to 0\n",
      "[rank: 3] Seed set to 0\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Missing logger folder: logs/esm_model_head\n",
      "Missing logger folder: logs/esm_model_head\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Missing logger folder: logs/esm_model_head\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | model   | FinetunedESM      | 654 M \n",
      "1 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "652 M     Non-trainable params\n",
      "654 M     Total params\n",
      "2,616.487 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 579, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 986, in _run\n    results = self._run_stage()\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1030, in _run_stage\n    self._run_sanity_check()\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1059, in _run_sanity_check\n    val_loop.run()\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py\", line 182, in _decorator\n    return loop_run(self, *args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py\", line 135, in run\n    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py\", line 396, in _evaluation_step\n    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 411, in validation_step\n    return self._forward_redirection(self.model, self.lightning_module, \"validation_step\", *args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 642, in __call__\n    wrapper_output = wrapper_module(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1523, in forward\n    else self._run_ddp_forward(*inputs, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1359, in _run_ddp_forward\n    return self.module(*inputs, **kwargs)  # type: ignore[index]\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 635, in wrapped_forward\n    out = method(*_args, **_kwargs)\n  File \"/tmp/ipykernel_2842/3126010323.py\", line 19, in validation_step\n    logits = self(batch)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_2842/3126010323.py\", line 10, in forward\n    return self.model(batch)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_2842/2619312275.py\", line 35, in forward\n    token_embeddings = self.llm(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 914, in forward\n    encoder_outputs = self.encoder(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 619, in forward\n    layer_outputs = layer_module(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 509, in forward\n    self_attention_outputs = self.attention(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 443, in forward\n    self_outputs = self.self(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 347, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.43 GiB. GPU 1 has a total capacity of 22.19 GiB of which 16.56 GiB is free. Including non-PyTorch memory, this process has 5.63 GiB memory in use. Of the allocated memory 4.81 GiB is allocated by PyTorch, and 369.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlightning_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(end\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/multiprocessing.py:144\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m process_context \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mstart_processes(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapping_function,\n\u001b[1;32m    138\u001b[0m     args\u001b[38;5;241m=\u001b[39mprocess_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we will join ourselves to get the process references\u001b[39;00m\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mprocess_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    147\u001b[0m worker_output \u001b[38;5;241m=\u001b[39m return_queue\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/opt/conda/envs/ml/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:158\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    156\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    157\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 579, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 986, in _run\n    results = self._run_stage()\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1030, in _run_stage\n    self._run_sanity_check()\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\", line 1059, in _run_sanity_check\n    val_loop.run()\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py\", line 182, in _decorator\n    return loop_run(self, *args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py\", line 135, in run\n    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py\", line 396, in _evaluation_step\n    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 411, in validation_step\n    return self._forward_redirection(self.model, self.lightning_module, \"validation_step\", *args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 642, in __call__\n    wrapper_output = wrapper_module(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1523, in forward\n    else self._run_ddp_forward(*inputs, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1359, in _run_ddp_forward\n    return self.module(*inputs, **kwargs)  # type: ignore[index]\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py\", line 635, in wrapped_forward\n    out = method(*_args, **_kwargs)\n  File \"/tmp/ipykernel_2842/3126010323.py\", line 19, in validation_step\n    logits = self(batch)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_2842/3126010323.py\", line 10, in forward\n    return self.model(batch)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_2842/2619312275.py\", line 35, in forward\n    token_embeddings = self.llm(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 914, in forward\n    encoder_outputs = self.encoder(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 619, in forward\n    layer_outputs = layer_module(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 509, in forward\n    self_attention_outputs = self.attention(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 443, in forward\n    self_outputs = self.self(\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/envs/ml/lib/python3.10/site-packages/transformers/models/esm/modeling_esm.py\", line 347, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 21.43 GiB. GPU 1 has a total capacity of 22.19 GiB of which 16.56 GiB is free. Including non-PyTorch memory, this process has 5.63 GiB memory in use. Of the allocated memory 4.81 GiB is allocated by PyTorch, and 369.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "trainer.fit(\n",
    "    model=lightning_model, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    ")\n",
    "end = time.time()\n",
    "print(f\"Training Time: {(end-start)/60:.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
