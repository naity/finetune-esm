{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:15:13,970\tINFO worker.py:1715 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bb978150854a8988ea733a2ef3f16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.10.13</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.9.2</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.10.13', ray_version='2.9.2', ray_commit='fce7a361807580953364e2da964f9498f3123bf9', protocol_version=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object_store_memory': 8160347750.0,\n",
       " 'node:172.30.66.101': 1.0,\n",
       " 'node:__internal_head__': 1.0,\n",
       " 'memory': 16320695502.0,\n",
       " 'CPU': 28.0,\n",
       " 'GPU': 1.0,\n",
       " 'accelerator_type:G': 1.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/cafa5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92210, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A021WW32</td>\n",
       "      <td>MFYEHIILAKKGPLARIWLAAHWDKKITKAHVFETNIEKSVEGILQ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A023FFD0</td>\n",
       "      <td>MHSTIVYACLLALAVFVALHGTPLAALAENGEGTTQPDYDNSTDYY...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A023GPJ3</td>\n",
       "      <td>MDRDAEEGRPLSLVNRRPSISAPISGRKSAPASAAAAVAAAAAAAA...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A023GPK8</td>\n",
       "      <td>MSTIKLLIIGQLWLSIGLISGDDSLDTREGVDLVLKCRFTEHYDST...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Entry ID                                           Sequence  Index\n",
       "0  A0A009IHW8  MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENA...      0\n",
       "1  A0A021WW32  MFYEHIILAKKGPLARIWLAAHWDKKITKAHVFETNIEKSVEGILQ...      1\n",
       "2  A0A023FFD0  MHSTIVYACLLALAVFVALHGTPLAALAENGEGTTQPDYDNSTDYY...      2\n",
       "3  A0A023GPJ3  MDRDAEEGRPLSLVNRRPSISAPISGRKSAPASAAAAVAAAAAAAA...      3\n",
       "4  A0A023GPK8  MSTIKLLIIGQLWLSIGLISGDDSLDTREGVDLVLKCRFTEHYDST...      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(data_path / \"train_bp_top500_seqs.parquet\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üç≤ Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîç EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length min: 3, max: 35375\n"
     ]
    }
   ],
   "source": [
    "seq_lens = df[\"Sequence\"].str.len()\n",
    "print(f\"Sequence length min: {seq_lens.min()}, max: {seq_lens.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41900    3\n",
       "Name: Sequence, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the sequence of length 3\n",
    "seq_lens.loc[seq_lens == 3]\n",
    "\n",
    "# it's a peptide: https://www.uniprot.org/uniprotkb/P84761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Sequence Length')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACF0AAAZGCAYAAAB3c0zkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAC4jAAAuIwF4pT92AAEAAElEQVR4nOzdaZRW1Znw77smCgqUUSZBEIIymRCj0vqqreAQwJUgDpCItuirolHTtrE1MXFug6IrIbY4JDi0EDEm6nItcIrRNiZpBIUYcEAFbBQoQUSlqqCqqPp/8JW/DzXw1KakBq/rk2dz9rl3IYd88Jfnyamurq4OAAAAAAAAAAAaJLepDwAAAAAAAAAA0BKJLgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEuQ39QGoW3l5ebz77ruxZs2aWLduXWzevDm2bt0aRUVF0aFDh+jTp08MHz48OnTo0OizN23aFEuWLIn//d//jZKSkmjTpk107949hg4dGgMHDmz0eRERJSUlsWTJkli1alV88sknkZ+fH926dYv9998/hgwZEjk5OY0+s7y8PJYsWRIrVqyIjz/+OHJycqJz584xaNCgOOCAAyIvL6/RZwIAAAAAAADQOogumpF169bFCy+8EK+88kosXbo0Vq5cGZWVlfXuycnJieHDh8dJJ50U3/3ud6OoqGiXzrBo0aK48847469//Wts27at1nv69esXkydPju9973tRUFCwS/MiIt58882444474o9//GNUVFTUek/37t1j4sSJcdZZZ+3yzxgR8d5778Wdd94Z8+bNi9LS0lrv6dixY0yYMCHOPffc6NKlyy7PBAAAAAAAAKB1yamurq5u6kPwmZkzZ8aMGTOS9/fu3Tuuueaa+Od//ucG762oqIif//znMWfOnKz37LfffnHbbbdF//79GzwvIqK6ujruuOOOuP3223cal3yud+/eMWPGjPj617+eNDMi4uGHH44bbrghtmzZktX9nTp1iptvvjnp9xUAAAAAAACA1iu3qQ9A41mzZk2cd9558eCDDzZoX2VlZfzwhz9sUHAREbF8+fL43ve+F++8806D9n3uuuuuixkzZmQdXER89jOefvrpsXDhwqSZv/nNb+KnP/1p1sFFxGdftTJ16tSYP39+0kwAAAAAAAAAWiefdNGMfPGTLvr27RsHH3xwfP3rX4999903+vTpEx06dIj8/PwoKSmJFStWxMKFC+ORRx6JtWvX1njWr3/96zjyyCOzmnvTTTfFPffck7HWuXPnmDx5chxzzDHRq1ev2LRpUyxdujTuu+++ePXVVzPu3WeffeLRRx+NDh06ZP2zzpkzJ6677rqMtaKiopg0aVKMGTMm+vbtGyUlJbF8+fKYPXt2/OUvf8m4t1OnTvHYY49Fr169sp753HPPxfnnnx9f/CNfUFAQ48ePjxNPPDH69+8fFRUVsWLFipg7d248/fTTGfe2adMm5s6dG8OGDct6JgAAAAAAAACtl+iiGXniiSdizZo1ceyxx8Y+++yT1Z4tW7bEzTffXONTKvbee+946qmnoqCgoN79b7zxRowfPz4jLhg0aFDMmjUrevToUeP+6urq+PnPfx73339/xvpZZ50Vl19+eVZn3rBhQxxzzDFRVla2fa1Hjx4xa9asGDRoUK177rnnnrj55pszznn88cfHr371q6xmbt26NY499tgoLi7evrbHHnvEzJkz45BDDql1z7x58+Lyyy+PioqK7WvDhw+PP/zhD1nNBAAAAAAAAKB18/UizciYMWPi7LPPzjq4iIho27ZtXHXVVTFu3LiM9ffffz/++te/7nT/L3/5y4yQoX379vHrX/+61uAiIiInJyd+8pOfxOjRozPWf/vb32YEDfW58847M4KLvLy8mDlzZp3BRcRnUcfpp5+esfb000/HsmXLsppZ2/mmTZtWZ3ARETFu3Lj40Y9+lLG2dOnSeOaZZ7KaCQAAAAAAAEDrJrpoJS655JIaay+++GK9e15//fV47rnnMtYuvvjirL6y45prrom2bdtuv96yZUvMmjVrp/s2bNgQc+fOzVg77bTTYvjw4Tvde8kll0T37t23X1dXV8fMmTN3uq+ioiLuvvvujLXRo0fHMcccs9O9Z5xxRgwdOjRj7fbbb9/pPgAAAAAAAABav/ymPgCNo2/fvtG3b99YvXr19rV169bVu+eJJ57IuC4qKoqTTz45q3ndu3eP4447Lh5//PHta0899VT85Cc/qXffs88+m/F1HTk5OXHGGWdkNbOoqChOOumkuOOOO7avvfDCC1FSUhLt27evc9+CBQti48aNGWvZzszNzY3vf//78dOf/nT72uuvvx7vvvtu9OvXL6tnNKWqqqqMTxX5XH5+fuTk5DTBiQAAAAAAAAAaR3V1dVRWVtZYb9euXeTm7p7PoBBdtCLdunXLiC5KS0vrvf/ZZ5/NuD722GOjQ4cOWc+bMGFCRnSxbt26WLp0ab2fWrHjzG9961vRt2/fBs38YnRRXl4eL774Yhx//PFZz+zdu3eMHDky65njxo2L66+/PrZu3ZrxzLPOOivrZzSVsrKyeOONN5r6GAAAAAAAAAC7zeDBg+v9P+43Jl8v0op88sknGdddunSp8941a9bE22+/nbF2yCGHNGjeN7/5zSgoKMhYe/755+u8v7y8PP72t7/t0sx99tknevbsmfXMiM8+DeOLDj744AZ9ykNRUVGNkGRnMwEAAAAAAABo/UQXrcTGjRtj5cqVGWvf+MY36rz/zTffrLF24IEHNmhm27ZtY+jQoRlry5cvr/P+VatWRXl5+S7NrG1PfTNLSkrivffe260zAQAAAAAAAPhqEF20EnfeeWdUVVVtvy4sLIyxY8fWef+KFSsyrvPz86N///4Nnjtw4MCM6x3Dj/pm1ra/pcz86KOPYtOmTQ1+DgAAAAAAAACth+iihauqqopf//rXcf/992esT506td6vF3nnnXcyrnv06BG5uQ3/47DjV32sWrUqtm3bltXMvLy86NGjxy7PLCkpieLi4qxmRkT06tVrl2fW9WwAAAAAAAAAvjrym/oANExVVVWUlJTE6tWr4+WXX44//OEP8frrr2fcM378+Jg6dWq9z/nggw8yrmuLCrLRu3fvjOvy8vLYtGlTdO3adacz99prr8jLy9vlmRERxcXFtQYcO87MyclJCj3qmtnc5efX/op/7Wtfi4KCgt18mpavsrIy3nrrrYy1QYMG1fn7DDQP3l1omby70DJ5d6Fl8u5Cy+TdhZbL+wstk3e3eaqoqIi33367xvru/PfiT0Azd/bZZ8eLL76Y1b2dOnWKiy++OE477bSd3ltaWppx3aFDh6TztW/fvtZn1xZdNNbM2vaVlJTUeu+OM9u2bZsUG9Q2c8dnN0c5OTm1rtf2Fw9pdvwfV6Bl8O5Cy+TdhZbJuwstk3cXWibvLrRc3l9omby7zVdd/530yyC6aAXatWsX559/fkyePLnWCKI2tcUIKWrbl20AUVhYmDSztn11BRBNMRMAAAAAAACAr4bcpj4Au66srCx+8YtfxAUXXBALFizIes8XtWnTJml2bdFFXTHCjjNTA4jmPhMAAAAAAACArwafdNHMjR07NoYMGbL9urKyMj755JNYuXJlvPbaa7Fly5aIiKiuro7/+Z//iQULFsS//Mu/xBVXXLFbPzIFAAAAAAAAAL5qRBfN3EknnVTnr5WWlsbjjz8eM2bMiI0bN0bEZ/HFfffdFxUVFXHVVVfVubddu3YZ1+Xl5Unn+zz6+KKioqKsZm7durVVzmwJhgwZEgUFBU19jBansrIyXnvttYy1oUOHRn6+v0qhOfPuQsvk3YWWybsLLZN3F1om7y60XN5faJm8u81TRUVFvP766016Bn8CWrCioqKYNGlSHHfccXHWWWdl/GGaM2dOHH744TFq1Kg6935RbVFBNmrb1759+6xmpgYQte2rK4BoipktQX5+vuiikfi9hJbJuwstk3cXWibvLrRM3l1omby70HJ5f6Fl8u42verq6qY+QuQ29QHYdV26dInf/OY3seeee2as/+d//mede3YMBjZv3pw0u6SkZKfPbuyZte3LNvTYsmVLVFZWNsrMlhxdAAAAAAAAALDrRBetRLdu3eJf/uVfMtaWLVsWK1eurPX+7t27Z1yvW7cuae7atWszrtu0aROdOnXKaub69etj27ZtuzyztmfXtV5dXZ30szZkJgAAAAAAAABfDaKLVmT06NE11v7+97/Xeu+AAQMyrouLi6OqqqrBM3eMEfr37x95eXlZzdy2bVsUFxfv8sz27dtHz549s5pZ2/6UmRERAwcObPBzAAAAAAAAAGg9RBetSN++fWusbdiwodZ7dwwGKisrY9WqVQ2euWLFiozrfffdt857a4sU3nnnnS91Zm3RRWPM7Ny5c3Tu3LnBzwEAAAAAAACg9RBdtCL5+fk11nJycmq9d//996+xtnjx4gbN27JlSyxbtixjbb/99qvz/v79+0ebNm12aWZExCuvvJL1zA4dOkSfPn12eebLL7+c9UwAAAAAAAAAvhpEF63I+vXra6x17dq11nt79+4dX/va1zLWXnrppQbNW7x4cVRUVGSsHXXUUXXe36ZNmzj00EN3aebq1atrfNVHfTMjIo488siM64ULFzZoZllZWSxdurRBMwEAAAAAAABo/UQXrcj//M//1Fjb8VMevmj06NEZ108//XSUlJRkPe+xxx7LuO7Zs2cMHz683j07zly0aFGsXr0665mPPvpoxnWbNm3i8MMPb9DM999/PxYsWJD1zPnz58fWrVvrfSYAAAAAAAAAXz2ii1aiqqoqfvvb32asderUKUaMGFHnnm9/+9sZ16WlpfGHP/whq3nr16+PJ598MmPt+OOP3+m+0aNHR0FBwfbr6urqmD17dlYzy8rK4ve//33G2pFHHhnt27evd9/IkSOjS5cuGWsPPPBAVjOrqqpizpw5GWtDhgyJfv36ZbUfAAAAAAAAgNZLdNFMFBcXR3V1dfL+X/7yl/Haa69lrB1//PGRn59f556hQ4fG0UcfnbH2q1/9KoqLi3c679prr40tW7Zsvy4sLIyzzz57p/u6desWEydOzFibPXt2jbPX5pe//GXG2XJycuKCCy7Y6b6CgoI455xzMtaeeeaZeO6553a6d/bs2bFs2bKMtR/84Ac73QcAAAAAAABA6ye6aCZ+97vfxXe+852YN29eRsywMx999FFcccUVcdddd2Ws77HHHnHxxRfvdP+//uu/Rk5OzvbrTz/9NP7v//2/dYYX1dXVMW3atHjmmWcy1k877bTo0aNHVmeeOnVqtGvXbvt1ZWVlXHDBBfH222/Xuee+++6L+++/P2PtuOOOi2HDhmU1s7bz/fu//3ssWrSozj3z58+P6dOnZ6wNHz48jj322KxmAgAAAAAAANC61f0xCOx2y5cvj3/7t3+LoqKiOOqoo+Ib3/hGDBkyJHr16hUdOnSItm3bRklJSXz44YfxxhtvxF/+8pf44x//GKWlpRnPyc3Njeuuuy66deu205mDBw+OKVOmxD333JNxjvHjx8fpp58eo0aNil69esXHH38cS5cujfvuuy/+/ve/Zzxjn332adCnP+y1117xox/9KK6//vrta2vXro1TTz01Jk2aFGPHjo0+ffpEaWlpvPnmmzF79ux48cUXM57RqVOnuOKKK7KeWVhYGNdcc02cf/7529c++eSTOPPMM2PChAkxfvz46N+/f1RUVMSKFSvioYceiieffDLj00fatGkT1113XdYzAQAAAAAAAGjdRBfNUGlpacyfPz/mz5/f4L0FBQVxww03xNixY7Pec+mll8bKlSszvm5j48aNMWPGjJgxY0a9ezt37hx33HFHdOjQoUHnnDx5crz99tvx4IMPbl8rKSmJWbNmxaxZs+rd27Zt27jtttuid+/eDZo5atSouPTSS+PWW2/dvlZRUREPPfRQPPTQQ/Xuzc3NjWnTpmX9yRoAAAAAAAAAtH6+XqSZ+OJXfKT65je/GY8++miMHz++Qfvy8/Pjtttui+9973sN2jdo0KCYO3dufO1rX2vQvs9dffXVcdFFF0VeXl7We3r16hX/9V//FYccckjSzHPPPTduuOGGaNu2bdZ7OnbsGDNnzoxx48YlzQQAAAAAAACgdRJdNBPnnXde3HfffXHWWWfF17/+9SgoKMhqX9euXWPChAkxZ86cmDt3bgwaNChpfkFBQVxzzTUxZ86cOPzwwyM3t+4/Gn379o2f/OQn8eijj0b//v2T5kV8FppceOGF8cgjj8S3v/3ten/mvfbaKy666KKYN29efOMb30ieGRFxyimnxLx58+Lkk0+Odu3a1Xlfx44d48wzz4wnn3wyjj766F2aCQAAAAAAAEDr4+tFmomCgoI49NBD49BDD42IiPLy8li5cmW89957UVxcHCUlJVFRURFFRUXRoUOH6Nq1awwZMiR69uzZqOc46KCDYtasWfHRRx/FkiVL4n//93+jpKQkCgoKonv37jFs2LDkT7aoy+DBg2PGjBmxefPmWLx4cbz77rvx6aefRl5eXnTt2jUGDx4cQ4cObZRPA/lcnz594j/+4z/iqquuiiVLlsQ777wTn3zySeTk5ETnzp1j0KBBccABB0R+vlcEAAAAAAAAgNr5L8rNVJs2bWL//feP/fffv0nmd+7cebd/ukOHDh3iiCOOiCOOOGK3zSwsLIyRI0fGyJEjd9tMAAAAAAAAAFoHXy8CAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAHQRG6Z/XJTHwEAAAAAAADYBaILgCZSXrGtqY8AAAAAAAAA7ALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBQAAAAAAAABAAtEFAAAAAAAAAEAC0QUAAAAAAAAAQALRBcBudsvsl5v6CAAAAAAAAEAjEF0A7GblFdua+ggAAAAAAABAIxBdAOxmBfm5MWPu4qY+BgAAAAAAALCLRBcATcCnXQAAAAAAAEDLJ7oAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AGgiBfm5ccvsl5v6GAAAAAAAAEAi0QVAEyqv2NbURwAAAAAAAAASiS4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAHajGXMXN/URAAAAAAAAgEYiugDYjcortjX1EQAAAAAAAIBGIroAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6APiS3TL75aY+AgAAAAAAAPAlEF0AfMnKK7Y19REAAAAAAACAL4HoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegC4Es0Y+7ipj4CAAAAAAAA8CURXQB8icortjX1EQAAAAAAAIAviegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAqAJFeTnxi2zX27qYwAAAAAAAAAJRBcATay8YltTHwEAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEiQ39QHoH7r1q2L5cuXx9q1a+Pjjz+OiIiOHTtG165d44ADDogePXo08QkbT2VlZSxdujTeeuut+Oijj6K6ujo6duwYAwYMiBEjRkSbNm0afWZ1dXW8/vrr8eabb8aGDRuisrIy9txzz+jfv3+MGDEi2rdv3+gzAQAAAAAAAGgdRBfNzIYNG+JPf/pT/O1vf4sFCxbEhx9+WO/9ffv2jZNPPjlOPfXU6NKlS4PnnX766fHSSy+lHne7V155JTlQ2LhxY9x9993xyCOPbA9LdlRUVBTjxo2LqVOnRp8+fXblqBERUVJSEvfee2/MnTs31q9fX+s9BQUFccwxx8T5558f+++//y7PBAAAAAAAAKB18fUizcQ//vGPOOOMM+KII46In/3sZzF//vydBhcREatXr45f/OIXccwxx8Tvf//73XDSxvX888/HmDFj4t57760zuIiIKC0tjYcffjhOOOGEXf45//73v8e4cePitttuqzO4iIioqKiIJ554IiZMmBB33HHHLs0EAAAAAAAAoPURXTQTS5cujQULFkRVVVXS/pKSkrjyyivj6quvbuSTfXnmzZsX559/fmzatCnrPWVlZXHllVfGrFmzkmYuXLgwzjjjjFi7dm3WeyorK+OXv/xlXHfddUkzAQAAAAAAAGidfL1IM9avX7847LDD4pBDDomBAwdG165do7CwMNavXx+LFy+O3/3ud7FkyZKMPXPnzo2uXbvGxRdfnDTzn//5n2O//fZr8L6CgoIG3b9s2bK44oorMiKT3NzcOO6442LSpEkxYMCAyMvLi1WrVsUjjzwSjz/+eFRUVGy/d/r06TFgwIA4+uijs565du3auPDCC2PLli0Z64cffnhMnjw59ttvv2jXrl289957MW/evPjd734XpaWl2++bM2dODBw4ME477bQG/awAAAAAAAAAtE6ii2YmPz8/xo4dG6ecckoccsghtd6zxx57xIABA+Kkk06Khx56KK6//vqMIOGuu+6KMWPGxKBBgxo8/9vf/nZMmDAh+fzZ+tnPfhbl5eXbrwsKCuLmm2+OsWPHZtzXrVu3OOigg+K73/1u/OAHP4hPP/00IiKqq6vj6quvjsMOOywKCwuzmnnjjTdmfKpGTk5OXHHFFXHmmWdm3NelS5f4+te/HhMmTIhzzjkniouLt//a9OnT4/jjj49u3bo18CcGAAAAAAAAoLXx9SLNRG5ubpxwwgkxf/78mD59ep3BxY4mTpwY1157bcZaZWVl3H777V/GMRvF008/HcuWLctYu+yyy2oEF180cuTImDZtWsZacXFxPPjgg1nNXLp0aTz99NMZa2eccUaN4OKL9t9//5g5c2bk5eVtXysrK4s777wzq5kAAAAAAAAAtG6ii2bi5JNPjltvvTX69evX4L0nnXRSjUjjhRdeyPgkieZkxyBk2LBhcfrpp+903zHHHBOjR4/OWLv77rszPuWjLjNnzsy47t69e1xyySU73Td8+PAaXyfy0EMPxYcffrjTvQAAAAAAAAC0bqKLZuKLn6aQYvz48RnXJSUl8eabb+7SM78MK1eujDfeeCNj7bTTTovc3Oz+KO4YZ3z44YexcOHCevds3rw5XnjhhYy1U045Jdq1a5fVzMmTJ0dOTs726/Ly8vjTn/6U1V4AAAAAAAAAWi/RRSsxePDgGmvr169vgpPU79lnn824LiwsjDFjxmS9/5/+6Z+iV69e9T5zR3/+859rfBrGiSeemPXMfv36xYEHHtigmQAAAAAAAAC0fqKLVqJt27Y11srKyprgJPXb8RMnDjjggCgqKsp6f05OThx88MEZa88//3yDZvbq1Sv69u2b9cyIqPH1LX/961+b7de3AAAAAAAAALB7iC5aiTVr1tRY69KlSxOcpH47fuXJjp8gkY0d97z//vtRWlq6W2du3bo13n333QY/BwAAAAAAAIDWI7+pD0DjWLhwYY21ffbZp8HPqa6ujuXLl8fSpUtjw4YNUVZWFh07doxOnTrFgAEDYtiwYZGXl5d0xo0bN8amTZsy1gYOHNjg5+y4p7q6OlasWBHDhw+v9f6VK1dmXA8YMGCXZ0ZErFixIgYNGtTgZwEAAAAAAADQOoguWoFt27bF448/nrE2cODA2HvvvRv8rKuuuioqKyvr/PX27dvH4YcfHmeffXZ84xvfaNCzV6xYUWOtV69eDT5jbXvqii7Wrl1b41Mwevfu3eCZPXr0iNzc3KiqqsqYCQAAAAAAAMBXl68XaQUefvjhWLt2bcba2LFjk55VX3AREVFSUhJPPfVUnHrqqTF16tTYuHFj1s/+4IMPaqylRBc9e/aMnJycjLXi4uIvdWZ+fn7stddeWc0EAAAAAAAA4KvBJ120cOvWrYtbbrklY61jx44xefLkL332c889FyeeeGLcddddMXjw4J3eX1JSUmOtQ4cODZ5bUFAQhYWFsWXLlu1rO36aRX3r7du3b/DMiM/O+sXQoq6ZLUFlZWWNcIWdqy1K2lmoVB1VkZ8fMf2BhfGvk0ZEdVTVek9FRUWjnRPIlPLuAk3Puwstk3cXWibvLrRM3l1ouby/0DJ5d5un5vDvQHTRglVWVsall14an376acb6JZdcEp06dWrQs/r37x9HH310fPOb34xBgwZFt27doqioKDZv3hwffPBBvPLKKzF//vxYsGBBxr5169bFueeeGw8//HD06NGj3hm1RQqFhYUNOufn2rZtm1V0UVvo0bZt2+SZX9SSo4vXX3+9qY/Qarz22mt1/lpubm6UlpZF5ESUV2yL1157bfv1F5VXbIulS5dmfH0N8OWq790Fmi/vLrRM3l1omby70DJ5d6Hl8v5Cy+TdJUJ00aLdeOONsWjRooy1ww8/PCZNmpT1M0aNGhWXXHJJHHjggbX+eqdOnaJTp06x3377xaRJk2LBggVx2WWXZXziQ3Fxcfzbv/1bzJkzp95ZZWVlNdZSo4sd99UVQDTFTPiiNvm5UbGtuqmPAQAAAAAAAHwJcpv6AKR54IEHakQOPXv2jOnTpzfoayOmTJlSZ3BRm5EjR8bvf//76N27d8b6okWL4vnnn8/6OQAAAAAAAADQ0okuWqB58+bFjTfemLG2xx57xF133RVdunT50ud37949ZsyYUSPuuOeee+rd165duxprW7duTTrDjvuKioqazUwAAAAAAAAAvhp8vUgL88ILL8Tll18eVVVV29fatm0bd955ZwwePHi3nePrX/96HHvssfH0009vX3vllVeitLS0zhihtvWtW7dG+/btGzx/y5YtO312RNT67B33NvbMlmDIkCFRUFDQ1MdocSorK2t8N9fQoUMjP7/uv0qff+PvkV9ZFfkFVTF06NB46tXFNe4pKKiK4cOHN/p5gc+kvLtA0/PuQsvk3YWWybsLLZN3F1ou7y+0TN7d5qmioiJef/31Jj2DPwEtyKJFi+Liiy+OioqK7WsFBQUxY8aMOOigg3b7eY4//viM6KKioiIWL14c/+f//J9a768tgNi8eXODP52joqIi60+dqG29pKSkQfM+t3nz5qxmtgT5+fmii0ays9/LnMiNnIjIic/e15xaPmDo818Ddh9/D0LL5N2Flsm7Cy2TdxdaJu8utFzeX2iZvLtNr7q6uqmP4OtFWoqlS5fGeeedF2VlZdvXcnNz46abboqjjjqqSc40YsSIGmvFxcV13t+9e/caa2vXrm3w3HXr1tV4eWp7dmPOrKysjPXr12c1EwAAAAAAAICvBtFFC/DWW2/F2WefXeOTFq699toYN25cE50qomvXrjXWNm7cWOf9AwYMqLGWEkDUtmfgwIG13tuzZ88an0ixZs2aBs8sLi7O+EqX+mYCAAAAAAAA8NUgumjm3n333ZgyZUps2rQpY/2KK66IU089tWkO9f/U9lEtOTk5dd7fpUuX6NSpU8baO++80+C5K1asqDFz3333rfXe2n5tx/0pMyNqj0gAAAAAAAAA+OoQXTRja9eujSlTptT4WouLLroopkyZ0kSn+v99+OGHNda6dOlS7579998/43rx4sUNnvvyyy9nXO+9997Rvn373TqzsLAw+vXr1+DnAAAAAAAAANB6iC6aqQ0bNsSZZ54Z77//fsb6WWedFRdeeGETnSpTbfHCXnvtVe+eI488MuP6H//4R5SVlWU9s7q6OhYtWpSxdtRRRzVo5po1a2L16tVZz4yIWLhwYcb1YYcdFm3atGnQMwAAAAAAAABoXUQXzdCmTZtiypQpsWrVqoz1iRMnxuWXX940h6rFE088kXFdUFAQI0aMqHfP6NGjM663bNlS4zn1WbBgQaxZs6beZ+7oiCOOiIKCgoy1xx57LOuZq1evrvFJFzubCQ1RkJ8bt8x+eec3AgAAAAAAAM2K6KKZKSkpiXPOOSeWL1+esf6d73wnrr322iY6VU2LFy+OP/3pTxlr3/zmN6NDhw717tt3331j8ODBGWuzZ8+O6urqrObOnj0747pLly5x8MEH17unQ4cONT7t4uGHH44tW7ZkPfOL52vTpk2MGjUqq72QrfKKbU19BAAAAAAAAKCBRBfNyNatW2Pq1Knx6quvZqwfd9xxMW3atMjJyWm0WZs3b47Nmzcn7V27dm1cfPHFNdanTJmS1f4LLrgg43rZsmUxZ86cne579tln45lnnslYO++882p8ikVtzj///Izr4uLimDFjxk73LVu2rEboMXHixOjatetO9wIAAAAAAADQuokumonKysr44Q9/GC+99FLG+pFHHhm33npr5OXlNeq81atXx6hRo+I///M/o7i4OOt9f/7zn+Pkk0+ODz74IGP9W9/6Vtaf/nD88cfHsGHDMtZuuummePLJJ+vc89JLL8UVV1yRsdajR4/43ve+l9XMAw44II477riMtXvvvTfuv//+Ove89dZbccEFF0RlZeX2tXbt2sXUqVOzmgkAAAAAAABA65bf1AfgM7fddls899xzGWv5+fnRr1+/+NWvfpX0zGHDhsWYMWPq/PWPP/44brvttrj99tvjwAMPjEMPPTSGDBkS/fv3jz333DOKioqipKQkPvjgg3jllVdi3rx5sWTJkhrP6dmzZ/ziF79o0Nmuu+66mDRpUlRUVERERHl5eVxyySXx1FNPxcSJE2PAgAGRl5cXq1atikcffTQee+yx7fdGROTk5MS1114bhYWFWc/88Y9/HAsWLIiPP/44IiKqq6vjxhtvjD//+c8xefLk2G+//aJdu3bx3nvvxfz582Pu3LlRWlqa8YzLLrssunXr1qCfFQAAAAAAAIDWSXTRTNT2aROVlZXxwAMPJD/zxBNPrDe6+FxVVVUsWrQoFi1a1OAZe++9d9x1113Ro0ePBu0bPnx4TJs2LS677LKoqqrafo758+fH/Pnzd7r/0ksvjaOPPrpBM3v37h233XZbnHvuubFly5bt63/+85/jz3/+8073f//734/TTjutQTMBAAAAAAAAaL18vQhJcnJyYvz48fH444/HoEGDkp5xwgknxO233x4dO3bMek/btm3jhhtuiHPOOSdp5siRI+P++++Pnj17Zr0nLy8vLr744rjqqquSZgIAAAAAAADQOvmki6+offfdN2699dZYsGBBLF68OFasWBHbtm3b6b699947Ro8eHZMnT45+/frt8jlGjRoVTz75ZNx1113xyCOPxCeffFLrfe3atYtx48bF+eefH3369NmlmSNGjIj58+fHvffeG3Pnzo3169fXel9BQUGMHj06Lrjggth///13aSYAAAAAAAAArY/oopmYNm1aTJs2bbfNa9u2bZxwwglxwgknRETE1q1bY+XKlfH+++/HBx98ECUlJbF169YoKiqKPffcM7p06RLDhg2L7t27N/pZunTpEj/+8Y/jsssui1dffTXefvvt+Oijj6K6ujr23HPPGDhwYIwYMSIKCwsbbWb79u3jwgsvjB/84Afx2muvxRtvvBEffvhhbNu2LfbYY4/o379/jBgxIjp06NBoMwEAAAAAAABoXUQXREREYWFhDB48OAYPHtxkZ8jPz48DDzwwDjzwwN02MycnJ4YNGxbDhg3bbTMBAAAAAAAAaB1ym/oAAAAAAAAAAAAtkegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCYDcoyM+NGXMXN/UxAAAAAAAAgEYkugDYTcortjX1EQAAAAAAAIBGJLoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugBoZm6Z/XJTHwEAAAAAAADIgugCoJkpr9jW1EcAAAAAAAAAsiC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AGhGZsxd3NRHAAAAAAAAALIkugBoRsortjX1EQAAAAAAAIAsiS4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAJqZgvzcuGX2y019DAAAAAAAAGAnRBcAzVB5xbamPgIAAAAAAACwE6ILAAAAAAAAAIAEogsAAAAAAAAAgASiC4BmoCA/N2bMXdzUxwAAAAAAAAAaQHQB0EyUV2xr6iMAAAAAAAAADSC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AGgmCvL9lQwAAAAAAAAtif/CBwAAAAAAAACQQHQB8CWZMXdxUx8BAAAAAAAA+BKJLgC+JOUV25r6CAAAAAAAAMCXSHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AQAAAAAAAACQQHQBAAAAAAAAAJBAdAEAAAAAAAAAkEB0AdDIbpn9clMfAQAAAAAAANgNRBcAjay8YltTHwEAAAAAAADYDUQXAAAAAAAAAAAJRBcAAAAAAAAAAAlEFwAAAAAAAAAACUQXAAAAAAAAAAAJRBcAAAAAAAAAAAlEFwAAAAAAAAAACUQXAAAAAAAAAAAJRBcAAAAAAAAAAAlEFwAAAAAAAAAACUQXAAAAAAAAAAAJRBcAAAAAAAAAAAlEFwAAAAAAAAAACUQXAAAAAAAAAAAJRBcAAAAAAAAAAAlEFwAAAAAAAAAACUQXAAAAAAAAAAAJRBcAAAAAAAAAAAlEFwAAAAAAAAAACUQXAAAAAAAAAAAJ8pv6ANRv3bp1sXz58li7dm18/PHHERHRsWPH6Nq1axxwwAHRo0ePL2VuSUlJLFmyJFatWhWffPJJ5OfnR7du3WL//fePIUOGRE5OTqPPLC8vjyVLlsSKFSvi448/jpycnOjcuXMMGjQoDjjggMjLy2v0mZWVlbF06dJ466234qOPPorq6uro2LFjDBgwIEaMGBFt2rRp9JkAAAAAAAAAtA6ii2Zmw4YN8ac//Sn+9re/xYIFC+LDDz+s9/6+ffvGySefHKeeemp06dJll+e/+eabcccdd8Qf//jHqKioqPWe7t27x8SJE+Oss86KoqKiXZ753nvvxZ133hnz5s2L0tLSWu/p2LFjTJgwIc4999xG+Tk3btwYd999dzzyyCPbY5YdFRUVxbhx42Lq1KnRp0+fXZ4JAAAAAAAAQOvi60WaiX/84x9xxhlnxBFHHBE/+9nPYv78+TsNLiIiVq9eHb/4xS/imGOOid///vfJ86urq2PmzJkxYcKEeOKJJ+oMLiIiPvjgg7jtttti3Lhx8eqrrybPjIh4+OGHY9y4cfHwww/XGVxERHz88cdx7733xpgxY+K///u/d2nm888/H2PGjIl77723zuAiIqK0tDQefvjhOOGEE3bp9xYAAAAAAACA1kl00UwsXbo0FixYEFVVVUn7S0pK4sorr4yrr746af91110XM2bMiMrKyqz3rFmzJk4//fRYuHBh0szf/OY38dOf/jS2bNmS9Z5NmzbF1KlTY/78+Ukz582bF+eff35s2rQp6z1lZWVx5ZVXxqxZs5JmAgAAAAAAANA6+XqRZqxfv35x2GGHxSGHHBIDBw6Mrl27RmFhYaxfvz4WL14cv/vd72LJkiUZe+bOnRtdu3aNiy++OOs5c+bMid/+9rcZa0VFRTFp0qQYM2ZM9O3bN0pKSmL58uUxe/bs+Mtf/rL9vi1btsSFF14Yjz32WPTq1Svrmc8991zccsstGWsFBQUxfvz4OPHEE6N///5RUVERK1asiLlz58bTTz8d1dXVERFRVVUVl19+efTr1y+GDRuW9cxly5bFFVdckRG25ObmxnHHHReTJk2KAQMGRF5eXqxatSoeeeSRePzxxzM+8WP69OkxYMCAOProo7OeCQAAAAAAAEDrJbpoZvLz82Ps2LFxyimnxCGHHFLrPXvssUcMGDAgTjrppHjooYfi+uuvz4gD7rrrrhgzZkwMGjRop/M2bNgQ06dPz1jr0aNHzJo1K2N/586do0+fPjFq1Ki455574uabb94eQWzatCl+/vOfx69+9ausfsatW7fG1VdfvX3/5z/TzJkza/zMPXv2jMMOOyzmzZsXl19++fafs7y8PK666qr4wx/+kNXMiIif/exnUV5evv26oKAgbr755hg7dmzGfd26dYuDDjoovvvd78YPfvCD+PTTTyPis69gufrqq+Owww6LwsLCrOcCAAAAAAAA0Dr5epFmIjc3N0444YSYP39+TJ8+vc7gYkcTJ06Ma6+9NmOtsrIybr/99qz233nnnVFWVrb9Oi8vL2bOnFlvsHHWWWfF6aefnrH29NNPx7Jly7Ka+dvf/jaKi4sz1qZNm1bvzzxu3Lj40Y9+lLG2dOnSeOaZZ7KaWdv5LrvsshrBxReNHDkypk2blrFWXFwcDz74YFYz+eoqyM+NGXMXN/UxAAAAAAAAgC+Z6KKZOPnkk+PWW2+Nfv36NXjvSSedVCNYeOGFFzI+1aE2GzZsiLlz52asnXbaaTF8+PCdzrzkkkuie/fu26+rq6tj5syZO91XUVERd999d8ba6NGj45hjjtnp3jPOOCOGDh2asZZtXLLjfcOGDasRjtTmmGOOidGjR2es3X333RmfLAK1Ka/Y1tRHAAAAAAAAAL5kootmIi8vb5f2jx8/PuO6pKQk3nzzzXr3PPvssxnxQE5OTpxxxhlZzSsqKoqTTjopY+2FF16IkpKSevctWLAgNm7cmLGW7czc3Nz4/ve/n7H2+uuvx7vvvlvvvpUrV8Ybb7yRsXbaaadFbm52f/x3jDM+/PDDWLhwYVZ7AQAAAAAAAGi9RBetxODBg2usrV+/vt49zz77bMb1t771rejbt2/WMydMmJBxXV5eHi+++GKDZvbu3TtGjhyZ9cxx48ZFYWFhvc/c2czCwsIYM2ZM1jP/6Z/+KXr16tWgmQAAAAAAAAC0fqKLVqJt27Y11srKyuq8v7y8PP72t79lrO34FSU7s88++0TPnj0z1p5//vl697zwwgsZ1wcffHDk5ORkPbOoqKjG1580dOYBBxwQRUVFWc/MycmJgw8+uEEzAQAAAAAAAGj9RBetxJo1a2qsdenSpc77V61aFeXl5RlrBx54YIPn7rhn+fLldd5bUlIS77333m6dGRE1vmalMWa+//77UVpa2uDnAAAAAAAAANB6iC5aiYULF9ZY22effeq8f8WKFTXWBg4c2OC5O+5ZuXLlbp/50UcfxaZNm2q9d+PGjTV+rTFmVldX1/rzAAAAAAAAAPDVIbpoBbZt2xaPP/54xtrAgQNj7733rnPPO++8k3Gdl5cXPXr0aPDsHb9epKSkJIqLi7OaGRHRq1evXZ5Z17Mjag89UmbWtkd0AQAAAAAAAPDVJrpoBR5++OFYu3ZtxtrYsWPr3fPBBx9kXO+1116Rl5fX4Nm9e/eusVZXdLHjzJycnKTQY1dmRqSHHjk5OVnNBAAAAAAAAOCrIb+pD8CuWbduXdxyyy0Zax07dozJkyfXu6+0tDTjukOHDknza9tXUlKS1cy2bdtGQUFBo8zc8dn1nSXlZy0oKIjCwsLYsmXLTme2BJWVlTUiEnausrIyq7XqqPrCP2de1+eL91ZHVVRUVCSdE8iU7bsLNC/eXWiZvLvQMnl3oWXy7kLL5f2Flsm72zw1h38HoosWrLKyMi699NL49NNPM9YvueSS6NSpU717dwwGCgsLk85Q2766YoTmMHNX5rZt27bVRBevv/56Ux+h1XjttdcyrnNzc6O0tCzi/zUtbfJzo6KyOqqjeqfP+uK95RXbYunSpVFVlV2wATTMju8u0DJ4d6Fl8u5Cy+TdhZbJuwstl/cXWibvLhG+XqRFu/HGG2PRokUZa4cffnhMmjRpp3vLysoyrnclRNhRXTFCc5i5K3N33NeSowsAAAAAAAAAdp3oooV64IEHYs6cORlrPXv2jOnTp/vaCAAAAAAAAADYDUQXLdC8efPixhtvzFjbY4894q677oouXbpk9Yx27dplXG/dujXpLF/8uo3PFRUVNduZuzJ3x311zQQAAAAAAADgqyG/qQ9Aw7zwwgtx+eWXR1VV1fa1tm3bxp133hmDBw/O+jk7BgONFSLU9uzmNPPz/e3bt2/w3B1jj5YcXQwZMiQKCgqa+hgtTmVlZY3v5ho6dGjk52f+VfrM0sXb/7kgPzfyK6siG1+8t6CgKoYPH76LJwYisn93gebFuwstk3cXWibvLrRM3l1ouby/0DJ5d5unioqKeP3115v0DP4EtCCLFi2Kiy++OCoqKravFRQUxIwZM+Kggw5q0LN2DAY2b96cdKba9tUVNOw4c8uWLVFZWdngv4hqm1lXAFHbWTZv3pz1J4J8rqKiolV90kV+fr7oopHU9nuZ84UPEcqJ3Mj2C3++eG9OhH9H8CXy9yC0TN5daJm8u9AyeXehZfLuQsvl/YWWybvb9Kqrq5v6CL5epKVYunRpnHfeeVFWVrZ9LTc3N2666aY46qijGvy87t27Z1yvX78+tm3b1uDnrF27dqfPrmu9uro61q1bt1tn1rV/Z9atW1fjha1rJgAAAAAAAABfDaKLFuCtt96Ks88+u8YnPFx77bUxbty4pGcOGDAg43rbtm1RXFzc4OfsGDC0b98+evbsmdXM2vanzIyIGDhwYLOZCQAAAAAAAMBXg+iimXv33XdjypQpsWnTpoz1K664Ik499dTk59YWDLzzzjsNfs6KFSsyrvfdd986760tgGiMmZ07d47OnTvXem+XLl2iU6dOjT4zJyen3p8VAAAAAAAAgNZPdNGMrV27NqZMmRLr16/PWL/oootiypQpu/Ts/v37R5s2bTLWFi9e3ODnvPLKKxnX++23X533dujQIfr06bPLM19++eWsZ0ZE7L///o0+c++994727ds3+DkAAAAAAAAAtB6ii2Zqw4YNceaZZ8b777+fsX7WWWfFhRdeuMvPb9OmTRx66KEZay+99FKDnrF69eoaX7tx1FFH1bvnyCOPzLheuHBhg2aWlZXF0qVLd2nmP/7xjygrK8t6ZnV1dSxatKhBMwEAAAAAAABo/UQXzdCmTZtiypQpsWrVqoz1iRMnxuWXX95oc0aPHp1xvWjRoli9enXW+x999NGM6zZt2sThhx/eoJnvv/9+LFiwIOuZ8+fPj61bt9b7zJ3N3LJlSzzxxBNZz1ywYEGsWbOmQTMBAAAAAAAAaP1EF81MSUlJnHPOObF8+fKM9e985ztx7bXXNuqs0aNHR0FBwfbr6urqmD17dlZ7y8rK4ve//33G2pFHHrnTr9wYOXJkdOnSJWPtgQceyGpmVVVVzJkzJ2NtyJAh0a9fv3r37bvvvjF48OCMtdmzZ0d1dXVWc3f8PenSpUscfPDBWe0FAAAAAAAAoPUSXTQjW7dujalTp8arr76asX7cccfFtGnTIicnp1HndevWLSZOnJixNnv27Hjttdd2uveXv/xlFBcXb7/OycmJCy64YKf7CgoK4pxzzslYe+aZZ+K5557b6d7Zs2fHsmXLMtZ+8IMf7HRfRNQ427Jly2oEHLV59tln45lnnslYO++88zJiFQAAAAAAAAC+mkQXzURlZWX88Ic/jJdeeilj/cgjj4xbb7018vLyvpS5U6dOjXbt2mWc44ILLoi33367zj333Xdf3H///Rlrxx13XAwbNiyrmaeddlr06NEjY+3f//3fY9GiRXXumT9/fkyfPj1jbfjw4XHsscdmNfP444+vcb6bbropnnzyyTr3vPTSS3HFFVdkrPXo0SO+973vZTUTAAAAAAAAgNYtv6kPwGduu+22Gp/2kJ+fH/369Ytf/epXSc8cNmxYjBkzpt579tprr/jRj34U119//fa1tWvXxqmnnhqTJk2KsWPHRp8+faK0tDTefPPNmD17drz44osZz+jUqVONOKE+hYWFcc0118T555+/fe2TTz6JM888MyZMmBDjx4+P/v37R0VFRaxYsSIeeuihePLJJzO+DqRNmzZx3XXXZT0zIuK6666LSZMmRUVFRURElJeXxyWXXBJPPfVUTJw4MQYMGBB5eXmxatWqePTRR+Oxxx7bfm/EZ5/mce2110ZhYWGD5gIAAAAAAADQOokumokvflXH5yorK+OBBx5IfuaJJ5640+giImLy5Mnx9ttvx4MPPrh9raSkJGbNmhWzZs2qd2/btm3jtttui969ezfobKNGjYpLL700br311u1rFRUV8dBDD8VDDz1U797c3NyYNm1a1p+s8bnhw4fHtGnT4rLLLouqqqqIiKiqqor58+fH/Pnzd7r/0ksvjaOPPrpBMwEAAAAAAABovXy9CBERcfXVV8dFF13UoK8x6dWrV/zXf/1XHHLIIUkzzz333Ljhhhuibdu2We/p2LFjzJw5M8aNG5c084QTTojbb789OnbsmPWetm3bxg033BDnnHNO0kwAAAAAAAAAWifRBRHx2VdnXHjhhfHII4/Et7/97SgoKKjz3r322isuuuiimDdvXnzjG9/YpbmnnHJKzJs3L04++eRo165dnfd17NgxzjzzzHjyySd3+dMmRo0aFU8++WSceeaZseeee9Z5X7t27eLkk0+OefPmxSmnnLJLMwEAAAAAAABofXy9SDMxbdq0mDZtWlMfIwYPHhwzZsyIzZs3x+LFi+Pdd9+NTz/9NPLy8qJr164xePDgGDp0aOTk5DTazD59+sR//Md/xFVXXRVLliyJd955Jz755JPIycmJzp07x6BBg+KAAw6I/PzG++PapUuX+PGPfxyXXXZZvPrqq/H222/HRx99FNXV1bHnnnvGwIEDY8SIEVFYWNhoMwEAAAAAAABoXUQX1KpDhw5xxBFHxBFHHLHbZhYWFsbIkSNj5MiRu21mfn5+HHjggXHggQfutpkAAAAAAAAAtA6+XgQAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AIAAAAAAAAAIIHoAgAAAAAAAAAggegCAAAAAAAAACCB6AKgGSrIz41bZr/c1McAAAAAAAAA6iG6AGimyiu2NfURAAAAAAAAgHqILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguAAAAAAAAAAASiC4AAAAAAAAAABKILgAAAAAAAAAAEoguABrRjLmLm/oIAAAAAAAAwG4iugBoROUV25r6CAAAAAAAAMBuIroAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASCC6AAAAAAAAAABIILoAAAAAAAAAAEggugAAAAAAAAAASJDf1AfI1sKFC7f/c1FRUQwbNqzRnr1s2bIoLS3dfn3wwQc32rMBAAAAAAAAgNapxUQXp59+euTk5ERExODBg+PRRx9ttGdfeeWV8eabb0ZERE5OTrz22muN9mwAAAAAAAAAoHVqMdFFRMT/x969x1ld1vsC/65hblyHQbmKiiJeYDCPhlTbK3gn91bU8p6ZkantMi2rXVpGyVY8J/KIHsvUBC+HlC4Hb2RmL6vjFdJBFAXxighyk4FhZph1/uiwNgtmYM2PkTVrzfv9evFqnmc9z/P9DvBMvV58+v3S6XRBng0AAAAAAAAAFJ+SfDfQFqlUKvO0i4/jbAAAAAAAAACAXBVU6CLCEykAAAAAAAAAgI6h4EIXH4fNgxwlJX5LAAAAAAAAAIDtkzCIiPXr12e+rqyszGMnAAAAAAAAAECh6PShi6ampliyZElm3KNHjzx2AwAAAAAAAAAUik4funjyySejsbExIiJSqVTsvvvuee4I4J/KSkti8rTn890GAAAAAAAA0IrSfDeQLx999FE8+eSTMWnSpEilUpFOpyOVSsV+++2X79YAMhoaN+a7BQAAAAAAAKAVHSZ0MXbs2JzXvv76621av7nm5uZYt25drFmzJiIiE7bY5Kijjkp0LgAAAAAAAADQuXSY0MW7776beeJEazZ91tjYGO+++2671N0UuEilUrHHHnvEYYcd1i7nArSHTa8YufLcQ/LdCgAAAAAAALCFDhO62GTzp05sbvMwRmtrkkqn09G1a9e4/vrr2/1sgB3lFSMAAAAAAADQMXWo0MW2nnKRZF0uSkpK4ogjjohvf/vbMXTo0HY7FwAAAAAAAAAobh0mdHHqqadu8/OZM2dmXj9SVVUVY8aMSVSnS5cu0b179+jVq1fst99+8YlPfCL69u2b6CwAAAAAAAAAoPPqMKGL6667bpufz5w5M/P1oEGDtrseAAAAAAAAAODjVJLvBtoqlUrluwUAAAAAAAAAgI7zpIvtGTRoUObrfv365bETAAAAAAAAAIACCl386U9/yncLAAAAAAAAAAAZBfd6EQAAAAAAAACAjkDoAgAAAAAAAAAgAaELAAAAAAAAAIAEhC4AAAAAAAAAABIozXcDO6qhoSFeffXVeOONN+Kjjz6KtWvXRmNj4w6dedlll7VTdwAAAAAAAABAsSrI0EVzc3M88sgj8Zvf/CaeeeaZ2LhxY7ueL3QBAAAAAAAAAGxPwYUuXnnllfje974X8+fPj4iIdDrdruenUql2PQ8AAAAAAAAAKE4FFbr4xz/+EV/84hdj/fr1mbBFe4Yk2jvAAQAAAAAAAAAUr4IJXaxatSq+8pWvxLp16yKVSmXCFoISAAAAAAAAAEA+FEzo4pZbbolVq1ZlPdkinU7HgQceGP/6r/8aBx54YOy+++7Rs2fPKC0tmG8LAAAAAAAAAChQBZFOaG5ujpkzZ2Y93aKioiJ+8pOfxGc/+9k8dwcAAAAAAAAAdEYFEbp48cUXY82aNZFKpSKdTkcqlYr//M//jBNOOCHfrQEAAAAAAAAAnVRJvhvIxeLFizNfp1Kp+MQnPiFwAQAAAAAAAADkVUGELlasWBER/3ytSETEUUcdlcduAAAAAAAAAAAKJHTR1NSUNd5tt93y1AkAAAAAAAAAwD8VROiiuro6a1xSUhBtAwAAAAAAAABFrCDSC0OHDo2IiFQqFRERH374YT7bAQAAAAAAAAAojNDFgQceGD179syM58yZk8duAFo25T4/mwAAAAAAAKAzKYjQRWlpaZxyyimRTqcjnU7HX//611i7dm2+2wLI0tC4Md8tAAAAAAAAADtRQYQuIiK+8pWvRK9evSKVSsVHH30Ut9xyS75bAtgpykpLYvK05/PdBgAAAAAAALCFggld7LrrrvHjH/84M77jjjviD3/4Qx47Ath5PEUDAAAAAAAAOp6CCV1ERBx//PFx9dVXRyqViubm5rjqqqvi+uuvj7q6uny3BgAAAAAAAAB0MqX5biBX7733XkREHHnkkRERMWnSpNiwYUPccccdMWPGjDjxxBNj1KhRseeee0bv3r2jtDT5tzZo0KB26RkAAAAAAAAAKF4FE7oYM2ZMpFKprLlUKhXpdDo++uijmDFjRsyYMWOH66RSqXj55Zd3+BwAAAAAAAAAoLgVTOgiIiKdTmeNU6lUJoix5WcAAAAAAAAAAB+nggpdbPmki1w/y5XgBgAAAAAAAACQq4IKXQhFAAAAAAAAAAAdRcGELq677rp8twAAAAAAAAAAkFEwoYtTTz013y0AAAAAAAAAAGSU5LsBAAAAAAAAAIBCJHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJBAab4bgM01NDTE3LlzY9GiRbF69epIpVJRXV0dw4YNi5EjR0aXLl3avWZTU1PU1tbGa6+9FitXrox0Oh1VVVWx9957x0EHHRTl5eXtXhMAAAAAAACAwlcwoYvvfve7O6VOKpWKn/70pzul1vasXLkyamtr46WXXooXX3wxamtrY9myZVlrLrvssvja1762Q3XGjBkT77777g6d0bt373j66acT73/nnXfi1ltvjVmzZsW6detaXFNVVRXjx4+PCRMmRJ8+fRLX2mTFihVx2223xYMPPhirV69ucU23bt1i3LhxcfHFF8fgwYN3uCYAAAAAAAAAxaNgQhczZ86MVCr1sdZIp9N5D13ccccdmZDF22+/nbc+dqYZM2bExIkTo76+fpvrVq9eHXfccUfMnDkzrr/++jjyyCMT1/zzn/8cV111VaxatWqb69atWxczZsyI//N//k98//vfj9NPPz1xTQAAAAAAAACKS8GELjZJp9Mfy7kfd6AjV5MmTcp3CzvVL3/5y7jhhhvatGfVqlVx8cUXx4033hgnnXRSm2vOmjUrrrzyymhubs55z/r16+M//uM/YvXq1fGlL32pzTUBAAAAAAAAKD4FF7po73DExxXiKGSf/exnY+DAgW3a07Vr1zbXeeKJJ2Ly5MlZc2VlZXHKKafEqaeeGkOGDInGxsZYtGhR3HffffHYY49l/ryam5vjqquuij333DNGjBiRc8158+bFd77znazARUlJSRx33HFx5plnxt577x1dunSJxYsXx4MPPhi///3vo7GxMbP2hhtuiL333juOPvroNn+/AAAAAAAAABSXggldDBo0KPHepqamWL16dWzYsCEztym8UV5eHrvuuusO9/dx6datW9TU1ERNTU2MHDkyLr/88o+95uc+97kYPXr0x1pjw4YNcc0112SFXnr27BlTp06NQw89NGvtgAED4jOf+UzMmjUrrrrqqkwIoqGhIa6++up44IEHcq77gx/8IBoaGjLjsrKyuP7667d6Ysauu+4an/zkJ+Pf/u3f4tJLL42PPvooIv4Z0rnmmmviM5/5TFRUVLT5+wYAAAAAAACgeBRM6OJPf/rTDp+xdOnSeOaZZ+J//+//Hc8++2ykUqloamqKk08+eaeEGXJx4IEHxsiRIzO/9t577ygpKcl83lH63FH33HNPLF26NGtu0qRJWwUuNjdu3LhYtmxZXHfddZm52tramD17dhx77LHbrfnYY4/FvHnzsua+9a1vbfMVJaNHj45JkybFpZdemplbunRp3HvvvXHBBRdstyYAAAAAAAAAxatk+0uKR//+/ePkk0+Ou+++O26++ebo1atXpNPpuO222+KKK67Id3sRETFjxoy4+uqr49RTT4199tknK3BRLBobG+O2227Lmhs7dmwcc8wx2917/vnnx/Dhw7Pmbr755pzqbrluxIgRcd5552133zHHHBNjx47NmrvtttuyXjsCAAAAAAAAQOdTfP+in6OxY8fGXXfdFd26dYt0Oh0PPfRQTJ48Od9tdQpPP/10rFixImvu/PPPz2lvSUlJnH322Vlz8+fPjzfffHOb+95444145ZVXsubOOeecnEMtW4YzPvzww3j22Wdz2gsAAAAAAABAceq0oYuIiP333z++853vREREOp2OX/3qV/Hiiy/muavi9/jjj2eNBw0aFKNHj855/7hx46KiomKbZ26vZkVFRZx44ok51/zUpz4VAwcObFNNAAAAAAAAAIpbpw5dREScdtppMWjQoEilUpFOp2Pq1Kn5bqno/eUvf8kajxo1KlKpVM77u3XrFjU1NVlzf/7zn9tUc+TIkdGtW7eca6ZSqRg1alSbagIAAAAAAABQ3Dp96KKkpCSOPPLISKfTkU6n46mnnoo1a9bku62iVVdXF++8807W3MEHH9zmc7bcs2DBgm2uf/XVV9u95rvvvhvr1q1r8zkAAAAAAAAAFIfSfDfQEey7776Zrzdu3Bhz5syJI488Mo8d5Vdzc3PU1tbG/PnzY8WKFbFhw4aoqqqK3r17x/777x/77rtvm55MsblFixZtNTd06NA2n7PlnpUrV8aqVauid+/eW61dsWJFrFq1qt1rptPpWLRo0VZP3QAAAAAAAACgcxC6iNjqH+rfeuut/DTSQVx00UXR1NTU6ue9e/eOMWPGxEUXXdTm8MLChQu3mhs4cGCbexwwYECLZx9yyCFbzbcU9EhSs6U9QhcAAAAAAAAAnVenf71IRER9fX1ERObpDXV1dflsJ++2FbiIiFi1alU8+OCDMW7cuPjud78b69evz/nsDz74IGucSqWif//+be5x0KBBW80tXbo0p5oRyYMeWz7ho7WaAAAAAAAAABQ/T7qI/3r6QjqdjlQqFd27d89zR4UhnU7Hgw8+GC+99FLcdtttLQYhtrRu3bqscWVlZZSVlbW5do8ePbZ79iYthWha2r89ZWVlUVFRkQnpbKtmR9fU1JT4FTGdWUuBpM3n0tG81efpVuZbsq216WiOxsbGnM4Bsm3v7gIdk7sLhcndhcLk7kJhcnehcLm/UJjc3Y6pI/wZdPrQxcaNG+Oxxx6LVCoV6XQ6IiJ22WWXPHeVH/vtt18cffTRceCBB8awYcOiT58+UVlZGWvWrIklS5bEc889F7/73e9i3rx5Wftee+21+MpXvhL33nvvdsMMW4YUKioqEvXa0r7WAhAtzSetW1lZWRShi/nz5+e7haLx8ssvR0RESUlJrFu3PmKLLEt5aUk0NqUjHentnrWttQ2NG6O2tjaam3MLcADbtunuAoXF3YXC5O5CYXJ3oTC5u1C43F8oTO4uEUIXMXXq1Hjrrbey/l//I0aMyGNHO9/48ePjuOOOi3333bfFz/v06RN9+vSJESNGxBe+8IV4+OGH4wc/+EF89NFHmTULFiyIa6+9Nq6//vpt1tryVSQ7En7YUmsBiJZef9JeYY9CDV0AAAAAAAAAsONK8t1AvqxduzYmTpwYU6dOzQpc7LHHHrHnnnvmsbOd77LLLms1cNGSE088Me69997o2bNn1vwf/vCHePXVV9u7PQAAAAAAAADokArmSRfPPvvsDu1vamqKtWvXxttvvx0vvvhiPPnkk1FfXx/pdDrzapFUKhUXXnhhO3Vc3IYNGxYTJ06Mr3/965m55ubmuPPOO+O6665rdV/Xrl2zxhs2bEhUf/NXfGzSrVu3nGpuqlta2va//lv221pNAAAAAAAAAIpfwYQuzjvvvKwnUuyodDodEZF15oEHHhhnnHFGu9UodieccEKMGDEi5s2bl5l76qmntrlny5BC0tBFS/taC0C0NL9hw4bo3r17m+tuGfYo1NDFAQccEGVlZfluo+A0NTVt9W6u4cOHZwI8s2vnbLWnrLQkSpuaczp/W2vLypqjpqamjR0DEdu/u0DH5O5CYXJ3oTC5u1CY3F0oXO4vFCZ3t2NqbGyM+fPn57WHgvsbsCkssaM2D1uk0+kYNmxY3HbbbVFS0mnfuJLI8ccfnxW6+OCDD2Lx4sUxZMiQFtdvGVKor6+PpqamNv8wWrt27XbP3qSlcMXatWujT58+barZ2NhYNE+6KC0tFbpoJ5v/XqZaeGNTKkoi17jYttamIvyZQTvycxAKk7sLhcndhcLk7kJhcnehcLm/UJjc3fxrr/zAjii4hEEqlWqXX+l0OtLpdJSUlMQXvvCFmDFjRlRVVeX72ys4Bx100FZzS5cubXV9v379ssbpdDref//9NtddsmTJds/e1nxL+7fn/fff3+rStlYTAAAAAAAAgOJXUE+6aK+USteuXWP48OFxxBFHxKmnnuofznfALrvsstXcihUrWl2/9957bzW3ZMmSGDx4cJvqthSaGDp0aJtqtlVbagIAAAAAAABQ/AomdPHrX/96h/aXlpZGjx49olevXtG/f/+s14uQXEtBmG393rYUgFi4cGGMGjWqTXUXLVqUNa6uro7q6uoW1/bp0yd69+4dq1atyqrZVlvWTKVSsddee7X5HAAAAAAAAACKQ8GELg499NB8t0ALli9fvtVcnz59Wl3fo0ePGDx4cLzzzjuZuTlz5sSZZ57ZprrPP/981njffffd5vr99tsvnn766ayabbVlzd122y26d+/e5nMAAAAAAAAAKA4l+W6AwjZ37tyt5vr27bvNPUcccUTW+Nlnn21TzfXr10dtbW3W3FFHHdWmmi+99FKsX78+55rpdDqee+65NtUEAAAAAAAAoLgJXZBYOp2ORx55JGuub9++233lxtixY7PG7777btZTKLbnoYceig0bNmzzzO3VrK+vj4cffjjnmk8//XS89957baoJAAAAAAAAQHETuiCxWbNmxSuvvJI1d/jhh2933+jRo7d6Bcndd9+dU83m5uaYPn161twBBxwQe+655zb37bXXXrH//vtnzU2bNi3S6XROdadNm5Y17tOnT4waNSqnvQAAAAAAAAAUJ6GLTmzFihXR0NCQaO8rr7wSV199ddZcKpWKL3zhC9vdW1ZWFl/+8pez5mbPnh1PPPHEdvdOmzYt5s2blzV36aWX5tBxxCWXXJI1njdv3lYBjpY8/vjjMXv27Ky5r3zlK1FWVpZTXQAAAAAAAACKk9BFJ/bCCy/EMcccE3fddVesWrUqpz3pdDp+//vfx9lnnx11dXVZn5188slbPU2iNeecc070798/a+7b3/52PPfcc63ueeihh+KGG27ImqupqYljjz02p5rHH398jBgxImvuP//zP7d6RcrmnnnmmfjOd76TNde/f/8466yzcqoJAAAAAAAAQPEqzXcD7WXFihXxwgsvxLx582LlypWxevXqqKuri+7du0dVVVVUV1fHiBEj4uCDD97q1RYdSW1t7TZDAFv629/+Fhs2bGjxs169esWECRO2uX/p0qXx05/+NK6//vr41Kc+FYceemgccMABsccee0TPnj2jsrIy1q5dG++9914899xz8bvf/S5ee+21rc7Zf//945prrsm574qKivjhD38YX/3qVzNza9asiQsuuCDGjx8fp5xySgwZMiQaGxtj0aJFcf/998cjjzyS9TqQ8vLyuPbaa3OuGRFx7bXXxplnnhmNjY0REdHQ0BCXX355PProo/H5z38+9t577+jSpUssXrw4Zs6cGb/97W8zayP++TSPH/3oR1FRUdGmugAAAAAAAAAUn4IOXTQ0NMTvfve7mDZtWixYsCDnffvtt1+cd955cfLJJ0d5efnH2GHbLViwIH7xi1/kvP6FF16IF154ocXPdtttt+2GLjZpamqKp556Kp566qmca2+y//77x2233RY9evRo074xY8bEFVdcETfeeGNmrrGxMe6///64//77t7m3pKQkJk2atNWTK7anpqYmJk2aFN/61reiubk5IiKam5vjoYceioceemi7+6+44oo4+uij21QTAAAAAAAAgOJUsK8X+dOf/hRHH310XH311fHqq69GOp3O+dcrr7wS3//+92PMmDHxxBNP5PtbKVhlZWVx4YUXxowZM7Z6VUiuJkyYEBMnTozKysqc91RVVcXUqVNj3LhxiWp+9rOfjZtvvjmqqqpy3lNZWRkTJ06ML3/5y4lqAgAAAAAAAFB8Ci50kU6nY+LEiXHppZfGhx9+mHndRCqVyvnXpnOWL18el1xySUycODGf31LejBo1Kn7605/Gv/3bv8Wee+6Z+b3ZllQqFXvttVd89atfjccffzyuuuqqHX5ayBlnnBGzZs2K008/Pbp27drquqqqqrjgggvikUce2eGnTYwZMyYeeeSRuOCCC6JXr16truvatWucfvrpMWvWrDjjjDN2qCYAAAAAAAAAxaXgXi/y05/+NKZNmxYRsVVIYFMAY3s235dOp2P69OlRUlIS3/ve99qv0YTGjx8f48eP3ym1qqqq4rTTTovTTjstIiLq6urijTfeiCVLlsQHH3wQ69ati8bGxujWrVtUVVXFrrvuGiNHjozevXu3ey+DBw+On/zkJ3H11VfH3LlzY+HChbFmzZpIpVJRXV0dw4YNi5EjR0Zpafv9le3Tp09897vfjW9961vx4osvxuuvvx4rV66MdDodvXr1iqFDh8ZBBx0UFRUV7VYTAAAAAAAAgOJRUKGL+++/P+6+++6tQhMREcOGDYvjjz8+Ro4cGfvss09UVVVF165dY/369bFmzZp4/fXX46WXXopHHnkkXnvttcwZqVQq0ul03H333bHPPvvE5z73ubx8bx1B9+7do6amJmpqavLWQ0VFRYwePTpGjx6902qWlpbGwQcfHAcffPBOqwkAAAAAAABA4SuY0MXatWvjZz/72VaBi3333Td+8IMfxKhRo1rc16NHj+jRo0cMGjQojjjiiLj00kvjueeeix//+Mfx6quvZl45kk6n43/8j/8RJ510UvTo0WNnfVsAAAAAAAAAQIEqyXcDubrzzjtj5cqVEfFfT7f413/915g5c2argYvWfPKTn4wHH3wwTjnllKxXkqxatSruvPPOdusZAAAAAAAAACheBRO6ePTRRzNPpEilUnHkkUfG9ddfH126dEl0XpcuXWLSpElx1FFHZc5Mp9Px6KOPtnPnAAAAAAAAAEAxKojQxdKlS+O1117LjMvLy+NHP/pRu5z9ox/9KCoqKjLj119/PZYuXdouZwMAAAAAAAAAxasgQhcvv/xy5utUKhWHHXZY9O/fv13O7t+/fxx++OFZrxnZvB4AAAAAAAAAQEsKInTx4YcfRkRkghGjRo1q1/M/+clPtlgPAAAAAAAAAKA1BRG6WLFiRda4X79+7Xr+pvNSqVRERKxcubJdzwcAAAAAAAAAik9BhC4qKiqyxvX19e16/oYNGyLiv56kUVZW1q7nA+yostKSmDzt+Xy3AQAAAAAAAGymIEIXffr0iYj/ehLFu+++267nb3neLrvs0q7nA7SHhsaN+W4BAAAAAAAA2ExBhC42f51IOp2OJ554ol3P/9Of/pQJdERE9O3bt13PBwAAAAAAAACKT0GELj7xiU9EeXl5Zjx//vz461//2i5n//3vf4+XX345My4vL4+DDjqoXc4GAAAAAAAAAIpXQYQuKisrY9SoUZFOpyOVSkU6nY4f/OAH8cEHH+zQucuWLYsf/OAHmTNTqVR88pOfjMrKynbqHAAAAAAAAAAoVgURuoiIOP300zNfp1KpeO+99+Lcc8+NV199NdF5CxYsiHPPPTfeeeedrPkzzjhjh/oEAAAAAAAAADqHggldnHjiiVFTU5MZp1KpeOutt+K0006LiRMnxsKFC3M6Z+HChTFx4sQYP358vPXWW1lPuaipqYkTTjjh4/oWAAAAAAAAAIAiUprvBtri2muvjXPOOSfq6+sj4p/Bi6amppg+fXpMnz499t5776ipqYmhQ4dGz549o2vXrrF+/fr46KOPYuHChVFbWxuLFi2KiMgELTbp2rVrXHvttXn5vgAAAAAAAACAwlNQoYvhw4fHlClT4pJLLomNGzdGRGSeVBHxz6dYbApVtGTTuk37Ns2VlpbGz372szjggAM+xu4BAAAAAAAAgGJSMK8X2eSII46IX/7yl9GvX79MiCKVSmV+pdPpVn9tvi7in4GL/v37x+233x5HHHFEPr8tAAAAAAAAAKDAFFzoIiLiU5/6VPzud7+LM844I8rLyzOhiojsAMaWvyIis7a8vDw+97nPxe9///sYPXp0Pr8dAAAAAAAAAKAAFdTrRTbXu3fv+PGPfxzf/OY3Y8aMGfG3v/0t/vGPf8T69etb3dOtW7c48MAD47DDDovTTjstqqurd2LHAAAAAAAAAEAxKdjQxSbV1dUxYcKEmDBhQjQ3N8cbb7wRK1eujNWrV0ddXV107949qqqqorq6Ovbaa68oKSnIh3sAAAAAAAAAAB1MwYcuNldSUhJDhw7NdxsAAAAAAAAAQCfgsQ8AAAAAAAAAAAkIXQAAAAAAAAAAJNChXi/S0NAQy5cvz5orKyuLvn37tmudZcuWRWNjY9Zc3759o6ysrF3rAAAAAAAAAADFq0OFLq6//vqYPn161tyNN94YJ510UrvWeeaZZ+KKK66IVCqVmZswYUJcfvnl7VoHAAAAAAAAACheHeb1Im+//Xbcd999kU6nI51OR0TEF7/4xXYPXEREjBs3Lr74xS9maqXT6fj1r38dS5cubfdaAAAAAAAAAEBx6jChi//5P/9nNDU1RSqVilQqFcOGDYtvfvObH1u9b37zmzFs2LDM0y7q6+vjlltu+djqAQAAAAAAAADFpUOELtauXRuPPvpopFKpzFMu/uM//iNKSz++t5+UlZXF9773vUin05m6f/jDH2LDhg0fW00AAAAAAAAAoHh0iNDFY489FvX19RERkUql4uCDD47Ro0d/7HU//elPxyGHHJIJeqxbty4ee+yxj70uAAAAAAAAAFD4OkzoIiIy4Ydzzz13p9U+55xzIiIyrxl55JFHdlptAAAAAAAAAKBwdYjQxT/+8Y9M6KGysjLGjBmz02qPHTs2unbtGhH/DH384x//2Gm1AQAAAAAAAIDClffQxbvvvhsrV66MiH8+beKggw6KioqKnVa/oqIiDjrooMxTNj788MNYsmTJTqsPAAAAAAAAABSmvIcuXnvttaxxTU3NTu9hxIgRWeMFCxbs9B4AAAAAAAAAgMKS99DFqlWrIiIyT5oYPHjwTu9h9913zxpvevIGAAAAAAAAAEBr8h66WLNmTda4Z8+eO72HLWtu2RMAAAAAAAAAwJbyHrqoq6vLGqdSqTx18l+1t+wJAAAAAAAAAGBLeQ9dlJeXZ41XrFix03vY9DqRTa842bInAAAAAAAAAIAt5T100b1794j4r6dMbApA7Exb1uzWrdtO7wEAAAAAAAAAKCx5D10MHDgwa7xw4cKd3sOWNbfsCQAAAAAAAABgS3kPXeyxxx6Zr9PpdPztb3/LvOZjZ9hUc9OTNrbsCQAAAAAAAACgJXkPXey1117Rs2fPzHjNmjUxd+7cnVZ/7ty5sXr16sy4R48esffee++0+gAAAAAAAABAYcp76CIiYtSoUZFOpzNPm7j11lt3Wu3Na6VSqTjkkEN2Wm2AtigrLYnJ057PdxsAAAAAAADA/9chQhfHHXdc5ut0Oh1/+ctf4tlnn/3Y6z777LPx5JNPRiqVyrzS5IQTTvjY6wIk1dC4Md8tAAAAAAAAAP9fhwhdHH/88VFVVRURkQlAXHHFFbFkyZKPreb7778fV155ZebpGhERvXr1EroAAAAAAAAAAHLSIUIXXbt2jbPOOivztIlUKhUffPBBXHTRRbF8+fJ2r7d8+fK46KKLYunSpRERmVebnH322VFZWdnu9QAAAAAAAACA4tMhQhcRERMmTIh+/fplxqlUKhYuXBif/exn49FHH223OrNnz46TTz45Fi5cmPWUi379+sWECRParQ4AAAAAAAAAUNw6TOiiW7ducd1112XNpVKpWLVqVXzjG9+ICy+8MP74xz9Gc3Nzm89Op9Pxxz/+Mb70pS/Fv//7v8fKlSszT9VIp9NRUlISP/3pT6Nr167t8r0AAAAAAAAAAMWvNN8NbO5f/uVf4vLLL4///t//e+YpFKlUKtLpdPz973+Pv//977HrrrvGqFGj4sADD4yamprYddddo1evXtGjR49IpVLx0UcfxZo1a2L58uVRW1sbL730Ujz77LOxbNmyiPivV4lskkql4hvf+Eb8y7/8S16+ZwAAAAAAAACgMHWo0EXEP18zUldXF//rf/2vrYIXERHLli2Lhx9+OB5++OGcz9y0d9NZm89ffPHFXisCAAAAAAAAALRZhwtdRERcfvnlMXjw4Jg4cWI0NDRExNZhibbYfO+m/RUVFfH9738/zjjjjB1vGAAAAAAAAADodEry3UBrzjjjjHjwwQfj4IMPjnQ6vdXTKtrya5NN5xxyyCHx4IMPClwAAAAAAAAAAIl1yCddbDJ06NCYPn16PPnkk3HnnXfG//2//zcTvtjy6RWt2Xz9Zz7zmfjCF74QRx555MfWMwAAAAAAAADQOXTo0MUmRx55ZBx55JHx/vvvx5/+9Kd4+umn4+WXX4533nmn1VeNpFKp2G233WLEiBFx6KGHxpgxY2LgwIE7uXMAAAAAAAAAoFgVROhikwEDBsTZZ58dZ599dkRENDY2xtKlS2PNmjVRX18f6XQ6Kisro6qqKvr37x9lZWV57hgAAAAAAAAAKFYFFbrYUllZWQwePDjfbQAAAAAAAAAAnVBJvhsAAAAAAAAAAChEQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFQDuYct+cfLcAAAAAAAAA7GRCFwDtoKFxY75bAAAAAAAAAHYyoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6ACggZaUlMXna8/luAwAAAAAAAAihC4CC09C4Md8tAAAAAAAAACF0AQAAAAAAAACQiNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AVBgykr96AYAAAAAAICOwL/cAQAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdABSYstKSmDzt+Xy3AQAAAAAAAJ2e0AVAAWpo3JjvFgAAAAAAAKDTE7oAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEigNN8N0HGtWrUq5s6dG2+99VbU1dVFeXl59OvXL4YPHx5Dhw79WGrW1dXF3LlzY/HixbFmzZooLS2NXXfdNfbbb7844IADIpVKtXvNhoaGmDt3bixatChWr14dqVQqqqurY9iwYTFy5Mjo0qVLu9cEAAAAAAAAoPAJXXRgK1eujNra2njppZfixRdfjNra2li2bFnWmssuuyy+9rWvtWvd5557Lm699db429/+Fhs3bmxxzZ577hnnnntunHXWWVFWVrbDNV999dW45ZZb4o9//GM0Nja2uKZfv37x+c9/Pi688MLo1q3bDtd855134tZbb41Zs2bFunXrWlxTVVUV48ePjwkTJkSfPn12uCYAAAAAAAAAxUPoooO54447MiGLt99+e6fWbmxsjOuuuy6mT5++3bVvvvlm/OQnP4kZM2bETTfdFEOGDElUM51Oxy233BI333xzNDU1bXPtBx98EDfddFM88MADMWXKlDjwwAMT1YyImDFjRkycODHq6+u3uW716tVxxx13xMyZM+P666+PI488MnFNAAAAAAAAAIpLSb4bINukSZNi1qxZOz1w0dTUFF//+tdzClxsbsGCBXHWWWfFwoULE9W99tprY8qUKdsNXGzuvffei/POOy+effbZRDV/+ctfxve///3tBi42t2rVqrj44ovjoYceSlQTAAAAAAAAgOLjSRdERMSNN94Yjz/+eNZcdXV1nHvuuXHMMcfEwIEDY9WqVVFbWxt33nlnvPjii5l1K1asiIsvvjhmzpwZPXr0yLnm9OnT45577sma69atW5x55plx4oknxu677x51dXWxYMGCmDZtWvz1r3/NrKuvr4/LLrssfvvb38bAgQNzrvnEE0/E5MmTs+bKysrilFNOiVNPPTWGDBkSjY2NsWjRorjvvvvisccei3Q6HRERzc3NcdVVV8Wee+4ZI0aMyLkmAAAAAAAAAMVJ6KKD69atW9TU1ERNTU2MHDkyLr/88nav8corr8Qdd9yRNTds2LC4/fbbo3///pm5qqqq2HPPPeOkk06K6667Lu66667MZ2+99VbcfPPNcdVVV+VUc/ny5XHDDTdkzfXv3z9uv/32GDZsWGauuro6Bg8eHGPGjIlf/epXcf3112dCEKtWrYrrrrsufv7zn+dUc8OGDXHNNddk9kdE9OzZM6ZOnRqHHnpo1toBAwbEZz7zmZg1a1ZcddVV0djYGBERDQ0NcfXVV8cDDzyQU00AAAAAAAAAipfQRQdz4IEHxsiRIzO/9t577ygp+a+3wHwcoYuf/exnWUGE7t27xy9+8YuswMXmUqlUfO9734t33nkn6+kY99xzT1xwwQWt7tvcrbfeGuvXr8+Mu3TpElOnTs0KXGzpwgsvjCVLlsSvf/3rzNxjjz0W8+bNy+nJE/fcc08sXbo0a27SpElbBS42N27cuFi2bFlcd911mbna2tqYPXt2HHvssdutCQAAAAAAAEDxKtn+EnamGTNmxNVXXx2nnnpq7LPPPlmBi4/D/Pnz44knnsia+/d///ecXtnxwx/+MCorKzPj+vr6uP3227e7b/ny5XHfffdlzZ1zzjlRU1Oz3b2XX3559OvXLzNOp9MxderU7e5rbGyM2267LWtu7Nixccwxx2x37/nnnx/Dhw/Pmrv55pu3uw8AAAAAAACA4iZ00ck9/PDDWeNu3brF6aefntPefv36xXHHHZc19+ijj2533+OPP555XUfEP5+ccf755+dUs1u3bnHaaadlzf3lL3+Jurq6be57+umnY8WKFVlzudYsKSmJs88+O2tu/vz58eabb+a0HwAAAAAAAIDiJHTRyW3+epCIiGOPPTZ69OiR8/7x48dnjd9///2ora1tU81DDjkkdt9998Q1Gxoa4qmnnmpTzUGDBsXo0aNzrjlu3LioqKjY5pkAAAAAAAAAdC5CF53Ye++9F6+//nrW3KGHHtqmM/7bf/tvUVZWljX35z//udX1DQ0N8fe//32Hau6xxx4xYMCAnGtG/PNpGJsbNWpUpFKpnGt269Ztq9efbK8mAAAAAAAAAMVN6KITe/XVV7eaO/jgg9t0RmVlZQwfPjxrbsGCBa2uX7x4cTQ0NOxQzZb2bKtmXV1dvPPOOzu1JgAAAAAAAADFT+iiE1u0aFHWuLS0NIYMGdLmc4YOHZo1fuONN3Ku2dL+Qqm5cuXKWLVqVZvPAQAAAAAAAKA4CF10YgsXLswa9+/fP0pK2v5XYstXfSxevDg2btyYU80uXbpE//79d7hmXV1dLF26NKeaEREDBw7c4ZqtnQ0AAAAAAABA5yB00Yl98MEHWeOWQgW5GDRoUNa4oaGh1SdAbFmzb9++0aVLlx2uGRGthi62rJlKpRIFPdpSEwAAAAAAAIDiV5rvBsifdevWZY179OiR6Jzu3bu3ePYuu+zysdVsaV9dXV2La7esWVlZGWVlZe1Sc8uzC0VTU1OkUql8t1FwmpqaWp1LR3OLe9Lb+Czp2k3rGhsbczoXOrtt3V2g43J3oTC5u1CY3F0oTO4uFC73FwqTu9sxdYQ/A6GLTqylMEISLe3LNQBRUVGRqGZL+1oLQOSjZkc3f/78fLdQNF5++eUoKSmJdevWR7SQYykvLYnGpnSkI73ds3JdW15aEuvWN0VtbW00NzdHSUlJNDfnFuwA/unll1/OdwtAAu4uFCZ3FwqTuwuFyd2FwuX+QmFyd4nwepFObf369Vnj8vLyROe0FLpoLYywZc2kAYiOXhN2lpKSkvj9M2uipMSPcwAAAAAAANjZ/CsdQIHb0Lgx3y0AAAAAAABApyR00Yl17do1a9zQ0JDonPr6+q3munXrllPNDRs2FGVN2Fk84QIAAAAAAADypzTfDZA/WwYGWgoV5KKlfd27d8+pZtIAREv7WgtA5KNmR3fAAQdEWVlZvtsoOE1NTVu9m2v48OFRWloas2vntLinrLQkSpuaczo/17VlpSWRTjVFTU1N3PybF6N7925RU1OTUw3ojLZ1d4GOy92FwuTuQmFyd6EwubtQuNxfKEzubsfU2NgY8+fPz2sP/gZ0YlsGBtauXZvonLq6uu2e3d41W9qXa9Cjvr4+mpqa2vwDsKWahRq6KC0tFbpoJ5t+L1OtPDgoFSWRyvGsXNf+c11JlJWVRWNTOvM1kDs/B6EwubtQmNxdKEzuLhQmdxcKl/sLhcndzb90Op3vFrxepDPr169f1vj9999PdM6SJUuyxuXl5dG7d++cai5btiw2bty4wzVbOru1+XQ6neh7bUtNAAAAAAAAAIqf0EUntvfee2eNly5dGs3Nub0GYXNbhhGGDBkSXbp0yanmxo0bY+nSpTtcs3v37jFgwICcara0P0nNiIihQ4e2+RwAAAAAAAAAioPQRSe2ZWCgqakpFi9e3OZzFi1alDXea6+9cq4ZEbFw4cKPtWZLoYv2qFldXR3V1dVtPgcAAAAAAACA4iB00Yntt99+W83NmTOnTWfU19fHvHnzsub23XffVtcPGTIkysvLd6hmRMQLL7yQc80ePXrE4MGDd7jm888/n3NNAAAAAAAAAIqf0EUnNmjQoNhnn32y5p555pk2nTFnzpxobGzMmjvqqKNaXV9eXh6f/vSnd6jm22+/vdWrPrZVMyLiiCOOyBo/++yzbaq5fv36qK2tbVNNAAAAAAAAAIqb0EUnN3bs2KzxY489FnV1dTnv/+1vf5s1HjBgQNTU1LSp5nPPPRdvv/12zjVnzpyZNS4vL4/DDjusTTXffffdePrpp3Ou+dBDD8WGDRu2eSbsTGWlJTHlvrY/sQUAAAAAAABoP0IXndwJJ5yQNV63bl088MADOe1dtmxZPPLII1lzxx9//Hb3jR07NsrKyjLjdDod06ZNy6nm+vXr4ze/+U3W3BFHHBHdu3ff5r7Ro0dHnz59subuvvvunGo2NzfH9OnTs+YOOOCA2HPPPXPaDx+XhsaN+W4BAAAAAAAAOjWhi05u+PDhcfTRR2fN/fznP4+lS5dud++PfvSjqK+vz4wrKiriS1/60nb37brrrvH5z38+a27atGnx8ssvb3fvz372s6zeUqlUXHLJJdvdV1ZWFl/+8pez5mbPnh1PPPHEdvdOmzYt5s2blzV36aWXbncfAAAAAAAAAMVN6IL4xje+EalUKjP+6KOP4qKLLmo1eJFOp2PSpEkxe/bsrPlzzjkn+vfvn1PNiy++OLp27ZoZNzU1xSWXXBKvv/56q3vuvPPOuOuuu7LmjjvuuBgxYkRONVvq79vf/nY899xzre556KGH4oYbbsiaq6mpiWOPPTanmgAAAAAAAAAUr9J8N0C22trarV7ZsS1/+9vfYsOGDS1+1qtXr5gwYcJ2z9h///3ji1/8YvzqV7/KzC1YsCBOOeWUOO+882LMmDExcODAWL16ddTW1sadd94Z//jHP7LO2GOPPdr09Ie+ffvGlVdeGT/+8Y8zc0uWLInPfe5zceaZZ8ZJJ50UgwcPjnXr1sWrr74a06ZNi6eeeirrjN69e8d3vvOdnGtWVFTED3/4w/jqV7+amVuzZk1ccMEFMX78+DjllFNiyJAh0djYGIsWLYr7778/HnnkkUin05n15eXlce211+ZcEwAAAAAAAIDiJXTRwSxYsCB+8Ytf5Lz+hRdeiBdeeKHFz3bbbbecQhcREVdccUW88cYbWa/bWLFiRUyZMiWmTJmyzb3V1dVxyy23RI8ePXLuOyLi3HPPjddffz3uvffezFxdXV3cfvvtcfvtt29zb2VlZdx0000xaNCgNtUcM2ZMXHHFFXHjjTdm5hobG+P++++P+++/f5t7S0pKYtKkSTk/WQMAAAAAAACA4ub1IkRERGlpadx0001x1llntWnfsGHD4r777ot99tknUd1rrrkmvva1r0WXLl1y3jNw4MD49a9/HYceemiimhMmTIiJEydGZWVlznuqqqpi6tSpMW7cuEQ1AQAAAAAAACg+QhdklJWVxQ9/+MOYPn16HHbYYVFS0vpfj9133z2+973vxcyZM2PIkCGJa6ZSqbjsssviwQcfjBNOOCHKyspaXdu3b9/42te+FrNmzYpPfOITiWtGRJxxxhkxa9asOP3006Nr166trquqqooLLrggHnnkkTj66KN3qCYAAAAAAAAAxcXrRTqY8ePHx/jx4/Pawyc/+cm4/fbbY+XKlTF37tx46623oq6uLsrKyqJfv34xYsSIxE+2aM3+++8fU6ZMibVr18acOXPizTffjI8++ii6dOkSu+yyS+y///4xfPjwSKVS7VZz8ODB8ZOf/CSuvvrqmDt3bixcuDDWrFkTqVQqqqurY9iwYTFy5MgoLXVNAAAAAAAAANiaf02mVdXV1Tv96Q49evSIww8/PA4//PCdVrOioiJGjx4do0eP3mk1AQAAAAAAACh8Xi8CAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBsIOm3Dcn3y0AAAAAAAAAeSB0AbCDGho35rsFAAAAAAAAIA+ELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAKXFlpSUye9ny+2wAAAAAAAIBOR+gCoAg0NG7MdwsAAAAAAADQ6QhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBUATKSkti8rTn890GAAAAAAAAdCpCFwBFoqFxY75bAAAAAAAAgE5F6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhC4AiUVZaEpOnPZ/vNgAAAAAAAKDTELoAKCINjRvz3QIAAAAAAAB0GkIXAAAAAAAAAAAJCF0AAAAAAAAAACQgdAEAAAAAAAAAkIDQBQAAAAAAAABAAkIXAAAAAAAAAAAJCF0AAAAAAAAAACQgdAEAAAAAAAAAkIDQBQAAAAAAAABAAkIXAAAAAAAAAAAJCF0AAAAAAAAAACQgdAEAAAAAAAAAkIDQBQAAAAAAAABAAkIXAAAAAAAAAAAJCF0AAAAAAAAAACQgdAEAAAAAAAAAkIDQBQAAAAAAAABAAkIXAEVo8rTn890CAAAAAAAAFD2hC4Ai1NC4Md8tAAAAAAAAQNETugAAAAAAAAAASEDoAgAAAAAAAAAgAaELAAAAAAAAAIAEhC4AAAAAAAAAABIQugAAAAAAAAAASEDoAgAAAAAAAAAgAaELgCJSVloSU+6bk+82AAAAAAAAoFMQugAoMg2NG/PdAgAAAAAAAHQKQhcAAAAAAAAAAAkIXQAAAAAAAAAAJCB0AQAAAAAAAACQgNAFAAAAAAAAAEACQhcAAAAAAAAAAAkIXQAUobLSkpg87fl8twEAAAAAAABFTegCoEg1NG7MdwsAAAAAAABQ1IQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhCwAAAAAAAACABIQuAIrc5GnP57sFAAAAAAAAKEpCFwBFrqFxY75bAAAAAAAAgKIkdAEAAAAAAAAAkIDQBQAAAAAAAABAAkIXAAAAAAAAAAAJCF0AAAAAAAAAACQgdAEAAAAAAAAAkIDQBUCRKistiSn3zcl3GwAAAAAAAFC0hC4AilhD48Z8twAAAAAAAABFS+gCoEiVlZZk/nPytOfz3A0AAAAAAAAUH6ELgE7AEy8AAAAAAACg/QldAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQB0IlMnvZ8vlsAAAAAAACAoiF0AdCJNDRuzHcLAAAAAAAAUDSELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AOgEykpLYsp9c/LdBgAAAAAAABQVoQuATqKhcWO+WwAAAAAAAICiInQBAAAAAAAAAJBAab4bgE3q6upi7ty5sXjx4lizZk2UlpbGrrvuGvvtt18ccMABkUql2r1mQ0NDzJ07NxYtWhSrV6+OVCoV1dXVMWzYsBg5cmR06dKl3WsCAAAAAAAAUByELoj99ttvh88YMWJEPPjgg4n2vvrqq3HLLbfEH//4x2hsbGxxTb9+/eLzn/98XHjhhdGtW7cdaTUiIt5555249dZbY9asWbFu3boW11RVVcX48eNjwoQJ0adPnx2uCQAAAAAAAEBx8XoR8iadTsfUqVNj/Pjx8fDDD7cauIiI+OCDD+Kmm26KcePGxYsvvrhDdWfMmBHjxo2LGTNmtBq4iIhYvXp13HHHHXHiiSfGk08+uUM1AQAAAAAAACg+QhfkzbXXXhtTpkyJpqamnPe89957cd5558Wzzz6bqOYvf/nL+P73vx/19fU571m1alVcfPHF8dBDDyWqCQAAAAAAAEBx8noRtnLmmWdGz54927RnwIABbVo/ffr0uOeee7LmunXrFmeeeWaceOKJsfvuu0ddXV0sWLAgpk2bFn/9618z6+rr6+Oyyy6L3/72tzFw4MCcaz7xxBMxefLkrLmysrI45ZRT4tRTT40hQ4ZEY2NjLFq0KO6777547LHHIp1OR0REc3NzXHXVVbHnnnvGiBEj2vS9AgAAAAAAAFCchC7Yype//OUYPHjwx3b+8uXL44Ybbsia69+/f9x+++0xbNiwzFx1dXUMHjw4xowZE7/61a/i+uuvz4QgVq1aFdddd138/Oc/z6nmhg0b4pprrsnsj4jo2bNnTJ06NQ499NCstQMGDIjPfOYzMWvWrLjqqqsyrz1paGiIq6++Oh544IFE3zcAAAAAAAAAxcXrRdjpbr311li/fn1m3KVLl5g6dWpW4GJLF154YZx33nlZc4899ljMmzcvp5r33HNPLF26NGtu0qRJWwUuNjdu3Li48sors+Zqa2tj9uzZOdUEAAAAAAAAoLgJXbBTLV++PO67776suXPOOSdqamq2u/fyyy+Pfv36ZcbpdDqmTp263X2NjY1x2223Zc2NHTs2jjnmmO3uPf/882P48OFZczfffPN29wEAAAAAAABQ/IQu2Kkef/zxzOs6IiJSqVScf/75Oe3t1q1bnHbaaVlzf/nLX6Kurm6b+55++ulYsWJF1lyuNUtKSuLss8/Omps/f368+eabOe0HAAAAAAAAoHgJXbBTPf7441njQw45JHbfffec948fPz5r3NDQEE899VSbag4aNChGjx6dc81x48ZFRUXFNs8EAAAAAAAAoPMRumCnaWhoiL///e9Zc4ceemibzthjjz1iwIABWXN//vOft7nnL3/5S9Z41KhRkUqlcq7ZrVu3rV5/sr2aAAAAAAAAABQ/oQt2msWLF0dDQ0PW3MEHH9zmc7bcs2DBglbX1tXVxTvvvLNTawIAAAAAAADQOZTmuwE6noaGhnj++efjtddeixUrVkRzc3P07t07qqurY8SIETFkyJBE5y5atGiruaFDh7b5nC33vPHGGzu95sqVK2PVqlXRu3fvNp8FAAAAAAAAQHEQumArJ598cjQ1NbX6ed++feOEE06ICy+8MAYNGpTzuQsXLswad+nSJfr379/m/rZ8vUhdXV0sXbq0xbO2rBkRMXDgwB2uuensQw45pM1nAQAAAAAAAFAcvF6ErWwrcBERsWzZsrj77rvjuOOOi8mTJ293/SYffPBB1rhv377RpUuXNvfXUtBj6dKlOdVMpVKJgh5tqQkAAAAAAABA5+BJFyTW2NgYv/jFL2LOnDlx6623Rs+ePbe5ft26dVnjHj16JKrb0r66urqcalZWVkZZWVm71Nzy7ELS1NQUqVQq320UnJYCRk1NTZGO5lb3pCO2+XmStTuyLh3N0djYmFM/UCxau7tAx+buQmFyd6EwubtQmNxdKFzuLxQmd7dj6gh/BkIXRERESUlJHHjggXHkkUdGTU1NDB06NHr37h3l5eWxZs2aePvtt+OZZ56JBx54IBYvXpy197nnnouvf/3rcdttt0Vpaet/pbYMKVRUVCTqtaV9rQUg8lGzEMyfPz/fLRSNV155JdatWx/RSoalvLQkGpvSkY70ds/Kde2OrGto3Bi1tbXR3JxbEASK1csvv5zvFoAE3F0oTO4uFCZ3FwqTuwuFy/2FwuTuEiF0QUR86UtfirPOOit23333Fj/fZZddYpdddomDDjooLrroorj33ntj0qRJ0dDQkFnz17/+NW6++eb4+te/3mqd9evXZ42TBiAqKyu3mmstAJGPmgAAAAAAAAB0DiX5boD8+/a3v91q4GJLJSUlcc4558QvfvGLrV7Tceedd8aHH374cbQIAAAAAAAAAB2O0AWJfOpTn4rLL788a27dunVx7733trqna9euWeMNGzYkql1fX7/VXLdu3TpMTQAAAAAAAAA6B68XIbHzzjsv7rzzzvjggw8yc0899VRcdtllLa7fMqSQNADR0r7WAhD5qFkIDjjggK2eVML2NTU1bfVurv333z9m177U6p6y0pIobWrO6fxc1+7IurKy5qipqcmpHygWLd3d4cOHR2mp/xkEHZm7C4XJ3YXC5O5CYXJ3oXC5v1CY3N2OqbGxMebPn5/XHvwNILHy8vI4+uij4/7778/Mvfjii1FfXx+VlZVbrd8ypLB27dpEdVva17179xbXblmzvr4+mpqa2vzDr6WahRy6KC0tFbpoJ6WlpZHaxkODUlESqRzPynXtjqxLRfizh/BzEAqVuwuFyd2FwuTuQmFyd6Fwub9QmNzd/Eun0/luwetF2DEHHXRQ1njjxo2xfPnyFtf269cva7xs2bLYuHFjm2suWbJku2e3Np9Op+P999//WGsCAAAAAAAA0DkIXbBDdtlll63mVqxY0eLavffeO2u8cePGWLp0aZtrbhmA6N69ewwYMCCnmi3tT1IzImLo0KFtPgcAAAAAAACA4iF0wQ5p6XEtqVTLLz5oKaSwcOHCNtdctGhR1nivvfZqdW1LoYv2qFldXR3V1dVtPgcAAAAAAACA4iF0wQ5p6VUiffr0aXHtkCFDory8PGtuzpw5ba75wgsvZI333XffVtf26NEjBg8evMM1n3/++ZxrAgAAAAAAANA5CF2wQ+bOnZs17tKlS4uvHImIKC8vj09/+tNZc88880yb6r399ttbverjqKOO2uaeI444Imv87LPPtqnm+vXro7a2tk01AQAAAAAAACh+QhckVl9fH3/+85+z5kaOHBmVlZWt7hk7dmzW+Lnnnou3334755ozZ87MGpeXl8dhhx22zT1b1nz33Xfj6aefzrnmQw89FBs2bNjmmQAAAAAAAAB0PkIXJHbXXXfFsmXLsuYOP/zwbe4ZO3ZslJWVZcbpdDqmTZuWU73169fHb37zm6y5I444Irp3777NfaNHj97qlSd33313TjWbm5tj+vTpWXMHHHBA7LnnnjntBwAAAAAAAKB4CV10YsuWLYuNGzcm2vvUU0/Fz3/+86y5rl27xuc///lt7tt11123WjNt2rR4+eWXt1vzZz/7WSxdujQzTqVScckll2x3X1lZWXz5y1/Omps9e3Y88cQT2907bdq0mDdvXtbcpZdeut19AAAAAAAAABQ/oYtObNasWXHSSSfFAw88EHV1dTntaWpqijvvvDMuvvjiaGpqyvrsggsuiL59+273jIsvvji6du2adeYll1wSr7/+eqt77rzzzrjrrruy5o477rgYMWJETn2fc8450b9//6y5b3/72/Hcc8+1uuehhx6KG264IWuupqYmjj322JxqAgAAAAAAAFDcSvPdAPm1ePHi+N73vhfXXnttHH744XHwwQfHAQccELvttlv06NEjKioqYs2aNfH222/HM888Ew8++GC8++67W51z2GGH5fwEiL59+8aVV14ZP/7xjzNzS5Ysic997nNx5plnxkknnRSDBw+OdevWxauvvhrTpk2Lp556KuuM3r17x3e+852cv8+Kior44Q9/GF/96lczc2vWrIkLLrggxo8fH6ecckoMGTIkGhsbY9GiRXH//ffHI488Eul0OrO+vLw8rr322pxrAgAAAAAAAFDchC6IiIj6+vqYPXt2zJ49u817P/WpT8WUKVOirKws5z3nnntuvP7663Hvvfdm5urq6uL222+P22+/fZt7Kysr46abbopBgwa1qc8xY8bEFVdcETfeeGNmrrGxMe6///64//77t7m3pKQkJk2alPOTNQAAAAAAAAAofl4vQmJdu3aNK6+8Mu64447o0aNHm/dfc8018bWvfS26dOmS856BAwfGr3/96zj00EPbXC8iYsKECTFx4sSorKzMeU9VVVVMnTo1xo0bl6gmdGSTpz2f7xYAAAAAAACgYHnSRSd20kknRXl5eTz99NPx0ksvtfjakC2VlJTEvvvuGyeffHKcccYZUVVVlbh+KpWKyy67LI455pi45ZZb4vHHH4/GxsYW1/bt2zfOPPPM+OIXvxjdu3dPXDMi4owzzohPf/rTccstt8SsWbNi/fr1La6rqqqKU089Nb7yla9Enz59dqgmdFQNjRvz3QIAAAAAAAAULKGLTqxfv35x9tlnx9lnnx0REWvWrIlFixbFkiVLYvny5bF+/fpoamqKHj16RK9evWLAgAFRU1OT6KkW27L//vvHlClTYu3atTFnzpx4880346OPPoouXbrELrvsEvvvv38MHz48UqlUu9UcPHhw/OQnP4mrr7465s6dGwsXLow1a9ZEKpWK6urqGDZsWIwcOTJKS10RAAAAAAAAAFrmX5TJ6NWrVxx00EFx0EEH5aV+jx494vDDD4/DDz98p9WsqKiI0aNHx+jRo3daTQAAAAAAAACKQ0m+GwAgP6bcNyffLQAAAAAAAEBBE7oA6KQaGjfmuwUAAAAAAAAoaEIXAAmVlJTEzb95Md9tAAAAAAAAAHkidAGwAxqaPC0CAAAAAAAAOiuhCwAAAAAAAACABIQuAAAAAAAAAAASELoAAAAAAAAAAEhA6AIAAAAAAAAAIAGhC4BOpKy0JCZPez7fbQAAAAAAAEBRELoA6GTS6XRMuW9OvtsAAAAAAACAgid0AdAJNTRuzHcLAAAAAAAAUPCELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgAAAAAAAAAAEhC6AAAAAAAAAABIQOgCAAAAAAAAACABoQsAAAAAAAAAgASELgCIydOez3cLAAAAAAAAUHCELgCIhsaN+W4BAAAAAAAACo7QBQAAAAAAAABAAkIXAAAAAAAAAAAJCF0AAAAAAAAAACQgdAHQiZWVlsSU++bkuw0AAAAAAAAoSEIXAJ1cQ+PGfLcAAAAAAAAABUnoAgAAAAAAAAAgAaELAAAAAAAAAIAEhC4AAAAAAAAAABIQugAAAAAAAAAASEDoAgAAAAAAAAAgAaELAAAAAAAAAIAEhC4AAAAAAAAAABIQugAAAAAAAAAASEDoAgAAAAAAAAAgAaELAAAAAAAAAIAEhC4AAAAAAAAAABIQugAAAAAAAAAASEDoAgAAAAAAAAAgAaELgIRKSvwIBQAAAAAAgM7MvxgCJFBSUhKznluT7zYAAAAAAACAPBK6AEiooak53y0AAAAAAAAAeSR0AQAAAAAAAACQgNAFAFFW6r8OAAAAAAAAoK38KxsAAAAAAAAAQAJCFwAAAAAAAAAACQhdAJAxedrz+W4BAAAAAAAACobQBQAZDY0b890CAAAAAAAAFAyhCwAAAAAAAACABIQuAAAAAAAAAAASELoAoFWTpz2f7xYAAAAAAACgwxK6AKBVDY0b890CAAAAAAAAdFhCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUAAAAAAAAAQAJCFwAAAAAAAAAACQhdAAAAAAAAAAAkIHQBAAAAAAAAAJCA0AUALZpy35x8twAAAAAAAAAdmtAFAFFWWrJVyKKhcWOeugEAAAAAAIDCIHQBQEQIWQAAAAAAAEBbCV0AAAAAAAAAACQgdAEAAAAAAAAAkIDQBQAAAAAAAABAAkIXAAAAAAAAAAAJCF0AAAAAAAAAACQgdAEAAAAAAAAAkIDQBQAAAAAAAABAAkIXAAAAAAAAAAAJCF0AkFFWWhKTpz2f7zYAAAAAAACgIAhdAJCloXFjvlsAAAD4f+3dd3hUVf7H8c+kkQaEgIHQixQNCIhiV0BFRV3AShVQREDKuqsC6tqWn6CCyKqAoAICgkpRdmkK2HGpoYQqXVoSIBBSSJ3fH0o2d0oyczPJZDLv1/Pss94z99xzMsx3zr1zv/ccAAAAAAB8AkkXAAAAAAAAAAAAAAAAJpB0AQAAAAAAAAAAAAAAYAJJFwAAAAAAAAAAAAAAACaQdAEAMAgOCtDkBfHe7gYAAAAAAAAAAABQ7pF0AQCwk52T5+0uAAAAAAAAAAAAAOUeSRcAAAAAAAAAAAAAAAAmkHQBACjWhLmbvd0FAAAAAAAAAAAAoNwh6QIAUCyWGwEAAAAAAAAAAADskXQBAAAAAAAAAAAAAABgAkkXAGBCQECAZPF2LwAAAAAAAAAAAAB4E0kXAAAAAAAAAAAAAAAAJpB0AQAAAAAAAAAAAAAAYAJJFwAAAAAAAAAAAAAAACaQdAEAAAAAAAAAAAAAAGACSRcAAAAAAAAAAAAAAAAmkHQBAAAAAAAAAAAAAABgAkkXAAAAAAAAAAAAAAAAJpB0AQBwKjgoQJMXxHu7GwAAAAAAAAAAAEC5RNIFAKBI2Tl53u4CAAAAAAAAAAAAUC6RdAEAAAAAAAAAAAAAAGACSRcAAAAAAAAAAAAAAAAmkHQBAAAAAAAAAAAAAABgAkkXAAAAAAAAAAAAAAAAJpB0AQAAAAAAAAAAAAAAYAJJFwAAAAAAAAAAAAAAACaQdAEAAAAAAAAAAAAAAGACSRcAAAAAAAAAAAAAAAAmkHQBAAAAAAAAAAAAAABgAkkXAAAAAAAAAAAAAAAAJpB0AQBwy4S5m73dBQAAAAAAAAAAAKBcIOkCAOCW7Jw8b3cBAAAAAAAAAAAAKBdIugAAFCs4KIAZLgAAAAAAAAAAAAAbJF0AAFzCDBcAAAAAAAAAAACAEUkXAAAAAAAAAAAAAAAAJpB0AQAAAAAAAAAAAAAAYAJJFwAAAAAAAAAAAAAAACaQdAEAAAAAAAAAAAAAAGACSRcAAAAAAAAAAAAAAAAmkHQBAAAAAAAAAAAAAABgAkkXAAAAAAAAAAAAAAAAJpB0AQAAAAAAAAAAAAAAYAJJFwAAAAAAAAAAAAAAACaQdAEAAAAAAAAAAAAAAGACSRcAAAAAAAAAAAAAAAAmkHQBAAAAAAAAAAAAAABgAkkXAAAAAAAAAAAAAAAAJpB0AQAAAAAAAAAAAAAAYAJJFwAAAAAAAAAAAAAAACaQdAEAAAAAAAAAAAAAAGACSRcAAAAAAAAAAAAAAAAmkHQBAAAAAAAAAAAAAABgAkkXAAAAAAAAAAAAAAAAJpB0AQBwSXBQgKYs3ObtbgAAAAAAAAAAAADlBkkXAACXZefkebsLAAAAAAAAAAAAQLlB0gUAAAAAAAAAAAAAAIAJJF0AADxq8oJ4TZi72dvdAAAAAAAAAAAAAEodSRcAANMcJVdk5+SxDAkAAAAAAAAAAAD8AkkXAADTrFYrs1oAAAAAAAAAAADAbwV5uwMAAN8SHBSgyQviC7aZ1QIAAAAAAAAAAAD+iqQLAIDbSLQAAAAAAAAAAAAAWF4EAOBBhWfAAAAAAAAAAAAAACo6ki4AAB7DDBgAAAAAAAAAAADwJyRdAAAAAAAAAAAAAAAAmEDSBQDAI1haBAAAAAAAAAAAAP6GpAsAgEewtAgAAAAAAAAAAAD8DUkXAAAAAAAAAAAAAAAAJpB0AQAAAAAAAAAAAAAAYAJJFwAAAAAAAAAAAAAAACaQdAEAKJHgoABNXhDv7W4AAAAAAAAAAAAAZY6kCwBAiWXn5Hm7CwAAAAAAAAAAAECZI+kCAAAAAAAAAAAAAADABJIuAAAAAAAAAAAAAAAATCDpAgAAAAAAAAAAAAAAwASSLgAAAAAAAAAAAAAAAEwg6QIAAAAAAAAAAAAAAMAEki4AAAAAAAAAAAAAAABMIOkCAOBxwUEBmrwg3tvdAAAAAAAAAAAAAEoVSRcAgFKRnZPn7S4AAAAAAAAAAAAApYqkCwAAAAAAAAAAAAAAABNIugAAAAAAAAAAAAAAADCBpAsAAAAAAAAAAAAAAAATSLoAAHjNhLmbvd0FAAAAAAAAAAAAwDSSLgAAXpOdk+ftLgAAAAAAAAAAAACmkXQBAChVzGYBAAAAAAAAAACAioqkCwBAqbo0mwXJFwAAAAAAAAAAAKhoSLoAAJQJlhIBAAAAAAAAAABARUPSBQAAAAAAAAAAAAAAgAkkXQAASlVwUIAmL4j3djcAAAAAAAAAAAAAjyPpAgBQKgonWzhaWoREDAAAAAAAAAAAAPg6ki4AAKXGUbKF9EfChbPXAAAAAAAAAAAAAF9B0gUAoMyRcAEAAAAAAAAAAICKgKQLAIDXBAcFaMLczd7uBgAAAAAAAAAAAGAKSRcAgDI1eUG8YdvVWS8KJ2eQqAEAAAAAAAAAAIDygKQLAECZMru0SOF6LE8CAAAAAAAAAACA8oCkCwAAAAAAAAAAAAAAABNIugAAlIngoAC7pUUAAAAAAAAAAAAAX0bSBQCgzHhqWZDgoABNmLvZI8cCAAAAAAAAAAAAzCLpAgBQ7riSUOGpBA4AAAAAAAAAAADALJIuAADljtVqZSYLAAAAAAAAAAAAlHskXQAAyqXCM1lMXhDvxZ4AAAAAAAAAAAAAjpF0AQAo1yYviGcpEQAAAAAAAAAAAJRLJF0AALwqOChAkxfEFywnYjurBQkXAAAAAAAAAAAAKK+CvN0BAACyc/KUk5tf8N+OBAeRJwgAAAAAAAAAAIDyhTtYAACvcjWZIjgooGA2DAAAAAAAAAAAAKA8IOkCAOAzWGoEAAAAAAAAAAAA5QlJFwAAAAAAAAAAAAAAACaQdAEAKJeCgwI0eUG8t7sBAAAAAAAAAAAAOEXSBQCg3GI5EQAAAAAAAAAAAJRnJF0AAHwGs18AAAAAAAAAAACgPCHpAgBQLriaUOHK7BdmEzMmzN1sqh4AAAAAAAAAAAD8E0kXAIByw1PLiZg9DsuZAAAAAAAAAAAAwB0kXQAAfFJwUIDTmSmKeg0AAAAAAAAAAADwFJIuAAA+y3ZmisKJFoVfIwEDAAAAAAAAAAAApYGkCwBAhTB5QbysVqsmL4i3e41lQwAAAAAAAAAAAFAaSLoAAFQIlxIrSLAAAAAAAAAAAABAWSHpAgAAAAAAAAAAAAAAwASSLgAAFZqj5UZcNWHuZg/2BAAAAAAAAAAAABVNkLc7AHhbUlKStm/frmPHjikjI0OhoaGKjY1Vy5YtVa9ePW93D4ALHCVWBAcFaPKCeLvlRibM3axn+7Sz+39HWKoEAAAAAAAAAAAARSHpAn5r7dq1mjFjhuLj42W1Wh3u06JFCw0YMEBdu3aVxWIp4x4CcJWz5IhL5cFBAQXJFZfKbP/fVklmyAAAAAAAAAAAAIB/YHkR+J309HSNGDFCQ4YM0ZYtW5wmXEjSnj17NGrUKD322GM6ffp0GfYSgKdZrVaXEykczZABAAAAAAAAAAAA2CLpAn4lPT1dAwYM0KpVq9yqt2HDBvXq1UvJycml1DMAZlxaQsRV2Tl5BXUK//+EuZvt9gMAAAAAAAAAAACKw/Ii8CsvvPCCtm3bZiirXbu2+vfvrxtuuEG1atVScnKytmzZopkzZ+rAgQMF+x05ckTDhw/X3LlzFRRE6ADlhZkEiUt1Ls10Q5IFAAAAAAAAAAAAzGCmC/iNtWvXauXKlYay9u3ba+nSperXr5+aNWumKlWqqEmTJnr44Yf11Vdf6e677zbsHx8frwULFpRltwEAAAAAAAAAAAAA5RRJF/ALVqtVkydPNpTVrl1bU6dOVeXKlR3WCQkJ0TvvvKO4uDhD+bRp05SZmVlqfQVQ9txdpgQAAAAAAAAAAACQSLqAn1izZo327NljKHvxxRcVGRlZZL3AwECNHTvWUJacnKwvvvjC430E4F2Olhi5lIwxYe5mu9cclZWEp48HAAAAAAAAAACA0kfSBfzCihUrDNt16tTR7bff7lLdK6+8Uu3atTOU2S5TAqBicDTjRXZOXkFCRuHEiMJJGs4SM9zhKOkDAAAAAAAAAAAA5RtJF6jwcnJy9MMPPxjKunbtKovF4vIxunfvbtjeunWrzpw545H+AShfikp+KPxacFBAQaJFdk6erFarIfGiqCSM4hI0mPUCAAAAAAAAAADAN5B0gQpv69atunDhgqGsffv2bh3juuuuM2zn5+frp59+KnHfAPiG8NAguxkwJPsEjcLbriZvmHkdAAAAAAAAAAAA5QNJF6jw9u7da9gODAxU69at3TpG/fr1VaNGjSKPC6Bis11ORHK8HIm7Ji+IL/ExygKzbwAAAAAAAAAAANgj6QIV3sGDBw3bsbGxCg8Pd/s4jRs3NmwfOnSoRP0C4HsuJVk4m9EiOChAUxZu0+QF8YblRy6x3b50rJLObFEWCRHMvgEAAAAAAAAAAGCPpAtUeAcOHDBs165d29RxYmNjDdu2yRwA/IMrS4Nc2sd2X6vVapjVwjZhw2zyhKcTIhz141LCSVnPeMEMGwAAAAAAAAAAoDwj6QIVXlJSkmG7Vq1apo5jm3SRmJhouk8A/MOlRIXCS4hk5+QVzIhhyzYp45LiZswortyZwvsX/m9HS6lcKrdarQ7bufQ3XnqtuL648jdMWbjN0J6nEjACAhyf/pDgAQAAAAAAAAAA3BXk7Q4ApS0jI8OwHRkZaeo4tvUuXryo/Px8pzfvygOr1eqwPDMzU7m5uWXcG99X+D2zWq0KDbYoJNAqiyXfaZ2gIMki56+b2dfT+/nKMX22bev//juk0KhrteYoJMjBMa35igiVpny5WTm5+Xqya5zCKlk15ctCCQHWHGVkZGjWst1/HjdfGRkZCg7MU0ZGhmZ8vVNPdo0reN2uj4EW5eZZFRyY97/j/nnMwscrXF64rzm5+Yb2/zimVbm5+ZL1f30p/DdIKuiXbXuSCo4VHJinyfM36smucYb3aMqXm+3q2B2z0LEKt5ubmyuLxVLw+jfxF9SkSaZmfLW94O95smuc4fiOjltUGwA8z9G5SmZmpnJycrzQGwCuInYB30TsAr6J2AV8F/EL+CZit3xy9v47u09aGizWsmwN8IJrr71WqampBduPP/64Ro0a5fZx5syZo7FjxxrKNm/ebDqJoyykp6drz5493u4GAAAAAAAAAAAAAJSZFi1aKCIiokzaKr+P6AMekpmZadgOCQkxdZzQ0FC7svT0dFPHAgAAAAAAAAAAAAD4PpIuAAAAAAAAAAAAAAAATCDpAhVeWFiYYTs7O9vUcS5evGhXVlZT0gAAAAAAAAAAAAAAyh+SLlDhhYeHG7YdJU+4wlE922MDAAAAAAAAAAAAAPxHkLc7AJQ228SItLQ0U8exrRcaGqqAgPKdtxQWFqYWLVrYlQcFBclisXihRwAAAAAAAAAAAADgGVarVbm5uXbltqshlCaSLlDhxcTE6ODBgwXbp06dMnUc23oxMTEl6ldZCAgIYAkUAAAAAAAAAAAAABVWpUqVvNp++X5MH/CAxo0bG7ZPnDhh6ji29Zo0aWK6TwAAAAAAAAAAAAAA30fSBSo82+SIU6dOKSMjw+3jHDp0yLDdqFGjEvULAAAAAAAAAAAAAODbSLpAhde8eXPDdm5urrZv3+7WMY4ePark5OQijwsAAAAAAAAAAAAA8C8kXaDCa9OmjSpXrmwo27Bhg1vHsN0/ICBAt9xyS4n7BgAAAAAAAAAAAADwXSRdoMILDg7WbbfdZij7+uuvZbVaXT7GV199Zdhu06aNqlev7onuAQAAAAAAAAAAAAB8FEkX8Av33HOPYfvYsWNau3atS3X37NmjjRs3Gsruvvtuj/UNAAAAAAAAAAAAAOCbLFZ3HvcHfJTValXXrl21d+/egrI6dero3//+tyIiIpzWy8vL0yOPPKKEhISCsssuu0zffvutwsLCSrXPAAAAAAAAAAAAAIDyjZku4BcsFov++te/GsqOHz+uIUOGKC0tzWGd7OxsPfvss4aEC0kaPHgwCRcAAAAAAAAAAAAAAGa6gH8ZMWKEVq1aZSirU6eOBgwYoBtuuEExMTE6ffq0tmzZopkzZ2r//v2Gfdu2bau5c+cqKCioLLsNAAAAAAAAAAAAACiHSLqAX0lLS9OAAQO0fft2t+vWr19f8+bNU0xMTCn0DAAAAAAAAAAAAADga1heBH4lMjJSM2fO1J133ulWvWuuuUbz588n4QIAAAAAAAAAAAAAUICZLuC31qxZoxkzZig+Pt7pPs2bN9eAAQPUrVs3WSyWMuwdAAAAAAAAAAAAAKC8I+kCfi8xMVHbtm3T8ePHlZGRodDQUMXGxqpVq1aqV6+et7sHAAAAAAAAAAAAACinSLoAAAAAAAAAAAAAAAAwIcDbHQAAAAAAAAAAAAAAAPBFJF0AAAAAAAAAAAAAAACYQNIFAAAAAAAAAAAAAACACSRdAAAAAAAAAAAAAAAAmEDSBQAAAAAAAAAAAAAAgAkkXQAAAAAAAAAAAAAAAJhA0gUAAAAAAAAAAAAAAIAJJF0AAAAAAAAAAAAAAACYQNIFAAAAAAAAAAAAAACACSRdAAAAAAAAAAAAAAAAmEDSBQAAAAAAAAAAAAAAgAkkXQAAAAAAAAAAAAAAAJhA0gUAAAAAAAAAAAAAAIAJJF0AAAAAAAAAAAAAAACYQNIFAAAAAAAAAAAAAACACSRdAAAAAAAAAAAAAAAAmEDSBQAAAAAAAAAAAAAAgAkkXQAAAAAAAAAAAAAAAJhA0gUAAAAAAAAAAAAAAIAJJF0AAAAAAAAAAAAAAACYEOTtDgCAr0hKStL27dt17NgxZWRkKDQ0VLGxsWrZsqXq1avn7e4BFVp6erq2bt2qw4cPKzU1VUFBQapRo4aaN2+uK664QhaLxeNtZmdna+vWrTp48KDOnz8vi8WiatWqqWnTpmrVqpUCAwM93mZubq4SEhL022+/KSUlRVarVVWrVlXjxo3Vpk0bhYSEeLxNwBXnzp3T1q1bdfToUaWnpyskJEQxMTG68sor1aRJk1Jpk7gn7uGb/CWOrFardu/erb179+r06dPKzc1VlSpV1LBhQ7Vp00YREREebxNl69SpU9q3b59Onjyp8+fPS5KqVq2q6tWrq1WrVqpZs2aptMv4R9yiZLwVu97gT3F04MAB7dy5U8nJycrOzlZERITq16+vNm3aKCoqqlTaRNnJzs7WkSNHdOLECZ06dUppaWnKyspSeHi4IiMjVbduXbVs2VKRkZEeb5tr3Yo11qNseTN2vcFf4ohzZvNIugCAYqxdu1YzZsxQfHy8rFarw31atGihAQMGqGvXrqVyYgx4S/PmzUt8jLi4OC1evNhU3b1792rq1KlavXq1cnJyHO4TExOjRx99VI8//rjCw8NL0lVJ0rFjxzRt2jQtW7ZMGRkZDvepWrWqHnjgAQ0aNEjR0dElbvPs2bOaPn26Fi9eXPDDoK3w8HDde++9Gjx4sOrWrVviNuFbUlJSlJCQoB07dmj79u1KSEhQcnKyYZ9hw4Zp+PDhHm1306ZNmjZtmtatW6e8vDyH+zRo0EB9+vRRz549FRwcXOI2ifv/Ie59X1nFbqdOnXT8+PESHSMqKkrr1683Xd9f4ig9PV0zZ87UggUL7P4tLwkODtYdd9yhIUOGeORcCmXj9OnTWrt2rX799VetX79eZ86cKXL/evXq6aGHHtIjjzzikc8z49//ELdwR1nHbt++fbVhwwaz3S2wZcsW0zct/CWOcnJyNH/+fM2ZM0dHjx51uE9gYKBuuukmPfXUU7rmmmtK3CbKxqlTp/Tjjz9qy5YtSkhI0KFDh5Sbm1tkHYvFopYtW+rBBx9U165dSzwOcq37PxVhrEfZ8Ebscq1bscf6isZidXYHEQD8XHp6usaMGaNVq1a5XKd9+/aaNGmSatSoUYo9A8qOt5IurFarpk6dqg8++KDYk/dLateurcmTJ+uqq64y001J0pdffqmxY8fq4sWLLu0fFRWlt956S7fddpvpNr///nuNGjVK586dc2n/sLAwvfTSS3rooYdMtwnfMHPmzIIbtb///nux+3sy6SInJ0fjxo3TvHnzXK7TrFkzvffee2rYsKGpNol754h73+KN2PX2D1H+Ekfbtm3TyJEjdfLkSZf2DwoK0rBhwzRkyBDTbaL07dixQ2+//bY2btyo/Px8t+tHRETohRdeMP3ZYvxzjrhFUbwVu95OuvCXODp8+LCGDx+uffv2uVynT58+Gj16tEdujqN0TZkyRZMnTzZdv3bt2nr11VdNjUlc6zrnq2M9yo43Ypdr3eL56lhfEQV4uwMAUB6lp6drwIABbiVcSNKGDRvUq1cvp5mAAFzz+uuva/LkyS5fjErSiRMn1LdvX23cuNFUmx999JFeeukll0+ipT+moRw8eLCWL19uqs1ly5ZpyJAhLp9ES1JmZqZefPFFffzxx6bahO8YP368li1b5tJNW0/Kzc3VyJEj3foRSpL27dunnj176sCBA6baJe6dI+59i7di11v8JY42btyoxx57zOUfoaQ/vk/fffddvf7666baRNlISEjQ+vXrTd20lf64dnzxxRf1yiuvmKrP+OcccYuieDt2vcFf4ujAgQPq0aOHWwkXkjR37lyNHDnSre9T+KYTJ07oqaee0vz5892qx7Vu0XxxrIdvMRu73uIvccQ5s+ewvAgAOPDCCy9o27ZthrLatWurf//+uuGGG1SrVi0lJydry5YtmjlzpuGk+8iRIxo+fLjmzp2roCC+ZlGx9OjRQ5UrV3arTq1atdzaf968efrss88MZeHh4erRo4fuuece1atXT+np6dq3b5/mzp2rX375pWC/ixcvatiwYfrqq68UGxvrcpvfffedJkyYYCgLDg5Wt27d1L17dzVs2FA5OTk6ePCgFixYoG+++aZguaH8/HyNGjVKDRo0UFxcnMtt7ty5U6NHjzb8SBgQEKDOnTurR48eaty4sQIDA3X48GEtXrxYS5cuNUw/+fbbb6tx48bq2LGjy20Crpg4caLWrFljKKtWrZr69OmjO+64Q7GxsTp37pwSEhI0a9Ysbd++vWC/s2fPavDgwVqyZIlba3YS98Q9POu+++5zKx6kP56OcZe/xNHJkyc1bNgwux/bbr75ZvXp00fNmjVTWFiYjh07pmXLlumLL74wTDs7b948NWnSRL1793a5TXhXgwYNdOONN6p9+/Zq0qSJqlevrkqVKik5OVnx8fH64osvtHXrVkOdBQsWqHr16hoxYoTL7TD+EbfwrLKK3cJuu+02NWvWzO167s7G4C9xlJaWpsGDByslJcVQ3rp1a/Xv319xcXGqWrWqTp48qdWrV2vu3LmGG1Nr1qzRO++8o+eff97lNuFd9erV07XXXqurrrpKjRo1Ut26dRUZGamgoCClp6fr4MGD2rhxoxYvXmy4IWi1WvXqq6+qTp06uvXWW11qi2vdijXWw7vKMnYL41rX98f6iozlRQDAxtq1a+2mRWrfvr2mTJni8GZzdna2nnvuOa1cudJQ/o9//EN9+vQp1b4Cpc12eZE1a9aU6lqLp0+f1h133KHMzMyCspo1a+rjjz9W06ZNHdb55JNP9NZbb6nwKc1dd92lf/3rXy61mZWVpTvvvFOJiYkFZZUrV9aUKVPUvn17h3WWLVumUaNGGU5sW7ZsqUWLFrnUpiQ98MAD2rlzZ8F2cHCw3nrrLXXp0sXh/uvXr9fTTz+tCxcuFJTVrFlT3377rSpVquRyu/AdtvEXHh6uli1bqmXLlmrVqpWeeeYZw+ueWKJgz5496tatmyGemjZtqo8//lg1a9a0299qtWrcuHGaPXu2ofzxxx/XqFGjXGqTuCfuKxpvxK7tlKuffvqprrvuuhIdszj+FEfDhw/XN998U7BtsVg0evRo9e/f3+H+e/fu1ZNPPml4b8LCwrR69WqWISyH5s+fr1dffVVBQUHq0qWLHn74Yaef4cI+//xz/fOf/zR8noOCgvTVV185Hb8KY/wjblEy3opd2+VFxo0bpwceeMDcH+EGf4mj8ePHa+bMmYay/v37a/To0bJYLHb7nzp1SgMHDtRvv/1m6OdXX32lFi1auNQmyt6KFSt04sQJ3Xnnnapfv75LdS5evKi33nrLbpaKOnXqaNWqVcUmMnGtW/HGepQ9b8Qu17oVb6yvyFheBAAKsVqtduuS1a5dW1OnTnX6dH9ISIjeeecdu6zFadOmGU6qARTPNm4CAwM1ZcqUIn/8evzxx9W3b19D2TfffGM4SS3KZ599ZjhRlP74oaeoH+zuvfdePfvss4ayhIQEffvtty616ah/zz33nNOTaEm67rrrNH78eENZYmKiz0zJB/ddddVV6t27d8FSBZs3b9acOXM0atSoIj8rJfHuu+8aftyJiIjQjBkzHP4IJf1xMfbCCy/o9ttvN5Q7iitniHvivqLxRux6g7/EUUJCguFHKEl67LHHnP4IJf2ReDNlyhQFBgYWlGVmZmratGkutYmyFRAQoPvuu0/Lly/X22+/7dJNW0l69NFH9dprrxnKcnNz9cEHH7hUn/GPuEXJeCt2vcFf4igxMdFuRoA77rhDY8aMcZhwIf0xs+aMGTMUERFRUObotz2UL/fcc4+eeOIJl2/aSlJoaKhefvll3XvvvYby48ePa926dcXW51q3Yo318A5vxK43+Esccc7seSRdAEAha9as0Z49ewxlL774YrHTxgUGBmrs2LGGsuTkZH3xxRce7yNQUZ0+fVoLFiwwlPXu3VstW7Ystu4zzzyjmJiYgm2r1aopU6YUWy8nJ0fTp083lN1+++264447iq372GOP6corrzSUufpDne1+cXFxdhfVjtxxxx12F/zTp083ZFGj4vjyyy/18ssvq3v37rr88ssVEFC6p+67d+/Wd999ZygbMWKES9M2vvrqqwoNDS3YvnjxoktrSRL3xH1FVNax6w3+FEe23ysxMTF2s5U40rJlS7spVj///HOdOXOm2LooWw899JAmTpyoBg0auF33wQcftPvx9ccff1R2dnaR9Rj/iFuUnDdi11v8JY4++ugjZWVlFWyHhobqlVdeKbZebGys3fIwa9eutft9DxWDo8/hzz//XGQdrnUr3lgP32Mmdr3Bn+KIc2bPq3i//gBACaxYscKwXadOHbtBy5krr7xS7dq1M5TZLjkCwLk1a9YYTggtFosee+wxl+qGh4frwQcfNJT9+OOPSk9PL7Le+vXrdfbsWUOZq20GBASoV69ehrLdu3fryJEjRdY7dOiQ3Y8/vXv3dvmmnO0J95kzZ7Rx40aX6gJFsR0Dw8PD9dBDD7lUNyYmRp07dzaUrVq1qth6xD1xD9/kL3GUlpamH3/80VD28MMPu7wmcJ8+fQxP5mZnZ2vt2rUu1UXZKfyUlhndunUzbKenp2vv3r1F1mH8I25Rct6IXW/wlziyWq12v6HdfffdhhvPRXnooYcUHh5uKLO9vkHFUK9ePdWrV89QdurUqSLrcK1bPF8a6+GbzMSuN/hLHHHOXDpIugCAP+Xk5OiHH34wlHXt2tXpFIaOdO/e3bC9detWMvwAF61Zs8aw3a5dO7uT8aLYrqObnZ1dbMa0bZu1a9d2a13Ae++9126NPNtjFtdmpUqVdM8997jc5vXXX2/3NEZxbQKusP0c3XnnncXO9FSYbQyeOnVKCQkJbrVJ3DtG3KO88Zc4+umnn+yeELI93y9KgwYNdPXVV7vVJnxPixYt7MqSk5OLrMP45xriFqXJTOx6g7/E0Y4dO5SUlGQos02MKUpkZKTdU8jc/Km4atSoYdjOyMgocn+udV3jK2M9fJe7sesN/hJHnDOXDpIuAOBPW7du1YULFwxlrq4JeontAJyfn6+ffvqpxH0DKrrs7Gz9+uuvhjJ3469+/fqqVauWoez7778vso5tRu+1117rVqJVeHi43dSQ7rbZqlUruydyimKxWHTttde61SZQnBMnTmj//v2GMndjsG3btgoODjaUFfXZJO6Je/guf4kj2zZjY2Pd+rFcsv9eW7duXbmdvh7mFJ5y/JLC67fbYvwjblE+uBu73uIvcWTbZnBwsN3NHHfb3Ldvn06cOOHWMeAbUlNTDdvR0dFO9+Vat+KN9fBd7sSut/hLHHHOXDpIugCAP9lOIxkYGKjWrVu7dYz69evbZWyWx+kpgfLm8OHDdidl7v7A4qjOvn37nO6bnp6uY8eOlWmbkv13gifaPH78eLnMDofvcDRWufvZDA0NtVu7sqh4IO5L1iZxD2/xpzgqjTazsrKKnV4WvsXRDb2ifkBm/CtZm8QtPMXd2PUWf4kj2++TuLg4uyeF3W3T0XHh+86ePatDhw4Zyor6/ZZr3dJrU+JaF65zN3a9wZ/iiHPm0hHk7Q4AQHlx8OBBw3ZsbKxbGYWXNG7cWKdPny7Ytj2ZAHxZdna2Nm/erN9++01nz55Vfn6+oqKiVK1aNcXFxalhw4amjmsbf5LUpEkTt49jW6eo+CutNlNSUnTu3DlFRUXZ7Xv27FmdO3fO421arVYdPHjQLpMacJVtPAQFBZmK5yZNmmjbtm0F296IQeIe+GO2tYSEBO3evVtnz55VVlaWqlatqqioKLVo0ULNmjVz62mdwvwpjmy/Txo3blziNqU/3sOmTZu6fSyUT47WS65fv77T/Rn/StYmcQtPcTd2nbFardq3b58SEhJ0+vRpZWZmFoy5jRs3VlxcnAIDA0310Z/iyPZ7ykybDRs2VGBgoPLy8gzH7dChg9vHQvk1bdo05efnF2xXqlRJXbp0cbo/17ola7M8jvXwTe7GrjNc67rWZnkc6/0BSRcA8KcDBw4YtmvXrm3qOLbrZzkarAFfdf/99ys3N9fp65dddpnuvvtuPf74427FkG38BQYGqmbNmm73z3bqxfT0dCUmJjo8lm2bkn38mmnz0rHbtWtnV+7o+8BMm47qcEGKkrCNh5o1ayogwP1J8Wzj4fDhw8rLy3P4QzNx7x7iHu4YOHBgkeN1VFSUOnXqpIEDB7r9g46/xNHJkyftngwyc31w6fu08A+MXB9UHHl5eVq6dKmhrEmTJqpTp47TOox/7iFuURrMxK4zL7/8cpFjbkREhG6++WY98cQTbj/R6y9xlJeXp8OHD5e4zcDAQMXExOjkyZPFtgnfk5+fr48//lizZ882lA8ePLjIWWq41i1Zm5eOXV7Gevges7HrDNe6jpX3sd5fsLwIAPwpKSnJsO1ocHSF7QCXmJhouk9AeVPUSa0kJScna86cOercubMmTJhQ7P6X2MbfZZddZuppIEcniM5i0LZNi8Vi6iK4JG1K5k/ebbO2+a5BSXhqDLSNh+zsbLuMfWdtEvdFI+7hjuLG33Pnzmnx4sW69957NWbMGLfWsPeXOPJUm0FBQbrssstcahO+58svvzTc3JNU7BN7jH/uIW5RGszErjPFjbnp6elatWqVHnnkEQ0ePFhnz551+dj+EkcpKSnKyckxlPGbHPLz83XhwgXt2rVLc+bM0QMPPKAJEyYY9unWrZsGDx5c5HG41i27NiWudeG52HWGa13HyvtY7y+Y6QIA/mSb3RcZGWnqOLb1Ll68qPz8fFNZ1ICvysnJ0YwZMxQfH69p06apcuXKRe5fWvEn/fEjlytthoaGKjg42CNtOlszz1FfzPytwcHBqlSpki5evFhsm4ArPBWDERERDo9dvXr1UmuTuAfMs1qtWrx4sXbs2KHp06e79HSLv8SRo3JH33GuiIyMNPz4ROxWDKdOnbL7Ablq1arq06dPkfUY/9xD3MLTzMauJ3z33Xfq3r27PvzwQ7Vo0aLY/f0ljhyVe+q7kdj1HU888YR+/vlnl/aNiorSiBEj1Lt372L35Vq35G2Wp7Ee5U9pxW5Jca1bvsZ6f0HSBQD8ydGgaoajehkZGaZPsAFvCwgI0FVXXaXbbrtNLVu2VJMmTRQVFaWQkBClpqbq999/14YNG7Ro0SK7KUE3bdqkkSNHavr06QoKcn7aYRt/lSpVMtVXR/VcPcH0RpslaTc0NJQLUnhMaY6Brv4oRNwXj7hHcZo3b66OHTvqqquuUtOmTRUdHa3Q0FClpqbq5MmT2rRpk77++mvt3LnTUO+3337TU089pfnz5xd7zuovceTou8tT343Eru/Lzc3V3//+d124cMFQ/swzzzhcq7mw8hBDxK1rbRZG3FYMJYldWw0bNlTHjh3Vtm1bNW3aVDVq1FB4eLjS0tKUlJSkLVu2aPny5Vq/fr2h3qlTpzRo0CB9+eWXxT496y9x5Kic2IUjYWFhGjJkiPr06ePyDUKudcuuzZK0y7VuxWYmdm1xrVu88jzW+wuSLgDgT7ZTTYWEhJg6jrOTcJIu4IueeOIJ9ezZU/Xq1XP4evXq1VW9enW1adNGAwcO1Pz58zV+/HhlZ2cX7PPLL7/ogw8+0MiRI522Yxt/JTm5tOXsZK88tFmSdm3r+ftJLUqmNMfA8hyDxD0qigceeECdO3dWs2bNHL4eHR2t6OhoxcXFqV+/flqxYoX+8Y9/GG467du3T6+//rreeuutItvylzgidlGUN954Q5s2bTKU3XzzzerRo0exdctDDBG3nmsTvqUksXtJp06d9Mwzz+jqq692+HpUVJSioqLUrFkz9ejRQ+vXr9dzzz1neAo0MTFRf/vb3zRv3rwi2/KXOPLkDSdit2LLzMzUpEmTtG7dOg0dOlTXXXedS3UK41q39NosSbvEbsVmJnYv4VrXdeV5rPcXJF0AAACnnn/+eZf3DQgIUO/evdWkSRMNHDjQsCbrrFmz1KdPH4fTLgIAgJIZNmyYW/vfc889uvzyy9WzZ0/Dj1H//ve/9cQTT6h58+ae7iJQYcyZM8fuRmmtWrX09ttv262jDKD88FTsDhgwwK12r7vuOi1cuFCPPvqoTpw4UVC+adMmff/99+rQoYNbxwMqqi5duuiKK64o2M7NzVVqaqoOHTqkXbt2FTy9bbVa9d///lfr169Xv379NHr0aMZfwItKO3a51oUvIekCAP4UFhZmuElc+El9dxSewukSs9NmAb7o+uuv1zPPPGPIHs7IyND8+fOdniiHhYUZtrOysky17Sj+wsPDy22bl9otaukVZ2z766xNwBW2n01PjoHlOQaJe/izpk2bauzYsYaZqPLz8zVr1iyNGzfOaT1/iSNnbZpB7FYcy5Yt0xtvvGEoq1y5sj788ENFR0e7dIzyEEPErefahG/wROyWRExMjCZPnqxHHnlEVqu1oPyTTz4pMunCX+LIUTmx638efPBBp69lZGRo6dKlmjx5ss6ePSvpjxu4s2bNUk5Ojl5++WWndbnWLbs2L7XLta5/Ka3YLQmudc21aQaxaxTg7Q4AQHlhOyA4Ghxd4c6gClRUffv2VUxMjKHs559/drq/bYx46kTP0bHLU5sladf2u4bvGZREaY6BzhIPy0MMEvfwd3fffbfi4uIMZUWN15L/xJGj7y5PfTcSu77pxx9/1KhRo5Sfn19QFhoaqmnTpqlFixYuH6c8xBBx67k2Uf55KnZL6qqrrtKdd95pKNuyZUuR03D7Sxw5Kid2UVh4eLh69OihZcuWGZ6ol6R58+Zp7dq1RdYtjGvd0muzJO0SuxVTSWK3pLjWLV9jvb8g6QIA/mQ7IKSlpZk6jm290NBQBQTwdQv/EhISoo4dOxrKtm/f7vQErrTiT3L9IvjixYvKzc31SJvunNSa+VtzcnLIJIZHeSoG09PTiz22p9sk7oGSueuuuwzbSUlJOnz4sNP9/SWOHJU7+o5zhW1fiV3fs2nTJo0YMcIwM2JwcLAmT56sa665xq1jMf65h7hFSXgydj3BdszNyclRfHy80/39JY4clXvqu5HYrViio6P10UcfqUqVKoby999/32kdrnVL3mZ5Guvhm8zEridwrVt+xnp/wV1AAPiT7VP5p06dMnUc23q2xwX8RZs2bQzbeXl5On36tMN9beMkOTlZeXl5brd58uTJYo/trNxqtZqK+5K06ax+cU6dOmWYlraoNgFXeGoMtP08h4SEKCoqyqU2ifuiEfcoLbbjtSQlJiY63d9f4shTbebm5io5OdmlNlE+JSQk6KmnnlJmZmZBWUBAgN58880ilwVwhvHPPcQtzPJ07HpCScdcqWLGUbVq1RQcHGwo4zc5OFOjRg3169fPULZz504dOnTI4f5c65Zdm87qF4drXf/gbux6Ate65Wes9xckXQDAnxo3bmzYPnHihKnj2NZr0qSJ6T4Bvqx69ep2ZZfW77NlG395eXlFngQ7Y3uCGBERoVq1arnUpqP6ZtqUnMe9N9oEXGH72UxMTDRMwewq289mw4YNFRgY6FKbxL3n2gTc4c54LflPHNWqVcvuKR0z1weOvk+JXd/x22+/6YknnrB7guu1117Tvffea+qYjH+l1yZxi0tKI3Y9wRfGXG/EUWBgoBo0aFDiNvPy8pSUlORSm/Btt99+u13Ztm3bHO7LtW7J2pTK11gP3+ZO7HqCL4y7/jLW+wuSLgDgT7YDwqlTp4pcW9MZ2+zMRo0alahfgK+yza6VJIvF4nBfRydkBw4ccLvNgwcPGraLij9HJ7WeaLNatWqqVq2aw32jo6PtnoTwRJsWi4XvGpSIbQzm5uYWOeWiM+7EIHFfsjaJe3iKO+O15D9x5Og12/pm2pQcv4cof44cOaIBAwbo3LlzhvLRo0frkUceMX1cxr+StUncojilFbue4O6Y609xZPvdaKbNI0eO2E0DT+xWTPXq1bMrczazKte6JWuzvI318G3uxK4ncK1bvsZ6f0DSBQD8qXnz5obt3Nxcbd++3a1jHD161G5KJdvjAv7C0UlzdHS0w30bNmyokJAQQ1lRa9s6s2XLFsN2s2bNnO4bGRmpunXrlrjNzZs3u9ymZP+d4Ik269Sp43RdT8AVjsYqdz+bFy9e1M6dOw1lRcUDcV+yNol7eIo747XkX3FUGm1WqlTJ7mlelD8nT57UgAED7K7thg8frgEDBpTo2Ix/JWuTuEVRSjN2PeHMmTN2ZUWNuZL/xJHt98nOnTvt1qZ3t01Hx0XFEBQUZFfm7EYq17ru8YWxHr7Lndj1BK51y9dY7w9IugCAP7Vp00aVK1c2lG3YsMGtY9juHxAQoFtuuaXEfQN80datWw3bgYGBDqd1k/5YC/OGG24wlLkbf7///rvdVGrFrdV76623GrY3btzoVpuZmZlKSEgoUZs7duwwrDNcHKvVqk2bNrnVJlCc2rVr6/LLLzeUuRuD8fHxysnJMZQV9dkk7ol7lA+247UkXXbZZUXW8Zc4sm3zxIkT+v33311uU7J/b2688Ua7H+FRvpw+fVr9+/fX8ePHDeWPP/64hg0bVuLjM/4RtygdpR27nuDohoa7Y25FjSPbNnNycty+AWTbZrNmzVS7dm23jgHfYJtYJTleRkDiWtcdvjLWw3e5E7uewLWu621yzuwZJF0AwJ+Cg4N12223Gcq+/vprh9NQOfPVV18Zttu0aVOqJw5AeXXx4kV9//33hrJWrVopNDTUaR3bdf02bdrk1snekiVLDNshISG6+eabi6xj2+bx48e1fv16l9tcvny53dM3jtYnLOr1ixcvasWKFS63uX79ert19oprE3CF7efom2++UXp6usv1bcfAWrVqqWXLlm61Sdw7RtyjtFitVq1cudJQdtlllxU7na+/xNEtt9yi4OBgQ5ntd11Rfv/9d7unf4jd8u3cuXMaMGCA3bTjjz76qEaNGuWxdhj/XEPcwlVlFbslZfv5Dw4OVps2bYqs4y9x1KpVK8XExJhuMy0tTd9++62hrFOnTi7Xh2/573//a1dm+3R6YVzrusZXxnr4LndjtyS41i1/Y70/IOkCAAq55557DNvHjh3T2rVrXaq7Z88eu+y+u+++22N9A3zJ7Nmz7bKXi5v15fbbbzec7FmtVs2dO9el9jIzM7Vw4UJD2a233lrsdITXXXed3bRyc+bMcanN/Px8zZs3z1B2xRVXFDuNWqNGjdSiRQtD2dy5c11O8LJ9T6Kjo3Xttde6VBcoiu2YlZGRoUWLFrlUNzk52e5i9q677iq2HnFP3MO7li1bpj179hjKXJmlzV/iKDIy0u4JoC+//FIXL150uc3C/QsJCeEGUDmWnp6uJ598Uvv27TOU/+Uvf9Frr73m0bYY/4hbeE5Zxm5JxMfH2/2+1LZtW0VGRhZZz1/iyGKx2F2PrFy50uFT0Y4sXrxYGRkZhjJ+k6uY8vPz9dlnnxnKoqKiikxg4lq3eL401sM3mYndkuBat/yN9f6ApAsAKOT222+3W8/q//7v/4rNfs7Ly9OLL75oKLvsssv0yCOPeLyPQFlITk5WXl6eqbo///yz/vWvfxnKwsLC9OijjxZZr0aNGnb7zJ07V7t27Sq2zXfffVeJiYkF2xaLRUOHDi22XnBwsJ588klD2bfffqvvvvuu2Lpz5861W9Pz6aefLraeJLu+7dy50+6k3JE1a9bYPb3z1FNP2WUmA2ZceeWV6tixo6HsX//6lyG2nHnttdcMF2aVKlXSE088UWw94p64R8mcPXtW2dnZpuru2bNHL7/8sqHMYrGoX79+xdb1pzgaMmSIYTsxMVGTJ08utt7OnTvtfvx69NFHmQWvnMrKytLgwYO1fft2Q3nnzp01fvx4j681zfhH3MIzyjJ209LSlJaWZqruyZMnNWLECLvyAQMGuFTfX+Jo4MCBqlSpUsF2Zmam/vnPfxZb79SpU3Z969Spk6644opi66LsJSYmujWrsK13333Xbry86667FBQU5LQO17oVb6xH2Svr2OVat2KO9RUdSRcAUIjFYtFf//pXQ9nx48c1ZMgQpxfX2dnZevbZZ+3W6ho8eLDCwsJKq6tAqVq2bJm6dOmiRYsWuTzlYm5urmbNmqXBgwcrNzfX8Fr//v2LXTNPso+b3NxcDR06VPv373daZ9asWZo9e7ahrHPnzoqLi3Op371791bNmjUNZc8//7zdWniFLV++XG+//bahrGXLlrrzzjtdavOuu+6y69+bb75p9/REYRs2bNDo0aMNZTVr1lTPnj1dahNwxV//+lfDj9MXLlzQwIEDnf4YZbVaNX78eLsLPEdx5QxxT9zDvC1btuiOO+7Q7Nmzde7cOZfqWK1WLV26VL169bIb4++//367J2yc8Zc4atWqlTp37mwomzlzpt13UGG//fabhg4dajgfCgsL0+DBg11qE2UrNzdXI0eOtFtr/dZbb9XEiRMVGBhYKu0y/hG3KJmyjt3ff/9dnTp10vvvv+/SjdpLfvrpJz300ENKSkoylLdr187lJ0L9JY5q1qypXr16GcpWrVqlN9980+mNvlOnTunJJ580/GZnsVg0cuRIl9pE2fviiy/0l7/8RcuWLXP5iWpJSklJ0ejRo/Xhhx8ayitXruwwqckW17oVa6xH2Svr2OVat2KO9RWdxVqS1CQAqKBGjBihVatWGcrq1KmjAQMG6IYbblBMTIxOnz6tLVu2aObMmXYny23bttXcuXOLzLIGyrNZs2Zp3LhxkqTQ0FDdcsstuvrqq3XFFVeoTp06ioyMVKVKlZSamqrff/9dGzZs0OLFi3X8+HG7Y918882aNm2ay5nqc+fOtXuaJSIiQj169FCXLl1Ut25dZWRkaO/evZo7d65+/vlnw75RUVFasmSJateu7fLfu3btWrvs3uDgYD3wwAPq1q2bGjZsqJycHB08eFCff/65Vq5caTeF2oIFC1y+CJakhIQE9ejRQzk5OQVlAQEBuvvuu/Xoo4+qcePGCgwM1OHDh7VkyRJ99dVXhn0tFoumTp1q97QGKo6EhIQiL65mzJhh2L766qvVrl07h/tWqVJFgwYNcqndN998U5988omhLDo6Wn379lWnTp0UGxur8+fPKyEhQbNmzdK2bdsM+9avX19Lliwpdqrkwoh74r4iKcvYXb16dcGTM0FBQbr++uvVvn17XXHFFapfv74qV66s0NBQpaWl6cSJE9q0aZO+/vpr/fbbb3bHatGihebNm+dW7PpLHJ04cULdunXT+fPnDeW33HKL+vTpo2bNmiksLEzHjh3T8uXLtWDBArspzl9++WX17t3b5TZRdiZNmqRp06YZyoKCgtSzZ0+FhoaaOmZcXJzd0pWOMP4RtzCvrGN39+7d6tatm6Q/Pr9XX321brjhBl1xxRVq2LChqlSpovDwcKWnpyspKUlbtmzRsmXLtHXrVrtj1apVS1988YXLN24l/4mjtLQ0devWTb///ruhvE2bNurfv79atmypKlWq6OTJk1q9erXmzp2rlJQUw76PP/64Ro0a5XKbKFvvvfee3n//fUlSeHi4OnTooNatW+uKK65QbGysIiMjFRoaqvT0dJ05c0Z79uzRL7/8otWrV9t9vgICAjRx4kR16dLFpba51q1YYz3KVlnHLte6f6iIY31FRtIFADiQlpamAQMG2E1R6Yr69etr3rx5iomJKYWeAWWjcNJFSVx//fX64IMP3DqplaRXX31V8+fPd7u90NBQzZgxQ+3bt3e77vTp0zVx4kS36wUEBGjChAm699573a77n//8R88995zy8/Pdrvvss8/aTXeHimXx4sUaM2aMR45Vp04duzWkncnNzdWwYcNcmjrRVrVq1TR37lxdfvnlbtcl7otH3PuGsozdwj9ElUSLFi00ffp0t27+XOIvcbR+/XoNGjTIrae6LunVq5deeeUVt+uhbIwePVpLlizx6DG7d++u8ePHu7Qv41/xiFs4UtaxWzjpoiTq1KmjDz/8UE2bNnW7rr/E0W+//aY+ffq4/GRzYZ06ddJ7773HQ1DlWOEbtyURHByssWPHuhWXXOsWz9fGepSdso5drnUr9lhfUbG8CAA4EBkZqZkzZ7o8/dMl11xzjebPn0/CBfxeWFiYnn32Wc2cOdPthAtJeuWVVzR8+HC3poSNjY3Vp59+aupiVJIGDRqksWPHuvVUVNWqVTVlyhRTJ9GSdN999+mDDz5Q1apVXa4TGhqqsWPHcjGKUhMUFKT33nvP7Wk9mzZtqgULFpj6EUoi7otC3KO0BAcH6/HHH9eXX35p6kcoyX/i6LrrrtPs2bNVq1Ytl+sEBgZqxIgRdusJA4Ux/jlH3KIisVgs6tatm5YuXWoq4ULynzhq2rSp5s+f7/b71KtXL/3rX/8i4aKcK7zEh1lt27bVkiVL3E6E4lq3aL441qPseDN2zeBa13WcM3sOM10AQDHWrFmjGTNmKD4+3uk+zZs314ABA9StWzePnIAA3paUlKTVq1dr/fr12rFjh8NlQ2wFBASoWbNmuv/++/Xwww+7dXLozJ49ezR16lStWbPGMF1aYZdddpl69OihAQMGKCIiosRtHjt2TFOnTtWyZcuUmZnpcJ+qVauqe/fueuqppxQdHV3iNs+ePasPP/xQixcvVmpqqsN9wsLCdO+992rIkCGqW7duidtE+eetmS4K27Rpk6ZOnap169Y5zbKvV6+e+vbtq169erm8jFBRiPv/Ie59U1nG7vnz5wvG661bt+ro0aNO1zy/xGKxqGHDhrr77rvVs2dP0z9A2fKXOEpPT9fMmTO1YMECJScnO9wnODhYt99+u4YOHarmzZuXuE2ULm/PdHEJ49//ELdwRVnH7sWLFwvG3Pj4eB08eFB5eXnFHrNOnTq6/fbb1adPHzVo0MAj/fSXOMrJydFnn32mOXPm2C03cklAQIBuuukmDR48WNdcc02J20Tpy8nJ0aZNm/Tjjz9q06ZN2r17t9Nxr7Dq1avrtttu04MPPuiRf2uudf+nIoz1KH1lHbtc6/rHWF/RkHQBAC5KTEzUtm3bdPz4cWVkZCg0NFSxsbFq1aqV6tWr5+3uAaUqNTVVBw8e1MmTJ3X69GllZmYqNzdXkZGRqlKlimrVqqWWLVuamtXCFWlpaYqPj9eRI0d04cIFBQYGqnr16mrRooWuvPLKUkl2ysrK0tatW3XgwAGlpqbKYrGoWrVqatq0qVq1alUqT8/k5uZq+/bt2r9/v1JSUmS1WlWlShU1adJEbdq0UaVKlTzeJuCKlJSUgovc9PR0BQcHKyYmRnFxcaaf9ikOcU/cw33p6ek6dOiQTp48qaSkJGVkZCgnJ0fh4eGqWrWqatSooVatWikqKqrU+uAvcWS1WrVr1y7t2bNHZ86cUV5enipXrqyGDRuqTZs2pXZOhIqP8Y+4hW/IysrSoUOHdPz4cSUlJSk9PV1ZWVkKDw9XlSpVFB0drbi4uFKdCdWf4ui3337Trl27lJSUpJycHEVERKh+/fpq06aNqlWrViptomxkZ2fr0KFDOnbsmBITE5Wenl5w/hoZGanq1avriiuucOsJbHdwrVuxxnqUnbKOXa51K/5YXxGQdAEAAAAAAAAAAAAAAGBCgLc7AAAAAAAAAAAAAAAA4ItIugAAAAAAAAAAAAAAADCBpAsAAAAAAAAAAAAAAAATSLoAAAAAAAAAAAAAAAAwgaQLAAAAAAAAAAAAAAAAE0i6AAAAAAAAAAAAAAAAMIGkCwAAAAAAAAAAAAAAABNIugAAAAAAAAAAAAAAADCBpAsAAAAAAAAAAAAAAAATSLoAAAAAAAAAAAAAAAAwgaQLAAAAAAAAAAAAAAAAE0i6AAAAAAAAAAAAAAAAMIGkCwAAAAAAAAAAAAAAABNIugAAAAAAAAAAAAAAADCBpAsAAAAAAAAAAAAAAAATSLoAAAAAAAAAAAAAAAAwgaQLAAAAAAAAAAAAAAAAE0i6AAAAAAAAAAAAAAAAMIGkCwAAAAAAAAAAAAAAABNIugAAAAAAAAAAAAAAADCBpAsAAAAAAAAAAAAAAAATSLoAAAAAAAAAAAAAAAAwgaQLAAAAAAAAAAAAAAAAE0i6AAAAAAAAAAAAAAAAMIGkCwAAAAAAAAAAAAAAABNIugAAAAAAAAAAAAAAADCBpAsAAAAAAAAA8IDFixerefPmhv8dO3bM290CAAAAUIqCvN0BAAAAAADKu9zcXO3fv18HDx5UamqqUlNTlZ+fr7CwMIWHh6tWrVqqU6eO6tatq5CQEG93FwAAAAAAAGWEpAsAAAAAABzIzs7Wt99+q0WLFmnz5s26ePFisXWCg4PVtGlTtWrVStdee61uuukmRUdHl0FvAZSWTp066fjx44ayvXv3eqk3AAAAAIDyhqQLAAAAAABsrFmzRq+//rpOnTrlVr2cnBzt2rVLu3bt0ueff66AgAD17t1bL730Uin1FABQUs2bNzdsDxs2TMOHD/dSbwAAAAD4GpIuAAAAAAD4k9Vq1Wuvvab58+d75Hj5+fk6ceKER44FAAAAAACA8oekCwAAAAAA/vTKK6/o888/d/ha7dq1df311+vyyy9XdHS0wsLClJGRodTUVB0+fFg7d+7Unj17lJ2dXca9BgAAAAAAgLeQdAEAAAAAgKTVq1c7TLiIi4vTc889p+uvv14Wi6XIY2RmZuqnn37St99+q9WrVysjI6O0ugsAAAAAAIBygKQLAAAAAIDfs1qteuONN+zKO3furIkTJyokJMSl44SFhalz587q3LmzLly4oEWLFikxMdHT3QUAAAAAAEA5QdIFAAAAAMDvbdmyRcePHzeU1axZU+PGjXM54cJW5cqV1b9/fw/0DgAAAAAAAOVVgLc7AAAAAACAt/344492Zd27d1dkZKQXegMAAAAAAABfwUwXAAAAAAC/d+LECbuyli1beqEnzh08eFCHDh3S2bNnlZKSopCQEFWrVk2xsbFq3bq1KlWq5PE2ExMTtWPHDiUlJen8+fMKCwtT3bp11apVK9WsWdPj7ZVHJ06c0N69e3X27FmdPXtWgYGBqlatmmJiYtSmTRtFRESUeh8OHz6snTt3KjExUdnZ2YqKilJMTIzatWunqlWrlkqb2dnZSkhI0KlTp3Tu3DmlpqYqJCREkZGRqlevni6//HJddtllHmvPG59vX5Odna0dO3YoMTFRZ8+eVVpamqpUqaLo6Ghdfvnluvzyy0u9DxcvXtTWrVt18OBBpaamKjQ0VNWqVVOzZs3UokULWSwWj7Z34cIFbdmyRUlJSTpz5oxCQkIUExOjK664Qk2aNPFoW2UtJydH27dv14EDB5SSkqKgoCBFR0erYcOGuuqqqxQYGOjtLgIAAABwEUkXAAAAAAC/d/bsWbuysLAwL/TE6NChQ5o1a5Z++uknu+VPCqtUqZKuvfZaDRgwQDfffHOJ2/322281a9Ysbd68WVar1e51i8WiNm3a6Mknn9Ttt99eUN6pUydDP7t3767x48cX2dbo0aO1ZMmSgu06depo7dq1bvd5/fr1euyxxwxln376qa677jq3j5WYmKhZs2bp+++/18GDB53uFxwcrNatW6t3796655573L7h3Lx5c8P2sGHDNHz4cElSfn6+lixZolmzZmnfvn0O6wcGBqp9+/b661//qjZt2rjVtiN5eXn697//rX//+9/avHmzMjMzi9y/UaNGuuWWW9S9e3ddeeWVbrfnrc+3L7FarVq1apWWLFmiDRs2KCMjw+m+MTExuvPOOzVo0CDVqlXLrXbee+89vf/++4ayvXv3Fvz30aNHNXXqVK1YscLp56JGjRrq2bOnHn/8cYWHh7vVvq3Nmzfrww8/1Lp165STk+NwnwYNGqhv377q0aOHgoODJbn+feLo+6Kw999/3+79sGX2uyo5OVnTp0/XkiVLdOHCBYf7VKlSRd27d9eQIUNUrVo1t9sAAAAAULZIugAAAAAA+L2QkBC7MkezX5SVlJQUTZgwQUuWLFFeXl6x+2dlZennn3/Wzz//rPbt2+vtt992+6ar9EfyyUsvvaQ1a9YUuZ/ValV8fLyGDh2qu+++W+PHjy8XSSoldfHiRU2ePFnz5s1TVlZWsfvn5ORo06ZN2rRpk6ZNm6YJEyaoWbNmJe5HYmKiRo4cqfj4+CL3y8vL06+//qpff/1VgwcP1jPPPGO6zVWrVmnixIk6cuSIy3UOHTqkQ4cO6dNPP9Xo0aM1YMAAl+p56/PtazZt2qQ33nhDO3fudGn/pKQkzZs3T19++aUGDhyo4cOHKyCg5CsLz5s3T2+++WaxMXH69Gm99957Wrx4sT755BM1bNjQ7baysrL0+uuva9GiRQ4Tvgo7cuSIxo4dqy+//FIffPCB6tWr53Z7ZW3VqlV66aWXlJqaWuR+qampmj17tr7++mt9+OGHHkmqAgAAAFB6Sn7lBQAAAACAj3O0TMKKFSu80JM/bmQ/+uijWrhwoUs3pG1t2LBBDz30kLZv3+5WvZSUFPXv37/YhAtbK1eu1JNPPqns7Gy36pU3ycnJ6tu3rz755BOXEi5s7d27Vz169NAPP/xQon78/vvvevjhh4tNuLA1bdo0TZo0ye328vPz9eabb2rEiBFuJVzYSktLc2k/b32+fc3nn3+ufv36uZxwUVh2dramTJmip59+usiZMVzxzjvv6PXXX3crJo4fP65evXopMTHRrbYuXryowYMHa+HChcUmXBS2d+9e9ezZU8eOHXOrvbI2f/58jRw5stiEi8LOnTunAQMGaPfu3aXYMwAAAAAlxUwXAAAAAAC/17ZtW33++eeGsnXr1mnOnDnq27dvmfVj//796tWrl86fP2/32lVXXaWrr75ajRo1UpUqVZSTk6Pk5GTFx8frxx9/NCQ9JCcna9CgQVqyZIliY2OLbTcnJ0dPPPGEYTmBS2rWrKnOnTurSZMmqlq1qs6cOaNdu3ZpzZo1Bf3cuHGj3nzzzRL85d51+vRpPfroow6XuGjWrJmuvfZaXX755apSpYok6cyZM9q6dat++OEHpaenF+ybnp6u4cOHa8GCBaaW20hPT9fAgQMLblZbLBa1bdtWN954o2JjYxUeHq6UlBRt2bJF3377rd2N8BkzZqhTp05q3bq1y20+99xz+s9//uPwtWbNmunGG29U/fr1Va1aNeXk5Oj8+fPav3+/EhIStGvXLrdujnvr8+1rpk+frokTJ9qVh4eH68Ybb1SrVq102WWXKSIiQhcuXNCRI0e0bt06uwSNtWvX6sUXXzSVjCNJCxYs0IcffliwHR0drVtvvVWtWrVSdHS0srKydOTIEa1evVq//faboe6ZM2f08ssvG+oX529/+5vWrVtnV161alV16tRJcXFxql69utLT03X06FGtXbtW+/fvl/THZ2LYsGG6/PLLXWorPDxcLVq0KNjes2eP4fUaNWqoRo0aRR4jJibGpbYk6ccff9Q///nPgnipXLmybrrpJrVt21bVq1dXfn6+jh8/ru+//17btm0z1M3IyNCYMWO0cOFCBQXxUy4AAABQHnGmDgAAAADwe7fddptCQ0N18eJFQ/nYsWP1yy+/aODAgbrmmmtKtQ8ZGRkaOXKk3Q3pjh076rnnnlOTJk2c1k1OTtZbb72lpUuXFpSlpKRoxIgR+vzzz4tdYmDatGl2N2xDQkI0fPhwPfHEEwoMDHTY30mTJunTTz+V9McSBMHBwcX+neVNfn6+/v73v9slXLRt21ZjxoxxmsDQr18/paamasqUKZo1a1bBzdSsrCwNHz5cX3/9tSIjI93qy2effVaQSNG6dWu98soriouLs9uvd+/eOnbsmEaMGGH4d8vLy9O//vUvffzxxy619/HHHztMuGjfvr2ee+45XXXVVUXWT0xM1IoVKzR37txi2/Lm59uX/Prrr3ZJEqGhoXr66afVq1evIj9T69ev10svvaSjR48WlC1fvlzXXHONevfu7XZf3njjDUlScHCwRowYoX79+qlSpUp2+40cOVJz5szRuHHjlJ+fX1D+/fffa+vWrS4tjfHVV185nGWnf//+GjlypMLDw+1e+/vf/66VK1fq9ddf15kzZ7R7924dOnTIpb+tVatW+vrrrwu2mzdvbni9R48eGj58uEvHcsX48eOVn58vi8WiAQMGaMiQIQVJXIUNHTpUy5cv1+jRow1JVbt379aqVat07733eqxPAAAAADyn4lyVAgAAAABgUnR0tNObkt9995169+6tW2+9VWPGjNEXX3yhPXv2KDc316N9eOuttwqe2r7k2Wef1bRp04q8IS39sTzK22+/rWHDhhnKt2/frpUrVxZZ9+jRo3ZPowcFBWnSpEkaNGiQw4QL6Y8nxV988UWNGTNGkmS1Wn1yiZGPP/5Y//3vfw1lvXv31vz584udMaJKlSoaPXq0/u///s9QfuzYMc2fP9/tvly6ydqxY0fNmTPHYcLFJXXr1tUnn3xi9zT+unXrdOLEiWLb2rdvn8PZFPr166fZs2cXm3Ah/TELSv/+/bVq1So99NBDRe7rrc+3L0lLS9Ozzz5rSFyoXr26vvjiCw0aNKjYJJ7rrrtOixcvtksgeO+995SZmel2f7KyshQSEqIZM2Zo0KBBDhMupD9mZHnsscc0cuRIu9e+/PLLYtvJzMzUuHHj7MpfeukljRkzxmHCxSV333235syZo+rVq0uSXeJceZGVlSWLxaLx48dr1KhRDhMuLunSpYvdd4rk2nsJAAAAwDtIugAAAAAAQH88rd22bVunrycmJmrx4sX6xz/+oa5du+rqq6/Www8/rLFjx2rlypU6ffq06bYTExO1cOFCQ1mvXr305JNPunWc4cOH66abbjKUzZgxo8g6n332mXJycgxlgwYN0h133OFSm/3799d9993nVj/Li8zMTLtZITp06KCXX35ZFovF5eM8+OCDevjhhw1ls2fPNpWEUqdOHb399ttOb3AXFhUVpaefftpQlp+fr19++aXYuh9++KHy8vIMZffdd59eeOEFt2eOCAwMLHKZD29+vn3JggULDN8jAQEBmjJlil0SRVEqV66sDz74wDDrTEpKiukb9s8//7xuuOEGl/Z94oknVLNmTUPZzz//XGy9//znPzp37pyhrEuXLi4v7dSkSRONHTvWpX29qX///urWrZtL+95///12iU8bN260W1IIAAAAQPlA0gUAAAAAAJIqVaqk6dOnq2PHji7tn5WVpe3bt2vOnDkaOXKkbr75ZvXt21cLFy50+2b7rFmzDIkPkZGR+vvf/+7WMS4ZOnSoYXvXrl12S2dckp2drSVLlhjKYmJi9NRTT7nV5qhRoxQSEuJeR8uBRYsWKSUlpWA7ICBAL730kqljPf3004ZEjeTkZG3dutXt4wwbNkyVK1d2ef97773XbjYS26VibB07dkwrVqwwlEVHR+u1115zvaNu8Nbn25dkZ2dr9uzZhrJu3bq5tDSHrXr16qlr166Gsm+//dbUcdxZliQ4OFhdunQxlJ06dUpnzpwpst4XX3xh2A4MDNSoUaNc76ikTp066cYbb3SrTlmKjIy0m6mlOH/5y18M27m5udq7d68nuwUAAADAQ0i6AAAAAADgT1WqVNHUqVP15ptvqkGDBm7VtVqt2rBhg1588UXdddddWrp0qct1V61aZdi+5557il1KwJmrr77abur6DRs2ONx327Ztdk+Y/+Uvf1FoaKhbbcbExLicrFKe2L7v119/verVq2fqWLGxsWrWrJmhzNn77kx4eLjbs4ZUrVrV7rN66NChIuv88MMPdrNc9OjRw/Rnrjje+nz7kvj4eCUlJRnKiluypSgdOnQwbG/bts3tZLAHH3zQ7VlPHC1LU9TnMS0tTQkJCYaym2++WbVq1XKrXalk71dpM/OZd/ReHjx40FNdAgAAAOBBJF0AAAAAAFCIxWJRt27dtHz5ck2bNk333Xef2zfLTpw4oeeee05jxowp9kbn8ePH7Z7Uv/rqq93u9yUBAQGqXbu2oWzXrl0O93U0E0Pnzp1NtWu2nrdkZ2dr27ZthrKSvO+SVLduXcO2s/fdmdatW5uaMaR+/fqG7QsXLhS5//r16+3KbGdG8BRvfr59ycaNGw3bwcHBatWqlenj2X4Ws7KydODAAbeOce2117rdrqOkpaI+jzt27FB+fr6h7LbbbnO73Uv13FkWqCx56r1MS0vzRHcAAAAAeFiQtzsAAAAAAEB5FBQUpI4dO6pjx47Ky8vT7t27tXnzZu3YsUO7d+/WoUOH7GYLsLV48WJlZmbq3XffdbrPli1b7MqmTp1qt9SAO44ePWrYLryERmG2y1AEBQWpRYsWptqMi4szVc9bEhISlJWVZShbtGiRVq9ebfqYJ0+eNGw7e9+dcXd2lUtsk4KKuzFrm2wTHR2thg0bmmq7ON78fPsSR+/Tww8/bPp4hZdzucTd98nMZ8LR0jhFJV04Wi7jyiuvdLtd6Y84qF+/vo4cOWKqfmkqi/cSAAAAgPeQdAEAAAAAQDECAwPVsmVLtWzZsqAsMzNT27Zt0/r167Vy5Uqn076vWLFC7dq1U9++fR2+furUKbsy25vKJWW7hMglZ86cMWzHxsaqUqVKptpo2LChAgMDi01EKS8cve8nT560S5woCWfvuzNRUVGm2gkODjZs5+bmFrn/2bNnDdu2y6J4kjc/377E9n3KycnRnj17PNqGu+9T1apV3W4jKMj+p8aiPo+O+lSnTh23272kbt265TLpwsx7aRvXUvGxDQAAAMA7WF4EAAAAAAATwsLCdP3112vkyJFasWKFPvroIzVt2tThvlOnTlVmZqbD18rihrHtjA6X2D417ejJaldZLBZFRESYrl/WvPm+O+PohrWnpaWl2c2CYOaGsKvK4/tcHpXF+3Tx4kW39nd009/TUlNT7cpK8j3k7lJQZaUsYhsAAACA95B0AQAAAACAB9xyyy1auHChbr31VrvXzpw5o7Vr1zqs5+imY1lJT083bIeFhZXoeCWtX5a8+b57k+2/uSSFh4eXWnv++j67y1/fp+zsbLuykiR7hISElKQ7AAAAAGAKadYAAAAAAHhIaGioJk2apDvuuEMpKSmG13799Vfde++9dnUcLecxY8YMh8kbnmY7M4Wz2ThcVdL6ZSk0NNSu7NVXX1XPnj290Juy42g2koyMjFJrz5ufb19SqVIlwwwkNWrU0C+//OLFHpUNR7NapKenm559JS0traRdAgAAAAC3MdMFAAAAAAAeFBkZqe7du9uVHzp0yOH+1apVsys7f/68x/vliO0NT9vlRtxhtVodzqJQVnJzc93aPyoqyq6srN53b4qMjLSbSaA0/25vfr59ie375C/vUZUqVezKSrLUSlks0wIAAAAAtki6AAAAAADAw6666iq7MtuZLy6pUaOGXdmJEyc83idHqlevbtg+efKksrKyTB3r8OHDysvLc7teUJBxEs7CT/u7w92brd58373N9m/ft29fmbUl+c/77A7b9yknJ0dJSUle6k3ZiY2NtSsz+3m0Wq367bffStolAAAAAHAbSRcAAAAAAHiYoynzAwMDHe7bunVru7KNGzd6vE+OxMXFGbZzc3O1Z88eU8fauXOnqXqRkZGGbbPLAxw5csSt/Vu2bKmAAOPPImX1vntbmzZtDNtnz551OhNLSXnz8+1LSkREKgAAD5dJREFUHCVqbdq0yQs9KVutWrWyK9u6daupY+3fv5/lRQAAAAB4BUkXAAAAAAB42OnTp+3KHD3xL0nNmze3m3Fi06ZNTmfG8CTbm++S9O2335o61jfffGOqnm2CSkZGhs6ePev2cdy9kR8VFWWXdHLw4EHt37/f7bZ9Tfv27e3Kvv7661Jpy5ufb19y00032ZWZjSlf0rhxY7ulfpYvXy6r1er2sf7973+b7odtUpyZWXsAAAAA+C+SLgAAAAAA8LD169fbldWrV8/hvhaLRZ06dTKUZWZm6tNPPy2VvhXWunVruxueX3/9tdtLjCQnJ+u7774z1YdGjRrZlW3fvt2tYxw5ckT//e9/3W779ttvtyubPn2628fxNR07drRb1uXzzz8vlVkCvPn59iXXXnutXQLSN998o8OHD3unQ2XEYrHorrvuMpSdOHFCy5cvd+s458+f15dffmm6HxEREYbtjIwM08cCAAAA4H9IugAAAAAA+L21a9fq999/98ixjh49qhUrVtiVd+jQwWmdQYMG2d0EnzFjhrZt2+aRPjkTEhKi7t27G8qSkpLcTjx48803lZ2dbaoPLVu2tCtz94n1CRMmKD8/3+22+/TpoypVqhjKli5danq2D18RGxur++67z1B29uxZvfLKK6XSnrc+374kPDxc/fv3N5Tl5eXpueeeMx1bvqJXr152ZePGjdOZM2dcPsa4ceNMzZBzie33gKfGAwAAAAD+gaQLAAAAAIDf+/7773X33XdrzJgxOnDggOnjJCYm6umnn1ZmZqahPDo62uHyAZfUr19fDzzwgKEsJydHQ4cO1ZYtW0z1JS8vT8uWLdOkSZOK3K9nz54KDg42lE2bNs3lmSs+/fTTEk3rX79+fTVs2NBQtnz5cpdnu5gyZUqJljZ54oknDGVWq1XPP/+8Vq9ebeqYkvTDDz+UWgKDpwwaNMju3/0///mPxo0b5/bSDnl5eTp58qTT1735+fYl/fv3V7Vq1Qxl27dv14gRI3ThwgVTxzxz5owmTZqkX375xRNdLBUtWrSwmw0lOTlZ/fv3V2JiYpF18/LyNH78eC1ZsqREfWjWrJlhe+PGjcx2AQAAAMBlJF0AAAAAACApNzdXixcvVpcuXfTII49o7ty5SkpKcqluZmam5s+fr+7du2vfvn12rz///POqVKlSkccYPXq03Y2/06dP67HHHtPbb7+t5ORkl/qyZ88eTZo0SXfeeaf+9re/ac+ePUXu36BBAz311FOGstzcXI0YMUIff/yx8vLyHNbLzMzU+PHj9cYbb0j6Y5mAkJAQl/po66GHHjJs5+fn66mnntLmzZud1klKStKoUaM0efJkSSr2/XVm4MCBuvHGGw1lGRkZGjZsmP7xj3+4/MT74cOHNW3aNN13330aNGhQkX0vD5o0aaJRo0bZlc+aNUv9+vXTjh07ij1GUlKSZs+erbvuuksLFy4scl9vfb59SWRkpCZNmmQ3K8h3332nBx54QEuXLlVubm6xx8nKytLq1av17LPPqmPHjpo2bZrppI2y8uqrr9rNNrFv3z516dJF06dP1/Hjxw2vZWZmatWqVXrooYc0c+ZMSVJwcLDi4uJMtd+2bVvD9oULF/TMM8+UKAkPAAAAgP8IKn4XAAAAAAD8y7Zt27Rt2zb985//VJ06ddS6dWs1adJE1apVK3gSPT09XcePH9eePXu0fv16p09F33PPPXZLeDgSERGhqVOn6tFHH9Xp06cLynNycvTRRx9p9uzZatu2rdq1a6datWqpatWqysnJ0YULF5ScnKw9e/YoISHB5ZvXhQ0ePFjfffeddu7cWVCWnZ2tt956S59++qk6d+6sJk2aqEqVKkpJSdGuXbu0evVqnTt3rmD/3r1767vvvrO7OeqKnj17at68eYbZEs6ePatevXrp5ptv1o033qhatWopLy9PycnJ2rRpk9atW6eLFy9K+iPh4m9/+5vGjRvndttBQUF699131aNHDx08eLCg3Gq16osvvtCiRYvUsmVLXXPNNapbt66ioqKUn5+v1NRUnT17Vvv27VNCQoKpv9vb+vbtq+3bt2vp0qWG8vXr1+uhhx5S8+bNddNNN6lu3bqqVq2acnNzlZqaqgMHDighIUEJCQkuL+vizc93aejatWuJj9GoUSO9++67hrIbbrhBL774ol577TVD+dGjR/Xcc8/pzTffVPv27RUXF6fo6GiFh4crPT1dFy5c0O+//66dO3dq9+7dBbHhK2rWrKm3335bw4YNU05OTkF5WlqaJk6cqIkTJ6patWqKjo5Wenq6zpw5Y9hPkv76179q//79hu+xgADXnjfr1q2bJk+ebEhq+f777/X999+ratWqql69ul1SWUxMjGbMmGHmzwUAAABQwZB0AQAAAABAEY4fP276hnr37t31f//3fy7vX7duXS1cuFAjR47Utm3bDK/l5ORow4YN2rBhg6m+FCU4OFgfffSR+vXrZzdTx6lTp/Tpp58WWf+aa67RqFGjXF6SxFZkZKTGjRunJ5980u5G6s8//6yff/7Zad2goCC98847qly5sqm2Jalq1apasGCBnn/+eX3//feG1/Ly8gqScCqiN998UzVq1NAnn3xi99revXu1d+9ej7Xlrc93aSjNGTZ69eql6tWra8yYMUpPTze8dvr0aS1fvlzLly8vtfa9pUOHDnr//fc1YsQIZWVl2b2ekpKilJQUh3Uff/xxDRw4UM8++6yhPDIy0qW2Y2JiNGTIEL333nt2r50/f17nz5+3Ky/vs4cAAAAAKDssLwIAAAAA8Htdu3bV/fffbze9vVn16tXTlClTNH78eAUGBrpVNzY2VnPnztXQoUNLlEgg/bGExD333OPSvtHR0Zo9e7Y6derkVhudO3fWRx99ZHppkUtuuOEGffDBBwoPD3e5TvXq1fXRRx/pjjvuKFHb0h+JF9OmTdMLL7ygGjVqlOhYderU0QMPPFDiPpWFgIAAjRo1SpMmTVKdOnVMHcNisSg6Otqlfb31+fY1d911lxYtWqSOHTuW6DhBQUHq2LGjmjdv7qGela4OHTpo6dKldkv+OFOjRg1NmDChYKmc1NRUw+vufMaGDh2qZ555RsHBwa53GAAAAADETBcAAAAAAKhdu3Zq166dcnJytGnTJm3cuFGbN2/W9u3bnS4bYqtGjRq64YYbdP/99+umm25SUJD5S+6QkBCNHDlSjz/+uObPn6+1a9dqx44dhqnvHQkODlarVq104403qkOHDmrVqpVb7UZHR2vq1Kn65ptvNGvWLG3ZskVWq9Xhvq1bt9bAgQPVuXNnt9ooym233aaVK1fqvffe07Jly5y+91FRUXrggQf01FNPKSoqymPtWywW9evXTz169NCiRYu0cuVKbd261eFT94UFBAToiiuu0A033KDbbrtN1157rSwWi8f6VRa6dOmiO++8U4sXL9Z//vMfxcfH2806Yqt58+bq0KGDHnjgATVs2NDltrz1+fY1jRo10rRp07Rnzx7NmzdP69at07Fjx4qtFxUVpeuuu0433XST7rjjDlWvXr0Meus5DRs21MyZM7V9+3atXLlSGzZsUGJiolJSUhQcHKyYmBi1aNFCHTt21D333KNKlSoV1C28dI30RzKVqwICAjR48GA98sgjWrFihTZt2qT9+/crOTlZGRkZxX4PAAAAAPBfFquzX08AAAAAAPBzVqtViYmJOnz4sE6ePKm0tDSlp6fLYrEoMjJSERERuuyyy9S8efMSz45QnIyMDO3YsUPJyck6d+6cUlNTValSJUVERKh69epq1KiRGjRo4NGntBMTE7V9+3YlJSXp/PnzCg8PV506dXTVVVepZs2advt36tTJsBRL9+7dNX78eFNt5+TkKD4+XkePHlVKSory8/NVrVo1NWvWTC1btixRUos7srOztWPHDiUmJha874GBgYqIiFC1atXUqFEjNWrUyHDjtyLIyMjQtm3blJycrJSUFKWnpys8PFyVK1dWgwYN1KRJE1WrVs2j7ZX159sXnThxQnv37lVKSorOnTunrKwshYeHKzIyUrVr11bjxo0dxqY/uHjxotq1a2dI3hk6dKhGjhzpxV4BAAAA8AckXQAAAAAAAI/wZNIFALhj9erVevrppw1l06ZNK/ESLQAAAABQnABvdwAAAAAAAAAASuKjjz4ybAcHB6tNmzbe6QwAAAAAv0LSBQAAAAAAAACf9dFHHyk+Pt5Qduedd3p0CRwAAAAAcIakCwAAAAAAAABetXnzZi1evFjZ2dku18nPz9f777+viRMn2r3Wu3dvT3YPAAAAAJwK8nYHAAAAAAAAAPi3U6dOacyYMXrrrbd0++23q2PHjoqLi1NsbKzdvgcPHtSvv/6qTz/9VIcPH7Z7/eGHH9Y111xTBr0GAAAAAJIuAAAAAAAAAJQTKSkpWrhwoRYuXChJioiIUFRUlCIiIpSenq6UlBRlZGQ4rd+8eXO9+OKLZdVdAAAAACDpAgAAAAAAAED5lJ6ervT0dJf27dChgyZOnKiwsLBS7hUAAAAA/A9JFwAAAAAAAAC8qmHDhmrZsqUSEhLcrtukSRM9+eST6tq1qwICAkqhdwAAAADgHEkXAAAAAAAAALwqLi5OixYt0smTJ7VhwwZt27ZNBw8e1IkTJ5SSkqLMzExJUuXKlVW1alXVqVNHV199tdq3b69rrrlGFovFy38BAAAAAH9lsVqtVm93AgAAAAAAAAAAAAAAwNcw3x4AAAAAAAAAAAAAAIAJJF0AAAAAAAAAAAAAAACYQNIFAAAAAAAAAAAAAACACSRdAAAAAAAAAAAAAAAAmEDSBQAAAAAAAAAAAAAAgAkkXQAAAAAAAAAAAAAAAJhA0gUAAAAAAAAAAAAAAIAJJF0AAAAAAAAAAAAAAACYQNIFAAAAAAAAAAAAAACACSRdAAAAAAAAAAAAAAAAmEDSBQAAAAAAAAAAAAAAgAkkXQAAAAAAAAAAAAAAAJhA0gUAAAAAAAAAAAAAAIAJJF0AAAAAAAAAAAAAAACYQNIFAAAAAAAAAAAAAACACSRdAAAAAAAAAAAAAAAAmEDSBQAAAAAAAAAAAAAAgAkkXQAAAAAAAAAAAAAAAJhA0gUAAAAAAAAAAAAAAIAJJF0AAAAAAAAAAAAAAACYQNIFAAAAAAAAAAAAAACACSRdAAAAAAAAAAAAAAAAmEDSBQAAAAAAAAAAAAAAgAkkXQAAAAAAAAAAAAAAAJhA0gUAAAAAAAAAAAAAAIAJJF0AAAAAAAAAAAAAAACYQNIFAAAAAAAAAAAAAACACSRdAAAAAAAAAAAAAAAAmPD/P+t0hydDyi8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2400x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chain length distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax = sns.histplot(data=seq_lens, ax=ax)\n",
    "ax.set(xlabel=\"Sequence Length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚úÇÔ∏è Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16668</th>\n",
       "      <td>G3UZY9</td>\n",
       "      <td>KNSPKEFTASESEVCIKTFKEQMRLELELPKLPGNRPTSPKISPRS...</td>\n",
       "      <td>16668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63730</th>\n",
       "      <td>Q7T3S3</td>\n",
       "      <td>MKQTILDLMRMSRICRMVLATCLGSFILVIFYFQSMFQPVMRRNPF...</td>\n",
       "      <td>63730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27915</th>\n",
       "      <td>P0AEC8</td>\n",
       "      <td>MRHSLPYRMLRKRPMKLSTTVILMVSAVLFSVLLVVHLIYFSQISD...</td>\n",
       "      <td>27915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80016</th>\n",
       "      <td>Q9HY46</td>\n",
       "      <td>MRRTKEDSEKTRTAILLAAEELFLEKGVSHTSLEQIARAAGVTRGA...</td>\n",
       "      <td>80016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>A0A0R4IRU1</td>\n",
       "      <td>RLLSRMAGMKDQQFTEEKPLLPDSRGQETEMENCETFVATGDWKEH...</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Entry ID                                           Sequence  Index\n",
       "16668      G3UZY9  KNSPKEFTASESEVCIKTFKEQMRLELELPKLPGNRPTSPKISPRS...  16668\n",
       "63730      Q7T3S3  MKQTILDLMRMSRICRMVLATCLGSFILVIFYFQSMFQPVMRRNPF...  63730\n",
       "27915      P0AEC8  MRHSLPYRMLRKRPMKLSTTVILMVSAVLFSVLLVVHLIYFSQISD...  27915\n",
       "80016      Q9HY46  MRRTKEDSEKTRTAILLAAEELFLEKGVSHTSLEQIARAAGVTRGA...  80016\n",
       "1959   A0A0R4IRU1  RLLSRMAGMKDQQFTEEKPLLPDSRGQETEMENCETFVATGDWKEH...   1959"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "train_df, test_df = train_test_split(df, test_size=test_size, random_state=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(data_path / \"train_split.parquet\")\n",
    "test_df.to_parquet(data_path / \"test_split.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further split a validation set\n",
    "valid_size = 0.25  # 0.8*0.25=0.2\n",
    "train_df, valid_df = train_test_split(train_df, test_size=valid_size, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üè≠ Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, EsmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92210, 500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets\n",
    "targets = np.load(data_path / \"train_bp_top500_targets.npy\")\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esm2_t12_35M_UR50D\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = df[\"Sequence\"].iloc[0]\n",
    "len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSLEQKKGADIISKILQIQNSIGKTTSPSTLKTKLSEISRKEQENARIQSKLSDLQKKKIDIDNKLLKEKQNLIKEEILERKKLEVLTKKQQKDEIEHQKKLKREIDAIKASTQYITDVSISSYNNTIPETEPEYDLFISHASEDKEDFVRPLAETLQQLGVNVWYDEFTLKVGDSLRQKIDSGLRNSKYGTVVLSTDFIKKDWTNYELDGLVAREMNGHKMILPIWHKITKNDVLDYSPNLADKVALNTSVNSIEEIAHQLADVILNR'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 20,  8,  4,  9, 16, 15, 15,  6,  5, 13, 12, 12,  8, 15, 12,\n",
       "         4, 16, 12, 16, 17,  8, 12,  6, 15, 11, 11,  8, 14,  8, 11,  4,\n",
       "        15, 11, 15,  4,  8,  9, 12,  8, 10, 15,  9, 16,  9, 17,  5, 10,\n",
       "        12, 16,  8, 15,  4,  8, 13,  4, 16, 15, 15, 15, 12, 13, 12, 13,\n",
       "        17, 15,  4,  4, 15,  9, 15, 16, 17,  4, 12, 15,  9,  9, 12,  4,\n",
       "         9, 10, 15, 15,  4,  9,  7,  4, 11, 15, 15, 16, 16, 15, 13,  9,\n",
       "        12,  9, 21, 16, 15, 15,  4, 15, 10,  9, 12, 13,  5, 12, 15,  5,\n",
       "         8, 11, 16, 19, 12, 11, 13,  7,  8, 12,  8,  8, 19, 17, 17, 11,\n",
       "        12, 14,  9, 11,  9, 14,  9, 19, 13,  4, 18, 12,  8, 21,  5,  8,\n",
       "         9, 13, 15,  9, 13, 18,  7, 10, 14,  4,  5,  9, 11,  4, 16, 16,\n",
       "         4,  6,  7, 17,  7, 22, 19, 13,  9, 18, 11,  4, 15,  7,  6, 13,\n",
       "         8,  4, 10, 16, 15, 12, 13,  8,  6,  4, 10, 17,  8, 15, 19,  6,\n",
       "        11,  7,  7,  4,  8, 11, 13, 18, 12, 15, 15, 13, 22, 11, 17, 19,\n",
       "         9,  4, 13,  6,  4,  7,  5, 10,  9, 20, 17,  6, 21, 15, 20, 12,\n",
       "         4, 14, 12, 22, 21, 15, 12, 11, 15, 17, 13,  7,  4, 13, 19,  8,\n",
       "        14, 17,  4,  5, 13, 15,  7,  5,  4, 17, 11,  8,  7, 17,  8, 12,\n",
       "         9,  9, 12,  5, 21, 16,  4,  5, 13,  7, 12,  4, 17, 10,  2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_seq = tokenizer([seq], padding=False, truncation=True, return_tensors=\"np\")\n",
    "encoded_seq[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<cls> M S L E Q K K G A D I I S K I L Q I Q N S I G K T T S P S T L K T K L S E I S R K E Q E N A R I Q S K L S D L Q K K K I D I D N K L L K E K Q N L I K E E I L E R K K L E V L T K K Q Q K D E I E H Q K K L K R E I D A I K A S T Q Y I T D V S I S S Y N N T I P E T E P E Y D L F I S H A S E D K E D F V R P L A E T L Q Q L G V N V W Y D E F T L K V G D S L R Q K I D S G L R N S K Y G T V V L S T D F I K K D W T N Y E L D G L V A R E M N G H K M I L P I W H K I T K N D V L D Y S P N L A D K V A L N T S V N S I E E I A H Q L A D V I L N R <eos>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_seq[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_seqs(batch, targets, tokenizer, padding=False, truncation=True):\n",
    "    encoded_seqs = tokenizer(\n",
    "        batch[\"Sequence\"].tolist(),\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    return dict(\n",
    "        input_ids=encoded_seqs[\"input_ids\"],\n",
    "        attention_mask=encoded_seqs[\"attention_mask\"],\n",
    "        targets=targets[batch[\"Index\"].tolist()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    df,\n",
    "    targets,\n",
    "    tokenizer,\n",
    "):\n",
    "    return tokenize_seqs(\n",
    "        df,\n",
    "        targets,\n",
    "        tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([array([ 0, 20, 17,  4,  4, 11,  8,  7,  7,  4,  6,  4, 23, 23, 11,  7,  8,\n",
       "                5, 16, 11,  7,  8,  6,  8,  9,  9, 15,  6,  4, 12, 10, 14, 18, 12,\n",
       "                4, 13,  5, 12, 16,  9,  5, 15, 10,  4,  7, 13, 13,  8, 19,  4, 19,\n",
       "                8, 10, 10, 11,  8,  4,  9, 10,  7, 10, 15, 17, 13, 19, 12, 15, 14,\n",
       "                8, 13,  7,  4, 10,  4, 20, 15, 16, 14, 15, 10, 15,  5, 10,  9,  5,\n",
       "                7, 10,  5,  5, 13, 19,  4,  9, 16, 11,  4, 10, 12, 12,  8,  9, 15,\n",
       "               11, 21, 21,  5, 21, 15, 10,  8, 12, 17,  5, 11,  5,  4,  4,  8, 21,\n",
       "                9,  9,  4, 10, 11, 12,  9, 13,  7, 11,  6, 23,  5,  6, 16, 11,  4,\n",
       "               14, 14, 14, 23, 10, 11,  4, 14, 13,  4, 17, 10, 19, 10, 11,  5, 17,\n",
       "                8,  7, 23, 17, 17, 21, 12, 17, 14,  4, 16,  6,  5,  8, 17, 11,  5,\n",
       "               18, 11, 10, 22,  4, 14, 14,  7, 19,  9, 13, 17,  7,  8,  9, 14, 10,\n",
       "                6, 22, 17, 14,  9, 10,  4, 19, 17,  6,  5,  5,  4, 14,  4,  7, 10,\n",
       "                4,  7,  8, 17, 10, 12, 18,  8, 11, 16, 13, 16, 17,  7, 16,  6, 13,\n",
       "               11,  9, 19, 11,  4,  4, 12, 11, 18, 18,  6, 16, 22, 17, 13, 21, 13,\n",
       "                4,  8, 18, 11, 14, 18,  8, 14,  8, 12, 10,  8, 18,  8, 17,  6, 12,\n",
       "               17, 23, 13, 13,  8, 23,  9, 10,  8,  9, 14, 23, 18, 14, 12, 16, 12,\n",
       "               14, 10,  8, 13, 14, 10,  4, 14,  4, 10,  8, 17,  8, 23,  4, 14,  7,\n",
       "               18, 10,  8,  5, 14,  5, 23,  6,  8,  6, 17,  8, 14, 19, 20, 18,  6,\n",
       "                6,  7, 14, 10,  4, 10,  9, 16,  4, 17, 11,  4, 11,  8, 19,  4, 13,\n",
       "                5,  6, 16,  4, 19,  6,  8,  9,  9,  6,  4,  5, 21,  9,  4, 10, 13,\n",
       "                4, 11, 11, 13,  6,  6,  4, 20, 10, 12, 17, 13, 10, 18, 10, 13, 17,\n",
       "                6, 10,  9,  4,  4, 14, 18, 11, 15,  7, 14,  8, 15, 20, 23,  5, 11,\n",
       "               10, 17, 10, 12,  4, 17, 11, 11,  6,  4,  9,  9,  7, 14, 23, 18, 12,\n",
       "                5,  6, 13,  9, 10,  7, 13,  9, 17, 12,  5,  4, 11,  8, 20, 21, 11,\n",
       "                4, 18,  4, 10,  9, 21, 17, 10,  4,  5, 10,  5,  4, 10, 10,  4, 17,\n",
       "               14, 17, 22, 11,  8,  9, 16,  4, 19, 16,  9,  5, 10, 15, 12,  7,  6,\n",
       "                5, 19,  4, 16, 17, 12,  7, 18, 15, 13, 19,  4, 14, 21, 12,  7,  6,\n",
       "               11, 13,  5, 20, 17, 15, 16,  4,  6, 15, 19, 14,  6, 19, 17, 14, 17,\n",
       "               12, 13, 14, 11, 12,  8, 17,  7, 18,  5, 11,  5,  5, 19, 10, 18,  5,\n",
       "               21,  5, 11, 12, 16, 14,  7, 12, 18, 10,  4, 13,  9, 17, 18, 16,  9,\n",
       "               17, 10, 16, 18, 14, 11,  7, 14,  4, 19,  9,  5, 18, 18, 11, 14, 22,\n",
       "               10, 12, 12, 18,  9,  6,  6, 12, 13, 14, 16, 12, 10,  6,  4, 12,  8,\n",
       "               10, 14,  5, 15,  4, 17, 10, 16, 13,  6, 12, 20,  7, 13,  5,  7, 10,\n",
       "                9, 10,  4, 18,  5, 18, 17,  8, 15, 12,  8, 16, 13,  4,  6,  8,  4,\n",
       "               17,  4, 16, 10,  6, 10, 13, 21,  5,  4, 14,  6, 19, 17,  9, 22, 22,\n",
       "               10, 18, 23,  6,  4,  8,  5, 14, 10, 17,  7,  5,  9,  4,  6, 10,  7,\n",
       "                4, 17, 17,  5, 11,  4,  5, 16, 10, 12,  4, 16,  4, 19,  6, 10, 11,\n",
       "               13, 17, 12, 13,  4, 22,  7,  6,  6, 12,  5,  9, 14, 18,  7, 14,  6,\n",
       "                6, 10,  7,  6, 14,  4, 18,  8, 23, 12, 12,  5, 11, 16, 18, 16, 10,\n",
       "               12, 10, 16,  6, 13, 10,  4, 22, 22,  9, 17, 20,  6,  7, 18, 11,  5,\n",
       "                5, 16, 15,  5,  8,  4,  8, 10,  7,  8,  4,  5,  8, 12, 12, 23, 13,\n",
       "               17, 11,  6, 12, 11, 10,  7, 14, 10, 17, 14, 18,  4, 18,  8, 10, 17,\n",
       "               16,  5, 13, 18,  7, 17, 23,  6,  8, 12, 16,  6,  4, 13,  4, 17,  5,\n",
       "               22, 10,  9, 11, 13, 13,  8,  8,  8,  9, 11,  5,  8, 13,  9, 17,  9,\n",
       "               12, 14, 15,  9, 15,  9,  8, 17, 13,  4, 16, 13,  4, 20, 13,  4,  4,\n",
       "               13, 15, 16,  7,  6, 16, 15,  2])                                   ,\n",
       "        array([ 0, 20,  4,  6, 18,  4,  4, 18,  4, 14,  4,  7,  6,  5,  5,  7, 12,\n",
       "                6, 14, 10,  5, 17,  8, 16, 12, 23, 14,  6, 19, 15,  5,  8, 21,  5,\n",
       "               15, 21, 17,  8, 21, 11, 18, 11,  5, 13,  4, 11,  4,  5,  6, 15, 14,\n",
       "               23, 13, 11, 19,  6, 11, 13,  4, 15, 13,  4, 15,  4,  4,  7,  9, 19,\n",
       "               16, 11, 13,  9, 10,  4, 21,  7, 20, 12, 19, 13,  5, 17,  9, 16,  7,\n",
       "               19, 16,  7, 14,  9,  8,  7,  4, 14, 10,  7,  6, 17,  6, 17,  6, 11,\n",
       "                9, 15, 13,  8,  5,  4, 15, 18, 13, 19,  7,  9,  9, 14, 18,  8, 18,\n",
       "               11,  7,  8, 10, 17,  6, 13,  7,  4, 18, 13, 11,  8,  5,  8, 17,  4,\n",
       "               12, 18, 16,  8, 16, 19,  4, 17,  4, 10, 11, 22,  4, 14, 17, 13, 14,\n",
       "               21,  4, 19,  6,  4,  6,  9, 21, 11, 13,  8,  4, 10,  4,  9, 11, 17,\n",
       "               17, 19, 11, 10, 11,  4, 22, 17, 10, 13,  8, 19,  6,  7, 14,  8, 21,\n",
       "                8, 17,  4, 19,  6,  5, 21, 14,  7, 19, 19, 13, 21, 10,  6,  8,  5,\n",
       "                6, 11, 21,  6,  7, 18,  4,  5, 17,  8, 17,  6, 20, 13, 12, 15, 12,\n",
       "               17, 15, 11,  4, 13,  6, 15, 16, 19,  4,  9, 19, 17, 12,  4,  6,  6,\n",
       "                7,  4, 13, 18, 19, 18, 18, 11,  6,  8, 11, 14, 15,  9,  5,  8, 11,\n",
       "               16, 19,  5, 15,  7,  7,  6,  4, 14,  5, 20, 16,  8, 19, 22, 11, 18,\n",
       "                6, 18, 21, 16, 23, 15, 19,  6, 19, 10, 13,  7, 19,  9,  7,  5,  9,\n",
       "                7,  7, 19, 17, 19,  8, 16,  5,  6, 12, 14,  4,  9, 11, 20, 22, 11,\n",
       "               13, 12, 13, 19, 20,  9,  4, 10, 10,  7, 18, 11,  4, 13, 14,  9, 10,\n",
       "               18, 14,  4,  6, 15, 20, 10,  9,  4,  7, 13, 19,  4, 21, 13, 21, 17,\n",
       "               16, 21, 19, 12,  7, 20,  7, 13, 14,  5,  7,  8, 11,  8,  6,  5,  7,\n",
       "               22, 14,  6,  7, 11,  7, 19, 14, 13, 22, 18, 21, 14,  5, 12, 16, 13,\n",
       "               19, 22, 17,  6,  9, 18, 17, 15, 18, 18, 13, 14,  9, 11,  6, 12, 13,\n",
       "               12, 13,  6,  4, 22, 12, 13, 20, 17,  9,  5,  5, 17, 20, 23, 11, 18,\n",
       "               14, 23, 11, 13, 14,  9, 10, 19,  8, 12,  9, 17, 13,  4, 14, 14,  5,\n",
       "               14, 14,  5,  7, 10, 14,  8, 17, 14, 10, 14,  4, 14,  6, 18, 14, 13,\n",
       "               13, 18, 16, 14,  6,  8,  8, 15, 10,  4,  8, 15, 10,  5, 21,  6, 13,\n",
       "               15,  4,  6,  4, 14,  6, 10, 17,  4,  4,  8, 14, 14, 19,  8, 12, 15,\n",
       "               17,  5,  5,  6,  5,  4,  8, 16, 17, 11, 12, 16, 11, 17, 12,  6, 21,\n",
       "                5,  6,  6, 19,  7,  9, 19, 13, 11, 21, 17,  4, 19,  6, 11, 20, 20,\n",
       "                8,  8,  5,  8, 10, 12,  5, 20, 16, 16, 10, 10, 14, 13,  7, 10, 14,\n",
       "                4, 12, 12, 11, 10,  8, 11,  4,  6, 13, 17,  4,  8, 11, 22, 15,  4,\n",
       "               19, 10,  5,  8, 12,  5, 16,  7,  4,  5, 18,  5,  8, 20, 18, 16, 12,\n",
       "               14, 20,  7,  6,  5, 13,  7, 23,  6, 18,  6,  8, 17, 11, 11,  9,  9,\n",
       "                4, 23,  5, 10, 22,  5,  8,  4,  6,  5, 18, 19, 11, 18, 19, 10, 17,\n",
       "               21, 17,  9, 12,  6, 17, 12, 14, 16,  9, 19, 19, 19, 22,  9,  8,  7,\n",
       "               11,  9,  8,  5, 11, 15,  5, 12, 17, 12, 10, 19, 16,  4,  4, 13, 19,\n",
       "                7, 19, 11,  5, 18, 21, 10, 16,  8, 15, 11,  6,  9, 14, 18,  4, 16,\n",
       "               14,  4, 18, 19,  4, 19, 14,  9, 13, 15, 17, 11, 18,  5, 12, 13,  4,\n",
       "               16, 18, 18, 19,  6, 13,  5, 12,  4, 12,  8, 14,  7, 11,  9, 15, 17,\n",
       "                8, 11,  8,  7, 17,  5, 19, 18, 14, 15, 13, 12, 18, 19, 13, 22, 19,\n",
       "               11,  6,  5,  7, 12, 16,  6, 16,  6,  5, 17, 12, 12,  4,  8, 17, 12,\n",
       "               17, 12, 11, 21, 12, 14, 12, 21, 12, 10,  6,  6, 17, 12,  7, 14, 12,\n",
       "               10,  8,  8,  6,  5, 20, 11, 11, 11,  9,  4, 10, 15, 15,  6, 18, 16,\n",
       "                4, 12, 12,  5,  8,  6, 12, 13,  6, 11,  5,  8,  6,  8,  4, 19,  4,\n",
       "               13, 13,  6, 13,  8,  4,  9, 16, 11, 13, 11,  5, 17, 12,  9, 18,  9,\n",
       "               19, 10,  8,  6,  7,  4, 19, 12, 15,  6, 16, 18, 12, 21, 13,  7, 14,\n",
       "                7, 15, 12,  9,  8,  7, 12,  4,  4,  6, 16, 11, 11, 11,  5,  6,  5,\n",
       "                6, 10, 21, 17, 16, 15, 16,  7, 12,  9, 11, 17,  4,  9,  4, 11,  5,\n",
       "               14, 11, 10,  7, 15,  4,  5,  2])                                   ,\n",
       "        array([ 0, 20, 11, 20,  9, 16,  9, 12,  9,  7,  4, 13, 16, 18, 14,  7,  6,\n",
       "               20, 10,  7,  4,  5,  7, 13, 13, 13, 16, 11, 23,  4, 10, 12,  4, 16,\n",
       "               11,  4,  4, 16, 10, 23, 16, 19, 21,  7, 11, 11, 11, 17, 16,  5, 16,\n",
       "               11,  5,  4,  9,  4,  4, 10,  9, 17, 15, 17, 15, 18, 13,  4,  7, 12,\n",
       "                8, 13,  7, 13, 20, 14, 13, 20, 13,  6, 18, 15,  4,  4,  9,  4,  7,\n",
       "                6,  4,  9, 20, 13,  4, 14,  7, 12, 20,  4,  8,  5, 21,  8, 13, 14,\n",
       "               15, 19,  7, 20, 15,  6,  7, 15, 21,  6,  5, 23, 13, 19,  4,  4, 15,\n",
       "               14,  7, 10, 12,  9,  9,  4, 15, 17, 12, 22, 16, 21,  7,  7, 10, 15,\n",
       "                8, 15,  4, 15, 15, 17, 15,  8, 17,  7,  8, 17,  6,  8,  6, 17, 23,\n",
       "               13, 15,  5, 17, 10, 15, 10, 15,  9, 16, 19,  9,  9,  9,  9,  9,  9,\n",
       "                9, 10,  6, 17, 13, 17, 13, 13, 14, 11,  5, 16, 15, 15, 14, 10,  7,\n",
       "                4, 22, 11, 21,  9,  4, 21, 17, 15, 18,  4,  5,  5,  7, 13, 21,  4,\n",
       "                6,  7,  9, 10,  5,  7, 14, 15, 15, 12,  4, 13,  4, 20, 17,  7, 13,\n",
       "               15,  4, 11, 10,  9, 17,  7,  5,  8, 21,  4, 16, 15, 18, 10,  7,  5,\n",
       "                4, 15, 15,  7,  8, 13, 13,  5, 12, 16, 16,  5, 17, 10,  5,  5, 12,\n",
       "               13,  8, 21, 18, 20, 16, 20, 17,  8, 16, 15,  6,  4,  6,  6, 18, 19,\n",
       "               21, 21, 21, 10,  6, 12, 14,  7,  6,  8,  6, 16, 18, 21,  6,  6, 11,\n",
       "               11, 20, 20, 10, 21, 19,  8,  8, 17, 10, 17,  4,  6, 10,  4, 17,  8,\n",
       "                4,  6,  5,  6, 20, 18, 16, 14,  7,  8,  8,  8, 18, 14, 10, 17, 21,\n",
       "               17, 13,  6,  6, 17, 12,  4, 16,  6,  4, 14,  4,  9,  9,  4, 16, 12,\n",
       "               17, 17, 17, 12, 17, 10,  5, 18, 14,  8, 18, 11,  8, 16, 16, 17,  8,\n",
       "               14, 20,  7,  5, 14,  8, 17,  4,  4,  4,  4,  9,  6, 17, 14, 16,  8,\n",
       "                8,  8,  4, 14,  8, 17, 14,  6, 18,  8, 14, 21, 18,  9, 12,  8, 15,\n",
       "               10,  4,  9, 21, 22,  8, 17,  5,  5,  4,  8, 11, 17, 12, 14, 16,  8,\n",
       "               13,  7, 21,  8, 15, 14, 13, 11,  4,  9, 22, 17,  5, 18, 23, 13,  8,\n",
       "                5,  8, 14,  4,  7, 17, 14, 17,  4, 13, 11, 17, 14,  5,  8,  4, 23,\n",
       "               10, 17, 11,  6, 18,  6,  8, 11, 17,  5,  5, 16, 11, 13, 18, 18, 19,\n",
       "               14,  4, 16, 20, 17, 16, 16, 14,  5, 17, 17,  8,  6, 14,  7, 11,  9,\n",
       "                5, 16,  4, 18, 10,  8,  8, 17, 14, 17,  9,  6,  4,  4, 20,  6, 16,\n",
       "               16, 15,  4, 16,  8,  6,  4, 20,  5,  8, 13,  5,  6,  8,  4, 13, 13,\n",
       "               12,  7, 17,  8,  4, 20, 11, 16,  9, 16,  8, 16,  8, 13, 18,  8,  9,\n",
       "                6, 13, 22, 13,  4, 13,  6,  4,  5, 21,  8,  9, 21,  5, 19,  9, 15,\n",
       "                4, 21, 18, 14, 18,  8,  4,  8,  5,  2])                           ,\n",
       "        ...,\n",
       "        array([ 0, 20,  9, 21, 15,  7, 12, 23,  7,  4,  5,  7,  7,  4, 20,  4,  5,\n",
       "               18,  6,  8,  4,  5, 16,  5, 16,  5, 16,  5, 16,  5, 16,  9,  9, 11,\n",
       "               23, 12, 20,  5, 14, 10,  9, 10, 12, 17, 23,  6, 18, 14,  6,  7, 11,\n",
       "                5, 16, 16, 23, 11,  9, 10,  6, 23, 23, 18, 13, 13,  8,  7, 10,  6,\n",
       "               18, 14, 22, 23, 18, 21, 14, 20,  5, 12,  9, 17, 11, 16,  9,  9,  9,\n",
       "               23, 14, 18,  2])                                                   ,\n",
       "        array([ 0, 20, 20,  9,  4,  9,  8,  9, 11, 16,  9,  4, 21,  4, 21,  7, 17,\n",
       "                6,  9, 14,  9,  6, 15, 18,  8, 11,  9,  9, 10,  8, 21, 15, 19,  8,\n",
       "               22, 10,  4, 10,  7,  8,  4, 19,  7, 11,  4,  4,  4,  5,  6,  9, 11,\n",
       "               12,  5, 11,  4,  4,  6, 10,  4, 19, 19,  9, 15,  6,  6, 15,  8, 11,\n",
       "               22,  4,  9, 11,  4,  7, 16,  4,  7,  6, 18, 14,  4, 11,  4, 14, 23,\n",
       "               19, 19, 19,  4, 15, 14,  9, 14,  8, 15, 11, 15, 11, 12, 11, 15, 15,\n",
       "               11, 11,  8,  8, 18,  4, 11,  4,  8,  4,  7, 19, 12,  6,  4,  6,  4,\n",
       "                4,  7,  5,  6, 21, 23, 12,  4, 19,  8, 18,  6,  4,  4, 19,  4, 14,\n",
       "                7,  8, 11, 18,  8,  4, 12,  8,  5,  8, 16,  4,  5, 18, 17,  5,  7,\n",
       "               18,  8, 19, 18,  4, 17,  8, 16, 15, 12, 11, 14, 18, 12,  4, 17,  8,\n",
       "                4,  7,  4,  4, 11, 12,  8,  8, 11,  4,  4,  7, 12, 16, 21,  9, 14,\n",
       "                9,  8, 14,  8,  8, 11,  8, 15,  8,  5,  5, 15,  8, 15, 19,  7, 12,\n",
       "                6, 19, 12, 23,  5,  7,  6,  8,  8,  5,  6, 19,  8,  4,  7,  4,  8,\n",
       "                4, 11, 13, 19,  5, 18,  9, 15, 12,  4, 15, 15, 19, 11, 18, 15,  5,\n",
       "               12,  4, 13, 20,  5, 11, 19, 14,  8, 20,  7,  5, 11, 23,  7,  7,  7,\n",
       "                7,  6,  4, 18,  6,  8,  6,  6, 22, 15, 15,  4,  8, 11,  9, 20,  9,\n",
       "                9, 18, 16,  4,  6, 15,  8,  8, 19, 12,  4, 12, 17, 12,  6,  8, 11,\n",
       "               12,  8, 22, 16,  5, 23,  4, 12,  6,  8,  7,  6,  4, 12, 12,  9,  7,\n",
       "                8,  8,  4, 18,  8, 17,  7, 12,  8, 11,  4, 23,  4, 14,  7,  7, 14,\n",
       "                7,  4,  5,  7,  7, 18, 18, 10, 13,  9, 20,  8,  6, 12, 15,  4,  7,\n",
       "                5, 20, 18,  4,  5, 12, 22,  6, 18,  7,  8, 19,  6, 19, 16, 21, 19,\n",
       "                7, 17, 13, 10, 15, 14,  9,  9, 13, 16,  9,  4, 14, 16,  8, 15,  9,\n",
       "                9,  9,  9, 16, 15, 16,  7, 13, 11, 12, 21,  7, 16,  5,  2])       ,\n",
       "        array([ 0, 20,  5,  8,  6, 15,  9, 17,  7, 18, 11, 21,  8, 12, 11, 18, 21,\n",
       "                8, 18, 14, 12,  8, 16, 11, 22, 18,  8, 23,  7,  4, 20, 13, 15, 19,\n",
       "               12,  5, 12, 11, 23,  7,  4,  7, 13,  5, 13, 15,  6,  9, 10, 12,  4,\n",
       "               15,  4, 11,  9,  7, 12, 15,  9,  4, 15,  5,  4, 17, 10, 11,  7, 11,\n",
       "               21, 17,  8,  7, 20,  8, 17,  5, 14,  8, 20, 13, 11,  9,  9, 23, 23,\n",
       "                8, 16,  8,  5,  4, 15, 23, 18, 10,  5, 20,  7, 14, 21,  4, 15,  5,\n",
       "               15, 17, 15, 11,  4, 16, 10, 15,  7, 12, 15, 17,  4, 17, 17, 10, 20,\n",
       "               12,  4,  6,  8,  4, 13,  8, 23,  8, 16,  9,  9, 10,  9, 15, 11,  7,\n",
       "               23, 16,  6, 23, 13,  8, 19, 14, 15, 13,  8, 16, 15, 23,  7, 16, 16,\n",
       "                4,  9,  8,  4,  4, 16, 15,  5, 12,  8, 10,  4,  5,  2])           ],\n",
       "       dtype=object),\n",
       " 'attention_mask': array([array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1])                                                        ,\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1])                                                  ,\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1])                                                     ,\n",
       "        ...,\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1])                                                              ,\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])                    ,\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])                          ],\n",
       "       dtype=object),\n",
       " 'targets': array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(train_df, targets, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚òÅÔ∏è Distributed Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.data.DatasetContext.get_current().execution_options.preserve_order = (\n",
    "    True  # deterministic\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0090dca3f8d143dc9e901238670a06b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet Files Sample 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:15:45,841\tINFO dataset.py:2488 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2024-02-13 11:15:45,844\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=89 for stage ReadParquet to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-02-13 11:15:45,845\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 89, each read task output is split into 89 smaller blocks.\n",
      "2024-02-13 11:15:45,845\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> AllToAllOperator[RandomShuffle] -> LimitOperator[limit=1]\n",
      "2024-02-13 11:15:45,846\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-13 11:15:45,847\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0def1c1e0884c31a48a20721d757e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomShuffle 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474d10fa554841ac9ea9bc46adc48513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e6b68405b24d2fbbfb5f49b4438694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342d81fb609d475e8e5602172921a660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ReadParquet->SplitBlocks(89) pid=54098)\u001b[0m /home/ytian/anaconda3/envs/ml/lib/python3.10/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by mode='default'.\n",
      "\u001b[36m(ReadParquet->SplitBlocks(89) pid=54098)\u001b[0m   return transform_pyarrow.concat(tables)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Entry ID': 'Q17604',\n",
       "  'Sequence': 'MVSHKKNDRPRPLWILKIHKRLSLFEFKRYATGIGKDDGQDISWVLKGNAKNNVYQVTVETMENCETDECKKVIWVPDELAESTGTMFEDFKEDQPQESVSSISNNEANWGSSVNELDENYEKMQKEETFDPYDSDSDTSEDSDFDEDFEDSDKTMCSGQS',\n",
       "  'Index': 48142,\n",
       "  '__index_level_0__': 48142}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ray.data.read_parquet(data_path / \"train_split.parquet\")\n",
    "ds = ds.random_shuffle(seed=0)\n",
    "ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:15:46,979\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=89 for stage ReadParquet to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-02-13 11:15:46,979\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 89, each read task output is split into 89 smaller blocks.\n",
      "2024-02-13 11:15:46,980\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> AllToAllOperator[RandomShuffle]\n",
      "2024-02-13 11:15:46,980\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-13 11:15:46,981\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee16270963f4bd4976b9694092d0721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomShuffle 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138776af1d76465ea8ea497c3c0c90aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ae7ae6ced74dbea466f0ae40e94480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed0ab30c74b481ead1ebb2e92f5d768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_size = 0.25\n",
    "train_ds, valid_ds = ds.train_test_split(test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:15:47,622\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)] -> LimitOperator[limit=1]\n",
      "2024-02-13 11:15:47,623\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-13 11:15:47,623\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6020bce524e04678a0c012bb76b21d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([ 0, 20,  7,  8, 21, 15, 15, 17, 13, 10, 14, 10, 14,  4, 22, 12,  4,\n",
      "       15, 12, 21, 15, 10,  4,  8,  4, 18,  9, 18, 15, 10, 19,  5, 11,  6,\n",
      "       12,  6, 15, 13, 13,  6, 16, 13, 12,  8, 22,  7,  4, 15,  6, 17,  5,\n",
      "       15, 17, 17,  7, 19, 16,  7, 11,  7,  9, 11, 20,  9, 17, 23,  9, 11,\n",
      "       13,  9, 23, 15, 15,  7, 12, 22,  7, 14, 13,  9,  4,  5,  9,  8, 11,\n",
      "        6, 11, 20, 18,  9, 13, 18, 15,  9, 13, 16, 14, 16,  9,  8,  7,  8,\n",
      "        8, 12,  8, 17, 17,  9,  5, 17, 22,  6,  8,  8,  7, 17,  9,  4, 13,\n",
      "        9, 17, 19,  9, 15, 20, 16, 15,  9,  9, 11, 18, 13, 14, 19, 13,  8,\n",
      "       13,  8, 13, 11,  8,  9, 13,  8, 13, 18, 13,  9, 13, 18,  9, 13,  8,\n",
      "       13, 15, 11, 20, 23,  8,  6, 16,  8,  2]), 'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1]), 'targets': array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "sample_ds = train_ds.map_batches(\n",
    "    preprocess,\n",
    "    fn_kwargs={\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"targets\": targets,\n",
    "    },\n",
    "    batch_format=\"pandas\",\n",
    ")\n",
    "sample_ds.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÉTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=0):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    eval(\"setattr(torch.backends.cudnn, 'deterministic', True)\")\n",
    "    eval(\"setattr(torch.backends.cudnn, 'benchmark', False)\")\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOC = data_path / \"train_split.parquet\"\n",
    "\n",
    "\n",
    "def load_data(num_samples=None):\n",
    "    ds = ray.data.read_parquet(DATASET_LOC)\n",
    "    ds = ds.random_shuffle(seed=0)\n",
    "    ds = ray.data.from_items(ds.take(num_samples)) if num_samples else ds\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPreprocessor:\n",
    "    \"\"\"Custom preprocessor class.\"\"\"\n",
    "\n",
    "    def transform(self, ds):\n",
    "        return ds.map_batches(\n",
    "            preprocess,\n",
    "            fn_kwargs={\n",
    "                \"tokenizer\": tokenizer,\n",
    "                \"targets\": targets,\n",
    "            },\n",
    "            batch_format=\"pandas\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ü§ñ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = EsmModel.from_pretrained(model_name)\n",
    "embedding_dim = llm.config.hidden_size\n",
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token_id = llm.config.pad_token_id\n",
    "pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1446, -0.2660,  0.1712,  ..., -0.4816, -0.0534,  0.1805],\n",
       "         [-0.5734, -0.0414,  0.0484,  ..., -0.3091, -0.1884,  0.1087],\n",
       "         [-0.1941,  0.1439,  0.3154,  ...,  0.0504, -0.3529,  0.2344],\n",
       "         ...,\n",
       "         [-0.1977, -0.1326,  0.2912,  ..., -0.1406, -0.1176,  0.0924],\n",
       "         [-0.1192, -0.0658,  0.2952,  ..., -0.0859, -0.1602,  0.1112],\n",
       "         [-0.1797,  0.0206,  0.2692,  ..., -0.1254, -0.2582,  0.0178]],\n",
       "\n",
       "        [[-0.2242, -0.1906,  0.1815,  ..., -0.6006, -0.0007,  0.1336],\n",
       "         [-0.3523,  0.1899, -0.0292,  ..., -0.4881, -0.0595,  0.0969],\n",
       "         [-0.1907,  0.1744,  0.2269,  ..., -0.3823, -0.0320,  0.1509],\n",
       "         ...,\n",
       "         [-0.1719,  0.2291,  0.2042,  ..., -0.2456, -0.3433,  0.0727],\n",
       "         [ 0.0536, -0.1797,  0.2266,  ..., -0.2682, -0.1334, -0.0527],\n",
       "         [-0.3323,  0.2857,  0.2473,  ..., -0.5516, -0.1463,  0.0068]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 9.5062e-02,  3.9065e-01,  1.4700e-01, -2.4104e-02,  9.8816e-02,\n",
       "         -5.0994e-02,  8.5345e-02, -1.7930e-01, -2.2405e-01,  4.7676e-02,\n",
       "          1.8080e-01, -2.0817e-02,  3.2877e-02,  1.3291e-01,  4.5038e-02,\n",
       "         -1.9176e-01, -3.2537e-02, -2.6202e-01,  1.5646e-01, -1.0461e-01,\n",
       "         -2.7721e-01, -9.6906e-02,  1.8906e-01, -7.9032e-02, -6.6490e-03,\n",
       "          1.3639e-01,  8.9781e-02,  1.1918e-01, -2.7155e-02,  2.8102e-02,\n",
       "          3.8198e-01, -7.5937e-02, -8.4351e-02,  8.7086e-03,  9.1450e-02,\n",
       "         -3.0892e-01,  1.8132e-01, -3.6702e-02, -1.5819e-02,  3.9951e-02,\n",
       "         -1.1483e-01,  1.4150e-01,  3.1592e-03, -2.7788e-03, -1.5557e-01,\n",
       "          3.8999e-02,  1.4298e-01,  1.3001e-01, -1.0179e-01,  2.6773e-01,\n",
       "          1.0434e-03, -2.0554e-01, -1.2845e-01,  1.5493e-01, -2.8221e-01,\n",
       "         -5.8134e-02, -1.0774e-01,  6.5968e-03, -8.5740e-02, -3.1607e-02,\n",
       "          5.8699e-02, -1.0846e-01,  7.6971e-02,  1.5445e-01, -1.0954e-01,\n",
       "          8.1410e-02,  1.4909e-01,  3.6048e-01,  8.2494e-02,  1.1802e-01,\n",
       "         -1.1644e-03, -1.5218e-01, -1.5288e-02, -1.5686e-01,  9.0913e-02,\n",
       "          2.3846e-01,  4.2831e-02,  3.7549e-02, -3.4441e-01, -6.0707e-02,\n",
       "          1.8258e-02,  9.0997e-02,  8.7954e-02, -1.7442e-01, -1.1773e-01,\n",
       "          1.6320e-01,  3.9710e-02, -2.0046e-01, -9.2861e-02,  2.2550e-01,\n",
       "          1.6687e-01,  1.8245e-02,  1.6556e-01, -5.2289e-02, -5.3823e-02,\n",
       "          9.4358e-02,  5.2320e-02, -8.4555e-02,  8.5107e-02, -2.4406e-02,\n",
       "          3.4050e-01, -2.8917e-01,  2.6248e-01, -1.3812e-01, -1.2057e-01,\n",
       "          1.1058e-01, -2.9670e-02, -2.2231e-01, -2.6654e-01,  2.7449e-01,\n",
       "          6.0043e-03, -6.0524e-02,  1.3085e-01,  4.9276e-02, -3.3316e-02,\n",
       "          1.2084e-01,  1.0422e-01,  5.4712e-02, -1.7527e-01,  4.3932e-02,\n",
       "          1.1545e-01, -8.5003e-02, -2.2938e-01,  3.0133e-01,  1.4819e-02,\n",
       "          2.4506e-01, -2.6174e-01, -5.9191e-02, -2.7405e-02, -1.9601e-01,\n",
       "         -1.7231e-01,  7.8570e-02, -3.4795e-02,  3.5744e-02,  1.5313e-01,\n",
       "          1.4408e-01,  1.1465e-01,  6.5232e-02,  1.4156e-01,  1.1185e-01,\n",
       "         -7.5510e-02, -2.1361e-01, -1.9939e-01,  1.0831e-01,  7.0455e-02,\n",
       "         -2.6505e-02,  3.3991e-01, -1.1715e-02,  7.7136e-02,  7.5513e-02,\n",
       "          1.5956e-01,  2.5953e-01, -6.4057e-02, -7.5359e-02, -2.7305e-01,\n",
       "          5.5211e-02,  4.1450e-02, -7.5063e-02, -8.4777e-02,  2.3373e-01,\n",
       "          1.9306e-01, -4.8422e-02, -1.2702e-01,  4.7163e-02,  7.8058e-02,\n",
       "          7.6546e-02, -4.6060e-02, -8.1287e-02,  2.5868e-04,  2.7262e-01,\n",
       "          2.9326e-01,  2.1198e-01,  3.1181e-01, -3.0735e-02, -1.1582e-01,\n",
       "          9.5335e-02,  1.9797e-01,  1.9407e-01,  1.9900e-01,  4.3291e-01,\n",
       "          1.8225e-02, -2.4543e-02,  9.2413e-02,  1.0688e-01,  4.6381e-02,\n",
       "         -1.6244e-01,  1.4327e-01,  1.4114e-03, -5.0620e-02,  1.0256e-02,\n",
       "         -8.0429e-02,  1.8216e-01, -2.0436e-01,  1.4239e-01,  5.9247e-02,\n",
       "          4.4711e-02,  1.1918e-01, -2.1358e-01,  1.6375e-02,  2.4960e-01,\n",
       "         -1.1971e-01,  5.1974e-02, -3.2550e-02, -9.4265e-02,  2.4852e-01,\n",
       "          1.5798e-01, -4.5029e-01,  6.1007e-02, -1.9925e-01, -1.5809e-01,\n",
       "          2.2695e-01, -3.4347e-02,  9.6721e-02,  9.0751e-02, -3.4812e-02,\n",
       "         -3.3756e-01, -6.0745e-02,  6.2331e-02, -2.0974e-01, -2.3456e-01,\n",
       "         -6.2871e-02, -1.3688e-01, -1.1832e-01, -1.8776e-01, -2.1720e-03,\n",
       "          3.9867e-02,  1.3979e-01,  4.8921e-02,  4.5025e-02, -1.6577e-02,\n",
       "          4.5237e-02,  2.2498e-01, -1.0307e-01, -7.3960e-02, -3.6329e-02,\n",
       "          3.9808e-01,  3.2361e-02,  2.6515e-01, -2.5965e-02,  3.3730e-02,\n",
       "          1.9484e-01, -2.0343e-01, -1.2330e-01, -2.3495e-02,  4.7310e-02,\n",
       "          9.1811e-02, -8.8555e-02, -1.7243e-01,  3.1126e-01, -2.6799e-01,\n",
       "          2.7699e-02,  1.0285e-01,  5.7679e-02,  6.5818e-02,  1.1667e-02,\n",
       "         -1.9736e-01,  1.0457e-01, -1.4234e-01,  2.1919e-01, -4.4131e-02,\n",
       "          8.5128e-02, -2.4606e-02, -1.0807e-01, -9.9292e-02, -3.6677e-02,\n",
       "         -2.0663e-01,  8.0856e-02,  1.0784e-01, -1.4217e-01,  1.7632e-01,\n",
       "          3.7254e-01, -2.1987e-01,  6.0206e-02, -3.6906e-01,  1.0949e-01,\n",
       "         -1.4844e-01,  3.0613e-01,  3.3693e-01,  1.4295e-01,  1.9528e-01,\n",
       "         -1.1679e-01, -2.7614e-01,  2.0007e-01,  1.5290e-01, -8.1205e-02,\n",
       "         -2.1349e-01,  1.7095e-01,  2.2575e-01, -2.3908e-01,  1.3554e-01,\n",
       "         -1.7647e-01,  1.6443e-01, -1.8428e-01, -2.1841e-02,  1.8465e-01,\n",
       "         -7.1278e-02,  1.4996e-01,  8.9184e-02, -4.4920e-01, -2.5124e-01,\n",
       "          2.3127e-01, -1.4030e-01,  4.7971e-01,  3.1943e-02,  1.8671e-01,\n",
       "         -7.1478e-03, -7.9173e-03, -1.2658e-01,  2.7229e-02, -1.8483e-01,\n",
       "         -5.5380e-02,  1.5614e-01,  2.2308e-01,  2.1622e-01,  1.6497e-02,\n",
       "         -1.0144e-02, -9.9192e-02,  1.5912e-01,  1.0672e-01,  6.4774e-02,\n",
       "         -6.4047e-02, -2.4618e-01, -1.1224e-02, -8.3644e-02,  1.3675e-01,\n",
       "         -1.9072e-01,  1.4480e-01,  1.7789e-01, -8.1475e-02, -9.8075e-02,\n",
       "         -3.3553e-01, -3.5899e-02,  2.1600e-01, -4.4190e-02, -2.2771e-01,\n",
       "         -1.4888e-01, -1.1615e-01, -7.3532e-02,  1.7027e-01, -8.0448e-02,\n",
       "         -4.8542e-02,  1.3358e-01, -5.0248e-02,  3.0909e-02, -8.0636e-02,\n",
       "         -1.9960e-01,  8.3121e-02,  4.9561e-02,  1.6891e-02,  1.8914e-01,\n",
       "          8.8368e-02,  3.7460e-02,  2.6739e-01, -3.6397e-01,  2.3517e-01,\n",
       "          7.4959e-02, -2.7074e-01,  5.7984e-03,  1.1616e-01,  2.1675e-01,\n",
       "          9.4691e-02, -1.7858e-01,  1.8841e-02,  5.7707e-02, -2.3046e-01,\n",
       "         -2.1651e-01,  1.6728e-01,  5.6821e-02, -4.3570e-03,  1.8563e-01,\n",
       "         -1.2347e-01, -2.0881e-01, -2.6519e-02, -1.1928e-01,  7.6651e-02,\n",
       "         -5.5909e-02, -1.2451e-01,  7.4905e-02,  1.4355e-01,  4.3760e-02,\n",
       "          1.6176e-01, -1.1021e-02,  3.7157e-02, -1.8846e-01, -3.2576e-02,\n",
       "          1.4594e-02, -1.4194e-01,  9.1396e-02,  1.2620e-01, -4.4513e-02,\n",
       "          1.7710e-01,  2.3532e-01,  1.7242e-02,  2.0661e-01, -6.2844e-02,\n",
       "          2.1202e-01, -2.4535e-02,  4.0461e-02,  8.5745e-02, -1.0658e-01,\n",
       "         -1.4577e-01, -3.1807e-01,  2.1208e-01, -3.9676e-01,  1.2713e-01,\n",
       "         -1.1961e-01, -3.4495e-02, -2.5649e-02, -2.2349e-01,  1.1954e-02,\n",
       "          1.8794e-01,  5.9299e-02,  1.7557e-01,  2.6595e-01,  1.4382e-02,\n",
       "         -1.0218e-01, -2.3324e-01,  1.6957e-02, -1.3656e-01, -6.9694e-02,\n",
       "          1.5693e-01, -1.9457e-01,  9.7073e-02,  3.1999e-01, -1.3212e-01,\n",
       "          3.9717e-01, -3.1251e-01,  1.7832e-02, -2.6815e-01, -1.5271e-01,\n",
       "          7.1385e-02, -2.3031e-01, -3.4125e-02,  1.8851e-02, -8.2821e-02,\n",
       "         -1.5260e-01,  1.9965e-01,  1.2975e-01,  2.2652e-01,  1.9037e-01,\n",
       "          2.1690e-01, -1.8120e-02,  6.0282e-02,  3.0780e-01,  2.4012e-01,\n",
       "          2.1014e-01,  3.2939e-02,  1.5336e-01, -1.5447e-01, -2.3596e-02,\n",
       "          7.2954e-02, -1.9821e-01, -9.8542e-03,  2.0979e-02, -1.7161e-01,\n",
       "         -1.3641e-01,  1.0952e-01,  4.9994e-02,  2.3072e-01,  6.5794e-02,\n",
       "         -1.1446e-01, -2.0905e-02, -1.7376e-01,  6.4763e-03,  8.2671e-02,\n",
       "          6.4243e-02, -1.1624e-01, -7.7151e-02,  2.4496e-01, -9.1615e-02,\n",
       "          2.5655e-02,  1.3722e-01, -1.3444e-01, -1.5758e-01,  1.1262e-01,\n",
       "         -2.6040e-02, -1.6997e-01,  2.1223e-01, -2.6888e-02,  1.2284e-01],\n",
       "        [ 1.2855e-01,  3.7856e-01,  1.6968e-01, -4.9242e-03,  9.3669e-02,\n",
       "         -2.0163e-02,  1.3119e-01, -1.1813e-01, -2.2554e-01,  5.5673e-02,\n",
       "          1.7199e-01, -5.0758e-02,  4.3131e-02,  1.6105e-01,  1.5248e-02,\n",
       "         -2.1348e-01, -8.4213e-02, -1.9900e-01,  1.6644e-01, -9.7853e-02,\n",
       "         -2.2416e-01, -1.1228e-01,  2.1295e-01, -7.2266e-02,  1.9776e-02,\n",
       "          1.0302e-01,  7.0523e-02,  1.4069e-01, -1.0068e-02,  3.5425e-02,\n",
       "          4.0565e-01, -5.6812e-02, -1.1077e-01, -3.5201e-03,  5.3441e-02,\n",
       "         -2.6432e-01,  1.9059e-01, -2.2143e-02, -1.4358e-02,  8.6808e-02,\n",
       "         -1.0492e-01,  1.0350e-01, -1.6441e-02, -1.7361e-02, -1.7376e-01,\n",
       "          5.1482e-02,  1.3828e-01,  1.0411e-01, -8.3336e-02,  2.5258e-01,\n",
       "          7.1514e-03, -1.7090e-01, -1.1505e-01,  1.1976e-01, -2.5581e-01,\n",
       "         -1.1126e-01, -1.3049e-01, -7.1882e-03, -1.0718e-01, -8.5662e-02,\n",
       "          5.4344e-02, -1.0252e-01,  3.4310e-02,  1.6391e-01, -8.6913e-02,\n",
       "          6.1373e-02,  1.6454e-01,  2.9210e-01,  8.3177e-02,  1.2030e-01,\n",
       "          6.7276e-03, -1.3867e-01,  4.5380e-03, -1.7709e-01,  1.2207e-01,\n",
       "          2.4052e-01,  1.9245e-02,  9.3417e-03, -3.8656e-01, -5.3497e-02,\n",
       "         -1.2406e-02,  7.7348e-02,  9.1826e-02, -1.6456e-01, -1.2095e-01,\n",
       "          1.3259e-01,  3.1538e-02, -2.0981e-01, -1.1700e-01,  1.8043e-01,\n",
       "          1.8011e-01, -2.4368e-02,  1.7264e-01, -7.4162e-03, -2.4661e-02,\n",
       "          5.4164e-02,  4.0171e-02, -5.0443e-02,  9.9718e-02, -6.9472e-02,\n",
       "          3.1992e-01, -2.4966e-01,  2.3863e-01, -1.2820e-01, -1.2748e-01,\n",
       "          6.3323e-02,  2.8212e-03, -2.5079e-01, -2.8124e-01,  2.1727e-01,\n",
       "          1.4609e-02, -4.0350e-02,  1.3306e-01,  5.2347e-02, -9.4822e-03,\n",
       "          1.3774e-01,  1.5741e-01,  4.4730e-02, -1.8813e-01,  6.0936e-02,\n",
       "          9.0512e-02, -1.0770e-01, -2.1215e-01,  2.8533e-01,  1.0802e-02,\n",
       "          2.6035e-01, -2.2881e-01, -3.3148e-02, -2.4642e-02, -1.7161e-01,\n",
       "         -2.3885e-01,  6.9297e-02, -6.9183e-02,  3.4352e-02,  1.5601e-01,\n",
       "          1.8131e-01,  1.6187e-01,  6.8449e-02,  1.3748e-01,  1.1967e-01,\n",
       "         -6.1841e-02, -1.9117e-01, -2.1375e-01,  1.1844e-01,  2.9310e-02,\n",
       "         -2.4880e-02,  2.9039e-01, -1.2506e-02,  5.3687e-02,  6.7789e-02,\n",
       "          1.7031e-01,  2.3673e-01, -3.6638e-02, -1.0977e-01, -2.5296e-01,\n",
       "          5.5779e-02,  1.8966e-02, -4.4457e-02, -9.7784e-02,  2.1870e-01,\n",
       "          1.4189e-01, -4.0925e-02, -1.6832e-01,  4.2457e-02,  5.3053e-02,\n",
       "          8.3877e-02, -5.3470e-02, -7.1126e-02, -2.8185e-02,  2.6126e-01,\n",
       "          3.3539e-01,  2.1711e-01,  3.0261e-01, -2.7439e-02, -8.2155e-02,\n",
       "          1.9958e-02,  1.7703e-01,  1.4849e-01,  1.9232e-01,  3.9989e-01,\n",
       "          1.0024e-02, -1.8258e-02,  9.5963e-02,  5.2839e-02,  8.2348e-02,\n",
       "         -1.4242e-01,  1.2602e-01,  2.7363e-02, -2.7485e-02,  5.7575e-02,\n",
       "         -9.9436e-02,  1.9932e-01, -2.1531e-01,  1.5654e-01,  7.6685e-02,\n",
       "          8.4071e-02,  1.6448e-01, -2.6783e-01,  1.0046e-02,  2.0110e-01,\n",
       "         -1.4993e-01,  9.6235e-03, -2.9115e-02, -5.0047e-02,  2.8399e-01,\n",
       "          1.3811e-01, -3.8640e-01,  4.0967e-02, -2.5534e-01, -1.7826e-01,\n",
       "          2.5691e-01, -8.2208e-02,  6.2447e-02,  9.7082e-02, -4.1922e-02,\n",
       "         -3.5114e-01, -6.7012e-02,  6.5330e-02, -2.1743e-01, -2.1410e-01,\n",
       "         -5.4500e-02, -1.2255e-01, -1.2789e-01, -1.8444e-01,  1.3706e-02,\n",
       "          3.1655e-02,  1.0663e-01, -7.7987e-03,  7.9034e-02,  1.2188e-03,\n",
       "          3.4012e-02,  2.6323e-01, -1.7960e-01, -4.8421e-02, -1.1645e-01,\n",
       "          3.8535e-01,  4.8200e-02,  2.6940e-01, -8.5443e-02,  2.2581e-02,\n",
       "          1.8374e-01, -2.1095e-01, -7.4659e-02, -4.5311e-02,  1.5659e-02,\n",
       "          7.7481e-02, -1.2754e-01, -1.6151e-01,  2.8657e-01, -2.2722e-01,\n",
       "         -1.5500e-02,  1.2108e-01,  8.6902e-02,  5.1388e-02, -2.8632e-02,\n",
       "         -1.7750e-01,  5.1956e-02, -1.5860e-01,  1.9177e-01, -6.0641e-02,\n",
       "          1.3843e-01, -2.8962e-02, -3.1920e-02, -1.3608e-01, -2.7626e-02,\n",
       "         -2.5975e-01,  7.3693e-02,  1.1538e-01, -1.5513e-01,  1.6953e-01,\n",
       "          3.4929e-01, -2.2517e-01,  7.4750e-02, -3.4177e-01,  8.4521e-02,\n",
       "         -1.2492e-01,  3.1610e-01,  3.3615e-01,  1.4169e-01,  1.9926e-01,\n",
       "         -1.3074e-01, -2.7818e-01,  2.3814e-01,  1.1691e-01, -5.4743e-02,\n",
       "         -1.7726e-01,  1.6225e-01,  2.5836e-01, -1.7309e-01,  6.8821e-02,\n",
       "         -1.8214e-01,  1.6010e-01, -1.5770e-01, -4.6388e-02,  1.4411e-01,\n",
       "         -9.1050e-02,  1.6980e-01,  6.5870e-02, -3.8889e-01, -2.1871e-01,\n",
       "          2.0929e-01, -1.0492e-01,  4.5181e-01,  2.3725e-02,  1.6716e-01,\n",
       "         -1.3177e-02,  1.1727e-02, -1.5411e-01,  4.4098e-02, -2.0139e-01,\n",
       "         -3.8675e-02,  1.4302e-01,  2.1683e-01,  2.4943e-01,  4.7281e-02,\n",
       "         -2.4012e-02, -2.9235e-02,  1.4434e-01,  1.1932e-01,  4.2442e-02,\n",
       "         -3.7196e-02, -2.6725e-01, -3.1859e-02, -8.3886e-02,  1.1653e-01,\n",
       "         -1.6495e-01,  1.6657e-01,  1.6281e-01, -5.1608e-02, -1.1082e-01,\n",
       "         -2.9892e-01, -7.1907e-02,  2.2033e-01, -5.4805e-02, -1.6682e-01,\n",
       "         -1.0709e-01, -7.0636e-02, -8.3715e-02,  1.3408e-01, -9.8429e-02,\n",
       "         -6.3584e-02,  1.6090e-01, -4.2540e-02,  4.7166e-02, -5.9300e-02,\n",
       "         -2.2927e-01,  8.2182e-02,  3.9851e-02,  5.8429e-02,  1.6291e-01,\n",
       "          2.3948e-02,  7.1260e-04,  2.6365e-01, -3.3665e-01,  2.3911e-01,\n",
       "          8.2106e-02, -2.4100e-01, -2.1145e-02,  1.4572e-01,  2.5432e-01,\n",
       "          6.6752e-02, -1.2579e-01,  3.1899e-02,  8.5859e-02, -2.0862e-01,\n",
       "         -2.2319e-01,  1.9531e-01,  3.5742e-02,  4.2246e-02,  1.8580e-01,\n",
       "         -1.3200e-01, -2.5091e-01,  2.0684e-03, -8.3242e-02,  7.7144e-02,\n",
       "         -2.3194e-02, -1.7382e-01,  8.4235e-02,  1.4386e-01, -1.0840e-03,\n",
       "          8.7821e-02,  1.8446e-02,  4.0151e-02, -1.9379e-01, -2.3463e-02,\n",
       "          4.3304e-02, -1.3941e-01,  6.4898e-02,  1.4869e-01,  4.5098e-03,\n",
       "          1.9898e-01,  2.4708e-01, -2.7699e-02,  2.5851e-01, -8.7523e-02,\n",
       "          1.8523e-01,  5.5405e-03,  5.8319e-02,  7.7541e-02, -1.4364e-01,\n",
       "         -9.3867e-02, -3.0941e-01,  2.2294e-01, -4.2004e-01,  1.1184e-01,\n",
       "         -1.4388e-01, -2.6934e-02, -5.0237e-02, -2.5658e-01,  2.2050e-05,\n",
       "          1.6264e-01,  1.8691e-02,  2.1044e-01,  2.3265e-01, -1.9259e-02,\n",
       "         -1.2243e-01, -1.9917e-01, -1.0773e-02, -1.6126e-01, -1.0751e-01,\n",
       "          1.6003e-01, -1.9318e-01,  8.1970e-02,  2.6479e-01, -1.2131e-01,\n",
       "          3.7155e-01, -3.1984e-01,  8.7752e-04, -2.8382e-01, -1.4673e-01,\n",
       "          1.0794e-01, -1.9018e-01, -2.5022e-02, -5.6388e-04, -8.3051e-02,\n",
       "         -1.6624e-01,  2.1700e-01,  1.2496e-01,  2.6226e-01,  1.5169e-01,\n",
       "          2.1496e-01, -1.5912e-02,  5.3385e-02,  3.4254e-01,  2.3121e-01,\n",
       "          1.8583e-01,  5.3619e-02,  1.5698e-01, -1.8670e-01, -7.9988e-02,\n",
       "          3.8536e-02, -2.1338e-01, -1.7865e-02,  2.3943e-02, -1.9102e-01,\n",
       "         -1.5155e-01,  9.2455e-02,  1.5627e-02,  2.3801e-01,  7.0525e-02,\n",
       "         -1.1365e-01, -5.4092e-02, -1.5273e-01, -2.6836e-02,  1.2060e-01,\n",
       "          3.2212e-02, -1.5313e-01, -5.3463e-02,  2.5925e-01, -1.3948e-01,\n",
       "          3.4421e-03,  1.4634e-01, -1.3157e-01, -1.1767e-01,  9.3827e-02,\n",
       "         -3.5037e-02, -2.0949e-01,  2.6164e-01, -6.7332e-02,  1.2579e-01]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample\n",
    "batch = tokenizer([seq[:10], seq[10:30]], return_tensors=\"pt\", padding=\"longest\")\n",
    "outputs = llm(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 22, 480]), torch.Size([2, 480]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state, pool = outputs.last_hidden_state, outputs.pooler_output\n",
    "last_hidden_state.shape, pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 480])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean pooling of last_hidden_state\n",
    "\n",
    "# first expand the mask\n",
    "mask = batch[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.shape).float()\n",
    "\n",
    "# sum unmasked token embeddings\n",
    "sum_embeddings = torch.sum(last_hidden_state * mask, dim=1)\n",
    "\n",
    "# number of unmasked tokens for each sequence\n",
    "# set a min value to avoid divide by zero\n",
    "num_tokens = torch.clamp(mask.sum(1), min=1e-9)\n",
    "\n",
    "# divide\n",
    "mean_embeddings = sum_embeddings / num_tokens\n",
    "mean_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"distilbert-base-uncased\", num_labels=2\n",
    "# )\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetunedESM(nn.Module):\n",
    "    def __init__(self, llm, dropout_p, embedding_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.llm = llm\n",
    "        self.dropout_p = dropout_p\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.pre_classifier = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def mean_pooling(self, token_embeddings, attention_mask):\n",
    "        \"\"\"Average the embedding of all amino acids in a sequence\"\"\"\n",
    "\n",
    "        # expand the mask\n",
    "        expanded_mask = (\n",
    "            attention_mask.unsqueeze(-1).expand(token_embeddings.shape).float()\n",
    "        )\n",
    "\n",
    "        # sum unmasked token embeddings\n",
    "        sum_embeddings = torch.sum(token_embeddings * expanded_mask, dim=1)\n",
    "\n",
    "        # number of unmasked tokens for each sequence\n",
    "        # set a min value to avoid divide by zero\n",
    "        num_tokens = torch.clamp(expanded_mask.sum(1), min=1e-9)\n",
    "\n",
    "        # divide\n",
    "        mean_embeddings = sum_embeddings / num_tokens\n",
    "        return mean_embeddings\n",
    "\n",
    "    def forward(self, batch):\n",
    "        input_ids, attention_mask = batch[\"input_ids\"], batch[\"attention_mask\"]\n",
    "\n",
    "        # per token representations from the last layer\n",
    "        token_embeddings = self.llm(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).last_hidden_state\n",
    "\n",
    "        # average per token representations\n",
    "        mean_embeddings = self.mean_pooling(token_embeddings, attention_mask)\n",
    "\n",
    "        # https://github.com/huggingface/transformers/blob/main/src/transformers/models/distilbert/modeling_distilbert.py\n",
    "        mean_embeddings = self.pre_classifier(mean_embeddings)  # (bs, embedding_dim)\n",
    "        mean_embeddings = nn.ReLU()(mean_embeddings)\n",
    "        mean_embeddings = self.dropout(mean_embeddings)\n",
    "\n",
    "        logits = self.classifier(mean_embeddings)  # (bs, num_classes)\n",
    "        return logits\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def predict(self, batch):\n",
    "        self.eval()\n",
    "        y = self(batch)\n",
    "        return y.cpu().numpy()\n",
    "\n",
    "    def save(self, dp):\n",
    "        with open(Path(dp, \"args.json\"), \"w\") as fp:\n",
    "            contents = {\n",
    "                \"dropout_p\": self.dropout_p,\n",
    "                \"embedding_dim\": self.embedding_dim,\n",
    "                \"num_classes\": self.num_classes,\n",
    "            }\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "        torch.save(self.state_dict(), Path(dp) / \"model.pt\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, esm_model, args_fp, state_dict_fp):\n",
    "        with open(args_fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "\n",
    "        llm = EsmModel.from_pretrained(esm_model)\n",
    "        model = cls(llm=llm, **kwargs)\n",
    "        model.load_state_dict(\n",
    "            torch.load(state_dict_fp, map_location=torch.device(\"cpu\"))\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of FinetunedESM(\n",
      "  (llm): EsmModel(\n",
      "    (embeddings): EsmEmbeddings(\n",
      "      (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (position_embeddings): Embedding(1026, 480, padding_idx=1)\n",
      "    )\n",
      "    (encoder): EsmEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x EsmLayer(\n",
      "          (attention): EsmAttention(\n",
      "            (self): EsmSelfAttention(\n",
      "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
      "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
      "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "              (rotary_embeddings): RotaryEmbedding()\n",
      "            )\n",
      "            (output): EsmSelfOutput(\n",
      "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "          (intermediate): EsmIntermediate(\n",
      "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
      "          )\n",
      "          (output): EsmOutput(\n",
      "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (pooler): EsmPooler(\n",
      "      (dense): Linear(in_features=480, out_features=480, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "    (contact_head): EsmContactPredictionHead(\n",
      "      (regression): Linear(in_features=240, out_features=1, bias=True)\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (pre_classifier): Linear(in_features=480, out_features=480, bias=True)\n",
      "  (classifier): Linear(in_features=480, out_features=500, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model = FinetunedESM(\n",
    "    llm=llm, dropout_p=0.1, embedding_dim=embedding_dim, num_classes=500\n",
    ")\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.train.torch import get_device\n",
    "\n",
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(arr, dtype=np.int32):\n",
    "    max_len = max(len(row) for row in arr)\n",
    "    padded_arr = np.zeros((arr.shape[0], max_len), dtype=dtype)\n",
    "    for i, row in enumerate(arr):\n",
    "        padded_arr[i][: len(row)] = row\n",
    "    return padded_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch[\"input_ids\"] = pad_array(batch[\"input_ids\"])\n",
    "    batch[\"attention_mask\"] = pad_array(batch[\"attention_mask\"])\n",
    "    dtypes = {\n",
    "        \"input_ids\": torch.int32,\n",
    "        \"attention_mask\": torch.int32,\n",
    "        \"targets\": torch.float,\n",
    "    }\n",
    "    tensor_batch = {}\n",
    "    for key, array in batch.items():\n",
    "        tensor_batch[key] = torch.as_tensor(\n",
    "            array.copy(), dtype=dtypes[key], device=get_device()\n",
    "        )\n",
    "    return tensor_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:15:50,865\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)] -> LimitOperator[limit=8]\n",
      "2024-02-13 11:15:50,865\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-13 11:15:50,866\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d8cf5ff03a4ece8f26498dd6973375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([array([ 0, 20,  7,  8, 21, 15, 15, 17, 13, 10, 14, 10, 14,  4, 22, 12,  4,\n",
       "               15, 12, 21, 15, 10,  4,  8,  4, 18,  9, 18, 15, 10, 19,  5, 11,  6,\n",
       "               12,  6, 15, 13, 13,  6, 16, 13, 12,  8, 22,  7,  4, 15,  6, 17,  5,\n",
       "               15, 17, 17,  7, 19, 16,  7, 11,  7,  9, 11, 20,  9, 17, 23,  9, 11,\n",
       "               13,  9, 23, 15, 15,  7, 12, 22,  7, 14, 13,  9,  4,  5,  9,  8, 11,\n",
       "                6, 11, 20, 18,  9, 13, 18, 15,  9, 13, 16, 14, 16,  9,  8,  7,  8,\n",
       "                8, 12,  8, 17, 17,  9,  5, 17, 22,  6,  8,  8,  7, 17,  9,  4, 13,\n",
       "                9, 17, 19,  9, 15, 20, 16, 15,  9,  9, 11, 18, 13, 14, 19, 13,  8,\n",
       "               13,  8, 13, 11,  8,  9, 13,  8, 13, 18, 13,  9, 13, 18,  9, 13,  8,\n",
       "               13, 15, 11, 20, 23,  8,  6, 16,  8,  2])                           ,\n",
       "        array([ 0, 20,  5, 11, 19,  8,  4,  5, 17,  9, 10,  4, 10,  5,  4,  9, 13,\n",
       "               12,  9, 10,  9, 12,  6,  5, 12,  4, 16, 17,  5,  6, 11,  5, 12,  4,\n",
       "                9,  4,  8, 15,  9, 15, 11, 17,  9, 10,  4,  4, 13, 10, 16,  5,  5,\n",
       "                5, 18, 11,  5,  8,  7, 16, 21,  7,  9,  5,  9,  4,  8,  5, 16, 12,\n",
       "               10, 19,  4, 11, 16,  7,  5, 11,  6, 16, 14, 21,  9,  6,  8,  8, 19,\n",
       "                8,  8, 10, 15, 13, 23, 16, 20,  5,  4, 15, 10,  7, 13, 19,  5, 10,\n",
       "                4, 15, 12,  8, 13,  7,  5, 10, 11, 23,  9, 16, 20,  4,  9, 17,  2]),\n",
       "        array([ 0, 20, 16, ...,  9,  8,  2]),\n",
       "        array([ 0, 20, 12, 10,  4,  6, 16, 17,  4, 10,  8, 12,  8, 15,  7, 15,  4,\n",
       "               16,  8, 18, 17, 17, 19, 15, 19,  8,  8,  8, 17, 17, 17, 17, 17, 17,\n",
       "               17, 17, 12, 17,  8, 17, 12, 17, 17, 12, 15, 12, 17,  9, 19,  8, 17,\n",
       "                4, 10, 15, 12, 12,  9, 13,  6, 16,  9, 17,  8, 17, 10,  4, 13, 15,\n",
       "                4, 15,  9,  4, 18, 14, 13, 15,  9, 13,  4,  8,  8, 14,  4,  9, 19,\n",
       "                4, 13,  8,  9, 16, 10,  4, 17,  9, 11, 15, 16, 15,  4, 12, 13,  4,\n",
       "                9, 15,  8, 18,  7,  9, 13,  4,  5, 15,  4, 17, 15,  5, 10,  7,  7,\n",
       "                5, 16,  8, 19,  4,  4, 13,  6,  9, 13,  6, 12,  9, 17, 13, 11, 13,\n",
       "               22, 15,  8, 13,  7, 15,  9, 12,  8, 13, 13,  9, 15, 17,  4, 10, 15,\n",
       "               12, 16, 11,  4,  4,  9, 18,  9,  5, 12, 13, 13,  5,  7, 11, 10, 19,\n",
       "               10, 13,  4, 20,  4, 13,  8, 15,  6, 15,  8, 18,  7, 11,  8, 18, 15,\n",
       "                8, 12, 10, 13,  7,  4, 20, 16, 22, 17,  9,  6,  4, 11,  9, 15,  7,\n",
       "               16, 15, 13,  4,  5, 11, 15, 13, 16, 13,  5,  5, 22,  7, 11, 12,  4,\n",
       "               15, 11,  7,  8,  7, 16, 15, 23, 12,  4, 15,  8,  4, 17, 12, 12,  7,\n",
       "                6, 15,  8,  7,  4, 15, 13, 10, 19, 13, 18,  5, 11, 17, 12, 12, 12,\n",
       "                9, 11, 12,  6,  7,  8,  7, 19,  5,  9, 19, 15,  8,  4, 12,  7, 15,\n",
       "               15, 15,  9, 14, 15, 11, 19, 15, 15, 12,  8, 15,  4, 12, 14, 17,  8,\n",
       "                5,  4, 15, 15, 18, 19, 17,  4,  8, 11, 13, 17,  4, 13,  7, 12,  7,\n",
       "                4, 14, 14,  9,  8, 15, 13, 12, 18,  8, 12,  6,  9, 18,  4,  7,  8,\n",
       "               16,  7, 18, 15, 21, 23, 11, 12, 16,  9,  8,  4,  6,  9, 13,  6,  8,\n",
       "               15, 16,  8, 14,  5, 18, 11, 12, 16,  8, 21, 19,  5, 17,  6,  7, 10,\n",
       "               11, 11, 15,  7, 12, 14, 21, 15, 17, 12, 18, 15,  4, 12,  9,  5,  6,\n",
       "               21,  9, 12, 10,  9, 11,  6,  6,  5, 10,  4, 18, 14, 20,  7, 12, 15,\n",
       "               14,  4, 14, 22, 12, 11, 14, 11,  9,  6, 14, 19,  4, 21, 19, 15,  7,\n",
       "               14, 12, 20, 10, 11, 17,  6,  8,  5, 20, 16,  4, 10, 11,  4,  7, 13,\n",
       "                8, 13, 20,  8,  4, 12, 19, 10,  5,  4, 17, 12,  4,  6,  9, 11, 14,\n",
       "               22,  7, 12, 17, 10, 13,  4, 19, 17,  7, 12,  4,  9,  5, 22,  5, 17,\n",
       "                6,  6, 17, 12,  6, 13, 12, 14, 15, 10, 11, 13, 18,  9, 19, 14,  9,\n",
       "               12,  8, 13, 13, 20,  4, 18, 13, 21,  9,  5, 10, 15,  9,  4, 19, 15,\n",
       "               15,  9, 16, 10, 12, 15,  8,  4, 17, 18, 17,  4, 21,  8,  4, 10, 23,\n",
       "               13, 11, 17, 19, 15,  4,  9,  7,  5, 10, 15, 18,  4, 13, 21, 11,  4,\n",
       "               19, 18, 14, 21, 17, 12, 13, 18, 10,  6, 10,  8, 19, 14, 12, 14, 14,\n",
       "               21,  4, 17, 21,  4,  6,  8, 13, 18, 23, 10,  8,  4,  4, 15, 18,  9,\n",
       "               15,  8,  4, 14,  4,  6,  9, 15,  6,  4,  9, 22,  4, 15, 12, 21,  7,\n",
       "                5, 17,  4, 19,  6,  7, 13, 15, 12, 14,  4, 17,  9, 10,  4,  5, 18,\n",
       "               11,  9, 10, 17, 20,  9, 17, 12, 18, 13,  8,  7, 13,  8, 14,  4, 17,\n",
       "                6, 17, 15, 22, 22,  4, 15,  5, 13, 17, 14, 22, 16, 11,  4,  5,  5,\n",
       "               23, 20,  9,  4, 11, 15,  5, 12, 10,  8,  6, 15, 14,  5,  9, 18,  4,\n",
       "                8, 17,  4, 14, 12, 21, 16, 13,  6, 11, 23, 17,  6,  4, 16, 21, 19,\n",
       "                5,  5,  4,  6,  6, 13,  7, 22,  6,  5,  9, 15,  7, 17,  4,  4, 14,\n",
       "                8, 13, 23, 14, 16, 13,  7, 19,  8,  8,  7,  5, 16,  4,  7,  9, 16,\n",
       "               12,  7,  9,  9, 13,  5, 15, 17,  6, 13,  9, 12,  5, 16, 18, 18,  4,\n",
       "                6, 15,  7, 13, 10, 15,  4,  7, 15, 16, 11,  7, 20, 11,  8,  7, 19,\n",
       "                6,  7, 11, 19, 12,  6,  5, 10,  9, 16, 12,  9, 17,  5, 12,  4,  9,\n",
       "               15, 18,  8, 13,  4, 13,  4, 13,  9, 13, 18, 12, 18, 15,  8,  8, 11,\n",
       "               19, 12, 11, 15, 17, 11, 18,  5,  8,  4, 17, 17, 20, 18,  7,  6,  5,\n",
       "               10,  8, 12, 20, 15, 22, 20,  8, 13, 23,  5, 11,  4, 12,  5, 15,  8,\n",
       "                6, 21, 23,  7, 11, 22, 17, 11, 14,  4,  6,  4, 14,  7,  7, 16, 14,\n",
       "               19, 15, 15,  6,  6, 15, 19, 17, 12, 10, 11,  4,  9, 23, 13, 18, 12,\n",
       "                7,  7, 21, 17, 13, 13,  4,  4, 16,  7, 13,  8, 17, 10, 16, 10,  8,\n",
       "                5, 18, 14, 14, 17, 18, 12, 21,  8,  4, 13,  8, 11, 21, 20, 18,  4,\n",
       "               11,  5, 20, 11, 23, 19, 13, 16,  6, 12, 11, 19,  8,  8,  7, 21, 13,\n",
       "                8, 19, 22, 11, 21,  5,  8, 11,  7, 13, 10, 20, 17, 13, 12,  4, 10,\n",
       "               17,  9, 18,  7,  9,  4, 21, 15, 16, 14, 12,  4,  9, 10,  4,  4,  9,\n",
       "               22, 18, 16,  7, 10, 19, 14, 13, 12, 15, 18, 14, 15,  4, 14, 15, 15,\n",
       "                6,  9,  4, 13, 12, 17, 15,  7, 15,  9,  8, 10, 19, 18, 18, 21,  2]),\n",
       "        array([ 0, 20, 15, 16, 17, 14, 18,  7,  8,  8,  8, 10, 10, 15, 17, 10, 15,\n",
       "               10, 21, 18, 16,  5, 14,  8, 21, 12, 10, 10, 10,  4, 20,  8,  5, 14,\n",
       "                4,  8, 15,  9,  4, 10, 16, 15, 19, 17,  7, 10,  8, 20, 14, 12, 10,\n",
       "               10, 13, 13,  9,  7, 16,  7, 12, 10,  6, 21, 18, 15,  6, 17, 16,  7,\n",
       "                6, 15,  7,  7, 16,  5, 19, 10, 15, 15, 18,  7,  7, 19,  7,  9, 15,\n",
       "               12, 16, 10,  9, 17,  5, 17,  6, 11, 17,  7, 19,  7,  6, 12, 21, 14,\n",
       "                8, 15,  7,  4, 12,  7, 15,  4, 15,  4, 13, 15, 13, 10, 15,  5, 12,\n",
       "                4,  9, 10, 10,  6, 15,  6, 10,  4,  5,  5,  4,  6, 15, 13, 15,  6,\n",
       "               15, 19, 11,  9,  9, 11,  5,  5, 16, 14, 20,  9, 11,  5,  2])       ,\n",
       "        array([ 0, 20,  5,  8,  6, 16, 18,  7, 17, 15,  4, 16,  9,  9,  7, 12, 23,\n",
       "               14, 12, 23,  4, 13, 12,  4, 16, 15, 14,  7, 11, 12, 13, 23,  6, 21,\n",
       "               17, 18, 23,  4, 15, 23, 12, 11, 16, 12,  6,  9, 11,  8, 23,  6, 18,\n",
       "               18, 15, 23, 14,  4, 23, 15, 11,  8,  7, 10, 15, 17,  5, 12, 10, 18,\n",
       "               17,  8,  4,  4, 10, 17,  4,  7,  9, 15, 12, 16,  5,  4, 16,  5,  8,\n",
       "                9,  7, 16,  8, 15, 10, 15,  9,  5, 11, 23, 14, 10, 21, 16,  9, 20,\n",
       "               18, 21, 19, 18, 23,  9, 13, 13,  6, 15, 18,  4, 23, 18,  7, 23, 10,\n",
       "                9,  8, 15, 13, 21, 15,  8, 21, 17,  7,  8,  4, 12,  9,  9,  5,  5,\n",
       "               16, 17, 19, 16,  6, 16, 12, 16,  9, 16, 12, 16,  7,  4, 16, 16, 15,\n",
       "                9, 15,  9, 11,  7, 16,  7, 15,  5, 16,  6,  7, 21, 10,  7, 13,  7,\n",
       "               18, 11, 13, 16,  7,  9, 21,  9, 15, 16, 10, 12,  4, 11,  9, 18,  9,\n",
       "                4,  4, 21, 16,  7,  4,  9,  9,  9, 15, 17, 18,  4,  4,  8, 10, 12,\n",
       "               19, 22,  4,  6, 21,  9,  6, 11,  9,  5,  6, 15, 21, 19,  7,  5,  8,\n",
       "               11,  9, 14, 16,  4, 17, 13,  4, 15, 15,  4,  7, 13,  8,  4, 15, 11,\n",
       "               15, 16, 17, 20, 14, 14, 10, 16,  4,  4,  9, 13, 12, 15,  7,  7,  4,\n",
       "               23, 10,  8,  9,  9, 18, 16, 18,  4, 17, 14, 11, 14,  7, 14,  4,  9,\n",
       "                4,  9, 15, 15,  4,  8,  9,  5, 15,  8, 10, 21, 13,  8, 12, 11,  6,\n",
       "                8,  4, 15, 15, 18, 15, 13, 16,  4, 16,  5, 13, 10, 15, 15, 13,  9,\n",
       "               17, 10, 18, 18, 15,  8, 20, 17, 15, 17, 13, 20, 15,  8, 22,  6,  4,\n",
       "                4, 16, 15, 17, 17, 21, 15, 20, 17, 15, 11,  8,  9, 14,  6,  8,  8,\n",
       "                8,  5,  6,  6, 10, 11, 11,  8,  6, 14, 14, 17, 21, 21,  8,  8,  5,\n",
       "               14,  8, 21,  8,  4, 18, 10,  5,  8,  8,  5,  6, 15,  7, 11, 18, 14,\n",
       "                7, 23,  4,  4,  5,  8, 19, 13,  9, 12,  8,  6, 16,  6,  5,  8,  8,\n",
       "               16, 13, 11, 15, 11, 18, 13,  7,  5,  4,  8,  9,  9,  4, 21,  5,  5,\n",
       "                4,  8,  9, 22,  4, 11,  5, 12, 10,  5, 22, 18, 23,  9,  7, 14,  8,\n",
       "                8,  2])                                                           ,\n",
       "        array([ 0, 20, 17, ...,  7, 18,  2]),\n",
       "        array([ 0, 20,  8,  4,  4, 21,  8, 13,  8,  8, 23,  6,  6, 10, 13,  4, 13,\n",
       "                8,  6, 23, 23, 11,  5, 20,  5,  8,  5, 23,  8,  6,  6,  5, 15,  9,\n",
       "               13,  8,  7,  8,  7,  6,  8,  6, 11,  6, 17, 14, 14,  8,  8, 18, 11,\n",
       "                9,  9, 11, 16,  6, 19, 13,  7,  9, 18, 13, 14, 14,  4,  9,  8, 15,\n",
       "               19,  9, 23, 14, 12, 23,  4, 20,  5,  4, 10,  9,  5,  7, 16, 11, 14,\n",
       "               23,  6, 21, 10, 18, 23, 15,  6, 23, 12,  7, 15,  8, 12, 10, 13,  5,\n",
       "                6, 21, 15, 23, 14,  7, 13, 17,  9, 12,  4,  4,  9, 17, 16,  4, 18,\n",
       "               14, 13, 17, 18,  5, 15, 10,  9, 12,  4,  8,  4, 11,  7, 15, 23, 14,\n",
       "               17, 15,  6, 23, 23,  4, 15, 20,  9,  4, 10, 21,  4,  9,  9, 21, 16,\n",
       "                4, 21, 23, 13, 18, 11, 11,  7,  9, 23, 14, 16, 23, 16,  6,  5, 18,\n",
       "               16, 15, 17, 21,  4, 15,  9, 21, 20, 11, 16,  9, 23, 14, 10, 10, 16,\n",
       "                7, 23, 23, 14, 17, 23,  5, 11,  8, 20,  5, 19,  9, 13, 15,  9,  4,\n",
       "               21, 13, 16, 11, 23, 14,  4,  5, 17,  7, 18, 23,  9, 19, 23, 17, 11,\n",
       "               20,  4, 12, 10, 16, 16, 20, 14, 17, 21, 19, 13, 17, 13, 23, 14, 11,\n",
       "                5, 14,  7, 14, 23, 18, 19,  8,  5, 18,  6, 23, 14,  9, 15, 20, 16,\n",
       "               10, 17,  9,  4,  5, 10, 21, 20, 16,  9, 18, 11, 16,  7, 21, 20, 10,\n",
       "               20, 20,  5, 16,  8, 12, 16, 17, 12,  8,  7, 11,  5, 11, 17, 14,  7,\n",
       "               14, 18, 12, 17,  6,  4, 14, 18,  9, 14,  5,  4, 18,  8, 21,  7,  8,\n",
       "               10,  5, 14, 19, 17, 23, 17, 14,  9,  7,  9, 17, 18, 15,  9, 11, 12,\n",
       "               16, 16,  4,  9,  6, 10,  4,  7, 10, 16, 13, 21, 16, 12, 10,  9,  4,\n",
       "               12,  5, 15, 20,  9, 11, 16, 17, 11, 21, 20,  5,  9,  4, 15, 10, 11,\n",
       "               12, 10, 13,  4,  9,  6, 15, 12, 11,  9, 20,  9,  5, 16, 16, 23, 17,\n",
       "                6, 12, 19, 12, 22, 15, 12,  9, 17, 18,  8,  6,  4, 16, 15,  5, 16,\n",
       "                9,  9,  9, 10, 14,  7,  7, 20, 21,  8, 14,  6, 18, 19, 11,  6, 15,\n",
       "               14,  6, 19, 15,  4, 23,  4, 10,  4, 21, 12, 16,  4, 14,  8,  5, 16,\n",
       "               10, 23,  5, 17, 18, 12,  8,  4, 18,  7, 21, 11, 20, 16,  6,  9, 19,\n",
       "               13,  8, 21,  4, 14, 22, 14, 18, 16,  6, 11, 12, 10,  4,  8, 12,  4,\n",
       "               13, 16,  8,  9,  6, 14,  9, 10, 16, 17, 21,  9,  9,  7, 20,  9,  5,\n",
       "               15, 14,  9,  4,  4,  5, 18, 16, 10, 14, 11, 12, 21, 10, 17, 14, 15,\n",
       "                6, 18,  6, 19,  7, 11, 18, 20, 21,  4, 16, 11,  4, 15, 16, 10, 11,\n",
       "               18,  7, 15, 13, 13, 11,  4,  4,  7, 10, 23,  9,  7,  4, 11, 10,  4,\n",
       "               13,  4, 17,  8,  4, 10, 10,  9,  6, 18, 16,  5, 10,  8, 11, 13,  6,\n",
       "                5,  5,  2])                                                       ],\n",
       "       dtype=object),\n",
       " 'attention_mask': array([array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1])                                      ,\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1])                                      ,\n",
       "        array([1, 1, 1, ..., 1, 1, 1]),\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1])                                               ,\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])        ,\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1])                                      ,\n",
       "        array([1, 1, 1, ..., 1, 1, 1]),\n",
       "        array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "               1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])        ],\n",
       "       dtype=object),\n",
       " 'targets': array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = sample_ds.take_batch(batch_size=8)\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 0, 20,  7,  ...,  0,  0,  0],\n",
       "         [ 0, 20,  5,  ...,  0,  0,  0],\n",
       "         [ 0, 20, 16,  ...,  9,  8,  2],\n",
       "         ...,\n",
       "         [ 0, 20,  5,  ...,  0,  0,  0],\n",
       "         [ 0, 20, 17,  ...,  0,  0,  0],\n",
       "         [ 0, 20,  8,  ...,  0,  0,  0]], device='cuda:0', dtype=torch.int32),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.int32),\n",
       " 'targets': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.]], device='cuda:0')}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = collate_fn(batch=sample_batch)\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 500])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch[\"targets\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train as train\n",
    "from ray.train import Checkpoint, CheckpointConfig, DataConfig, RunConfig, ScalingConfig\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
    "import tempfile\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel.distributed import DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 500])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(get_device())\n",
    "sample_output = model(sample_batch)\n",
    "sample_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(ds, batch_size, model, num_classes, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    ds_generator = ds.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "    for batch in ds_generator:\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(batch)\n",
    "        if num_classes == 1:\n",
    "            y_hat = y_hat.unsqueeze(1)\n",
    "        loss = loss_fn(y_hat, batch[\"targets\"])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(ds, batch_size, model, num_classes, loss_fn):\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    y_trues, y_preds = [], []\n",
    "    ds_generator = ds.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "    with torch.no_grad():\n",
    "        for batch in ds_generator:\n",
    "            y_hat = model(batch)\n",
    "            if num_classes == 1:\n",
    "                y_hat = y_hat.unsqueeze(1)\n",
    "            loss = loss_fn(y_hat, batch[\"targets\"])\n",
    "            eval_loss.append(loss.item())\n",
    "            y_trues.extend(batch[\"targets\"].cpu().numpy())\n",
    "            y_preds.extend(y_hat.cpu().numpy())\n",
    "\n",
    "    return np.mean(eval_loss), y_trues, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_per_worker(config):\n",
    "    # Hyperparameters\n",
    "    esm_model = config[\"esm_model\"]\n",
    "    dropout_p = config[\"dropout_p\"]\n",
    "    lr = config[\"lr\"]\n",
    "    lr_factor = config[\"lr_factor\"]\n",
    "    lr_patience = config[\"lr_patience\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    num_classes = config[\"num_classes\"]\n",
    "\n",
    "    set_seeds()\n",
    "    train_ds = train.get_dataset_shard(\"train\")\n",
    "    val_ds = train.get_dataset_shard(\"val\")\n",
    "\n",
    "    llm = EsmModel.from_pretrained(esm_model)\n",
    "    model = FinetunedESM(\n",
    "        llm=llm,\n",
    "        dropout_p=dropout_p,\n",
    "        embedding_dim=llm.config.hidden_size,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer=optimizer, mode=\"min\", factor=lr_factor, patience=lr_patience\n",
    "    )\n",
    "\n",
    "    num_workers = train.get_context().get_world_size()\n",
    "    batch_size_per_worker = batch_size // num_workers\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_step(\n",
    "            train_ds, batch_size_per_worker, model, num_classes, loss_fn, optimizer\n",
    "        )\n",
    "        val_loss, _, _ = eval_step(\n",
    "            val_ds, batch_size_per_worker, model, num_classes, loss_fn\n",
    "        )\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Checkpoint\n",
    "        with tempfile.TemporaryDirectory(prefix=\"ray_results\") as dp:\n",
    "            if isinstance(model, DistributedDataParallel):  # cpu\n",
    "                model.module.save(dp=dp)\n",
    "            else:\n",
    "                model.save(dp=dp)\n",
    "            metrics = dict(\n",
    "                epoch=epoch,\n",
    "                lr=optimizer.param_groups[0][\"lr\"],\n",
    "                train_loss=train_loss,\n",
    "                val_loss=val_loss,\n",
    "            )\n",
    "            checkpoint = Checkpoint.from_directory(dp)\n",
    "            train.report(metrics, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop config\n",
    "train_loop_config = {\n",
    "    \"esm_model\": model_name,\n",
    "    \"dropout_p\": 0.1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_factor\": 0.8,\n",
    "    \"lr_patience\": 3,\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 8,\n",
    "    \"num_classes\": 500,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling config\n",
    "num_workers = 1\n",
    "resources_per_worker = {\"CPU\": 16, \"GPU\": 1}\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=num_workers,\n",
    "    use_gpu=bool(resources_per_worker[\"GPU\"]),\n",
    "    resources_per_worker=resources_per_worker,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run config\n",
    "checkpoint_config = CheckpointConfig(\n",
    "    num_to_keep=1, checkpoint_score_attribute=\"val_loss\", checkpoint_score_order=\"min\"\n",
    ")\n",
    "run_config = RunConfig(\n",
    "    name=\"llm\",\n",
    "    checkpoint_config=checkpoint_config,\n",
    "    storage_path=str(Path().resolve() / \"ray_results\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6d0941872d490b80ae8fb71685392d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet Files Sample 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:15:52,852\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=89 for stage ReadParquet to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-02-13 11:15:52,852\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 89, each read task output is split into 89 smaller blocks.\n",
      "2024-02-13 11:15:52,853\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> AllToAllOperator[RandomShuffle]\n",
      "2024-02-13 11:15:52,853\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-13 11:15:52,853\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1ef92c326b4f43a39b2222eaf4079f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomShuffle 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378b64d9ff084c6dbd6ec67c42a02dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5887441b863f492f8be1186710d74729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c2f0e5d32e4ad988cf7b6910fb4858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ReadParquet->SplitBlocks(89) pid=54075)\u001b[0m /home/ytian/anaconda3/envs/ml/lib/python3.10/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by mode='default'.\n",
      "\u001b[36m(ReadParquet->SplitBlocks(89) pid=54075)\u001b[0m   return transform_pyarrow.concat(tables)\n"
     ]
    }
   ],
   "source": [
    "ds = load_data()\n",
    "test_size = 0.25\n",
    "train_ds, valid_ds = ds.train_test_split(test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:15:53,381\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "2024-02-13 11:15:53,382\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-13 11:15:53,382\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664512a1a1924a82a3258eed3162c971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:15:55,366\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "2024-02-13 11:15:55,367\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-13 11:15:55,367\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2be68680ff4ce58d385c70b8b879a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor = CustomPreprocessor()\n",
    "train_ds = preprocessor.transform(train_ds)\n",
    "val_ds = preprocessor.transform(valid_ds)\n",
    "train_ds = train_ds.materialize()\n",
    "valid_ds = val_ds.materialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ray.data.ExecutionOptions(preserve_order=True)\n",
    "dataset_config = DataConfig(datasets_to_split=[\"train\"], execution_options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config=train_loop_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    datasets={\"train\": train_ds, \"val\": val_ds},\n",
    "    dataset_config=dataset_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-02-13 14:48:58</td></tr>\n",
       "<tr><td>Running for: </td><td>03:33:02.17        </td></tr>\n",
       "<tr><td>Memory:      </td><td>18.5/31.2 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 17.0/28 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">   lr</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_50259_00000</td><td>TERMINATED</td><td>172.30.66.101:58984</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         12779.1</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">    0.162174</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(TorchTrainer pid=58984)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=58984)\u001b[0m - (ip=172.30.66.101, pid=59074) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m [W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Moving model to device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cc533e15764c62ad36dfe9f3f3038a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59156) Running 0:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b880258c9314758be6c601684dad16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59074) Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ytian/github/esm-lora/notebooks/ray_results/llm/TorchTrainer_50259_00000_0_2024-02-13_11-15-56/checkpoint_000000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d65d0a13cb747d6b8d193e21964778a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59156) Running 0:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65376942e71342b5b399567383defd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59074) Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ytian/github/esm-lora/notebooks/ray_results/llm/TorchTrainer_50259_00000_0_2024-02-13_11-15-56/checkpoint_000001)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1a27d3541d49e391ec227780deec95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59156) Running 0:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1e1a57ca924d989b7196b231201433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59074) Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ytian/github/esm-lora/notebooks/ray_results/llm/TorchTrainer_50259_00000_0_2024-02-13_11-15-56/checkpoint_000002)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9af41a46b14bada66a2282e69c794d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59156) Running 0:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33434adc41dc494c93c0593978a70c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59074) Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ytian/github/esm-lora/notebooks/ray_results/llm/TorchTrainer_50259_00000_0_2024-02-13_11-15-56/checkpoint_000003)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590da98e09964097994abfe9e534e62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59156) Running 0:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(SplitCoordinator pid=59156)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1acb90fbc2422f84518947753a2137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=59074) Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=17.0, gpu=1.0, object_store_memory=0.0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[36m(RayTrainWorker pid=59074)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ytian/github/esm-lora/notebooks/ray_results/llm/TorchTrainer_50259_00000_0_2024-02-13_11-15-56/checkpoint_000004)\n",
      "2024-02-13 14:48:58,491\tWARNING experiment_state.py:323 -- Experiment checkpoint syncing has been triggered multiple times in the last 30.0 seconds. A sync will be triggered whenever a trial has checkpointed more than `num_to_keep` times since last sync or if 300 seconds have passed since last sync. If you have set `num_to_keep` in your `CheckpointConfig`, consider increasing the checkpoint frequency or keeping more checkpoints. You can supress this warning by changing the `TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S` environment variable.\n",
      "2024-02-13 14:48:58,495\tINFO tune.py:1042 -- Total run time: 12782.18 seconds (12782.14 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.4 s, sys: 10.6 s, total: 1min 3s\n",
      "Wall time: 3h 33min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train\n",
    "results = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>...</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>config/train_loop_config/esm_model</th>\n",
       "      <th>config/train_loop_config/dropout_p</th>\n",
       "      <th>config/train_loop_config/lr</th>\n",
       "      <th>config/train_loop_config/lr_factor</th>\n",
       "      <th>config/train_loop_config/lr_patience</th>\n",
       "      <th>config/train_loop_config/num_epochs</th>\n",
       "      <th>config/train_loop_config/batch_size</th>\n",
       "      <th>config/train_loop_config/num_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.168559</td>\n",
       "      <td>0.166151</td>\n",
       "      <td>1707854328</td>\n",
       "      <td>checkpoint_000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>50259_00000</td>\n",
       "      <td>...</td>\n",
       "      <td>2570.455658</td>\n",
       "      <td>1</td>\n",
       "      <td>facebook/esm2_t12_35M_UR50D</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.164640</td>\n",
       "      <td>0.164051</td>\n",
       "      <td>1707856807</td>\n",
       "      <td>checkpoint_000001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>50259_00000</td>\n",
       "      <td>...</td>\n",
       "      <td>5049.391227</td>\n",
       "      <td>2</td>\n",
       "      <td>facebook/esm2_t12_35M_UR50D</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.163061</td>\n",
       "      <td>0.162828</td>\n",
       "      <td>1707859398</td>\n",
       "      <td>checkpoint_000002</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>50259_00000</td>\n",
       "      <td>...</td>\n",
       "      <td>7639.934725</td>\n",
       "      <td>3</td>\n",
       "      <td>facebook/esm2_t12_35M_UR50D</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.162195</td>\n",
       "      <td>0.162862</td>\n",
       "      <td>1707861961</td>\n",
       "      <td>checkpoint_000003</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>50259_00000</td>\n",
       "      <td>...</td>\n",
       "      <td>10202.932019</td>\n",
       "      <td>4</td>\n",
       "      <td>facebook/esm2_t12_35M_UR50D</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.162174</td>\n",
       "      <td>0.162152</td>\n",
       "      <td>1707864537</td>\n",
       "      <td>checkpoint_000004</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>50259_00000</td>\n",
       "      <td>...</td>\n",
       "      <td>12779.089809</td>\n",
       "      <td>5</td>\n",
       "      <td>facebook/esm2_t12_35M_UR50D</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch     lr  train_loss  val_loss   timestamp checkpoint_dir_name  \\\n",
       "0      0  0.001    0.168559  0.166151  1707854328   checkpoint_000000   \n",
       "1      1  0.001    0.164640  0.164051  1707856807   checkpoint_000001   \n",
       "2      2  0.001    0.163061  0.162828  1707859398   checkpoint_000002   \n",
       "3      3  0.001    0.162195  0.162862  1707861961   checkpoint_000003   \n",
       "4      4  0.001    0.162174  0.162152  1707864537   checkpoint_000004   \n",
       "\n",
       "   should_checkpoint   done  training_iteration     trial_id  ...  \\\n",
       "0               True  False                   1  50259_00000  ...   \n",
       "1               True  False                   2  50259_00000  ...   \n",
       "2               True  False                   3  50259_00000  ...   \n",
       "3               True  False                   4  50259_00000  ...   \n",
       "4               True  False                   5  50259_00000  ...   \n",
       "\n",
       "  time_since_restore  iterations_since_restore  \\\n",
       "0        2570.455658                         1   \n",
       "1        5049.391227                         2   \n",
       "2        7639.934725                         3   \n",
       "3       10202.932019                         4   \n",
       "4       12779.089809                         5   \n",
       "\n",
       "   config/train_loop_config/esm_model  config/train_loop_config/dropout_p  \\\n",
       "0         facebook/esm2_t12_35M_UR50D                                 0.1   \n",
       "1         facebook/esm2_t12_35M_UR50D                                 0.1   \n",
       "2         facebook/esm2_t12_35M_UR50D                                 0.1   \n",
       "3         facebook/esm2_t12_35M_UR50D                                 0.1   \n",
       "4         facebook/esm2_t12_35M_UR50D                                 0.1   \n",
       "\n",
       "  config/train_loop_config/lr config/train_loop_config/lr_factor  \\\n",
       "0                       0.001                                0.8   \n",
       "1                       0.001                                0.8   \n",
       "2                       0.001                                0.8   \n",
       "3                       0.001                                0.8   \n",
       "4                       0.001                                0.8   \n",
       "\n",
       "   config/train_loop_config/lr_patience  config/train_loop_config/num_epochs  \\\n",
       "0                                     3                                    5   \n",
       "1                                     3                                    5   \n",
       "2                                     3                                    5   \n",
       "3                                     3                                    5   \n",
       "4                                     3                                    5   \n",
       "\n",
       "  config/train_loop_config/batch_size  config/train_loop_config/num_classes  \n",
       "0                                   8                                   500  \n",
       "1                                   8                                   500  \n",
       "2                                   8                                   500  \n",
       "3                                   8                                   500  \n",
       "4                                   8                                   500  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Checkpoint(filesystem=local, path=/home/ytian/github/esm-lora/notebooks/ray_results/llm/TorchTrainer_50259_00000_0_2024-02-13_11-15-56/checkpoint_000004),\n",
       "  {'epoch': 4,\n",
       "   'lr': 0.001,\n",
       "   'train_loss': 0.16217386739909168,\n",
       "   'val_loss': 0.16215160568240716,\n",
       "   'timestamp': 1707864537,\n",
       "   'checkpoint_dir_name': 'checkpoint_000004',\n",
       "   'should_checkpoint': True,\n",
       "   'done': False,\n",
       "   'training_iteration': 5,\n",
       "   'trial_id': '50259_00000',\n",
       "   'date': '2024-02-13_14-48-57',\n",
       "   'time_this_iter_s': 2576.1577904224396,\n",
       "   'time_total_s': 12779.089809179306,\n",
       "   'pid': 58984,\n",
       "   'hostname': 'Witcher',\n",
       "   'node_ip': '172.30.66.101',\n",
       "   'config': {'train_loop_config': {'esm_model': 'facebook/esm2_t12_35M_UR50D',\n",
       "     'dropout_p': 0.1,\n",
       "     'lr': 0.001,\n",
       "     'lr_factor': 0.8,\n",
       "     'lr_patience': 3,\n",
       "     'num_epochs': 5,\n",
       "     'batch_size': 8,\n",
       "     'num_classes': 500}},\n",
       "   'time_since_restore': 12779.089809179306,\n",
       "   'iterations_since_restore': 5})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:34:14,097 E 53958 53958] (raylet) node_manager.cc:3022: 3 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:35:14,097 E 53958 53958] (raylet) node_manager.cc:3022: 5 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:36:14,098 E 53958 53958] (raylet) node_manager.cc:3022: 5 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:37:14,098 E 53958 53958] (raylet) node_manager.cc:3022: 3 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:38:14,099 E 53958 53958] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:39:14,099 E 53958 53958] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:40:14,100 E 53958 53958] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:41:14,100 E 53958 53958] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:42:14,101 E 53958 53958] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:43:14,102 E 53958 53958] (raylet) node_manager.cc:3022: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:44:14,102 E 53958 53958] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "\u001b[33m(raylet)\u001b[0m [2024-02-13 15:45:14,103 E 53958 53958] (raylet) node_manager.cc:3022: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: a4d02bda07eec1bc1d58387c4b93c27d58f80cb7797d0315615ccdf7, IP: 172.30.66.101) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.30.66.101`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "results.best_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
